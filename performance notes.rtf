{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fmodern\fcharset0 Courier;\f1\fmodern\fcharset0 Courier-Bold;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww26860\viewh21820\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf0 \expnd0\expndtw0\kerning0
      112    0.373    0.003   74.463    0.665 <ipython-input-11-c37fe3b06b6e>:129(backwardProjectForZY)\
      504    1.432    0.003   
\f1\b 72.782
\f0\b0     0.144 <ipython-input-11-c37fe3b06b6e>:91(convolve)\
calls\
     4046    0.008    0.000   
\f1\b 48.292
\f0\b0     0.012 basic.py:673(fft2)\
and calls\
      896    1.006    0.001   
\f1\b 24.424
\f0\b0     0.027 <ipython-input-11-c37fe3b06b6e>:84(convolvePart2)\
 which calls\
      784    0.059    0.000    2.299    0.003 <ipython-input-11-c37fe3b06b6e>:54(MirrorYArray)\
 and calls\
     1680    0.985    0.001   21.094    0.013 <ipython-input-11-c37fe3b06b6e>:71(convolvePart3)\
  which calls\
     1470    0.093    0.000    4.855    0.003 <ipython-input-11-c37fe3b06b6e>:37(MirrorXArray)\
  and calls\
     3150    
\f1\b 6.667
\f0\b0     0.002   
\f1\b 14.953
\f0\b0     0.005 <ipython-input-8-dbe0fb60aef9>:123(special_fftconvolve)\
   calls\
     3150    0.021    0.000    8.286    0.003 <ipython-input-8-dbe0fb60aef9>:112(special_fftconvolve_part1)\
    calls\
     3150    0.046    0.000    7.973    0.003 <ipython-input-8-dbe0fb60aef9>:80(special_rfftn)\
     calls\
     3150    0.449    0.000    
\f1\b 5.314
\f0\b0     0.002 <ipython-input-8-dbe0fb60aef9>:72(expand)\
      which calls\
     3150    2.589    0.001    2.627    0.001 <ipython-input-8-dbe0fb60aef9>:65(tempMul)\
\
By implication, 2.6s of fft2 belongs to special_fftconvolve, and all the rest is \'91large\'92 FFTs.\
\
I don\'92t understand how special_fftconvolve has so much time assigned to self.\
I suppose it must be the multiply? I suppose it must be taking the hit for *something*?\
Maybe the unpickling of \'91projection\'92!?\
\
\
    10346    3.071    0.000    
\f1\b 3.071
\f0\b0     0.000 \{method 'astype' of 'numpy.ndarray' objects\}\
\
      112    1.053    0.009    1.083    0.010 memmap.py:207(__new__)\
\
\
\
63% rfftn, so using symmetries will definitely help significantly for that\
15% fa*fb in special_fftconvolve \
14% special_fftconvolve_part1.\
\
\
Stats on mac pro across increasing numbers of threads show that dead time is no longer a significant problem.\
However, work time does still increase with number of threads - around 1.5x by the time I hit 8 threads.\
I can only imagine this is a memory bandwidth thing, whether in terms of sheer RAM bandwidth,\
cache performance, or overheads due to allocating memory.\
I imagine that doing as many in-place operations as possible (and/or working in scratch space?) can only be a good thing for this.\
\
\
I should try:\
- fusing any more maths operations I can find. Make sure function calls don\'92t prevent fused multiply/add\
- try doing the transpose as the final operation, rather than a mirror\
- am I tiling in the most efficient order? \
- would it help to change the axis order in rfftn? Raw speed, but also could be better for tiling to complete the matrix with conjugate\
- investigate whether fft performance is impacted by the prime factors of the input array\
\
}