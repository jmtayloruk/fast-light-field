{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Oblique;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \ul \ulc0 PSF generation\
\ulnone Their PSF generation only populates 6 variables. I should be able to save those in a .mat to avoid having to rerun it every time.\
-> I have done that, but their H is a 3D cell of 2D matrices, and I haven\'92t yet figured out how best to convert that to the 3D array that I need to work with.\ul \
\
What they do differently\ulnone \
They convolve each plane with a (blurring?) kernel at each reconstruction iteration. Is that all they do!? My code could even do that without the need for any additional FFTs (it could just be folded in as a multiplication before the inverse FFT\
\
\ul Performance\ulnone \
They 
\f1\i do not
\f0\i0  appear to use CAIndex, as far as I can tell. They just use the full H matrix in the convolution. \
\
Their code takes 60s/iter, when running for z=\{-5,0,5\}. They are doing convolutions between a 115x115 PSF and a 1273x1463 image. Prevedel\'92s code takes 10.7s for a backprojection - but Prevedel\'92s code generates a 39x39 PSF, so I suspect that is the reason why Olaf is taking longer!\
\
It seems like Olaf does not crop the PSFs to account for the fact that the PSFs close to z=0 are more compact. Neither does it crop them based on what is actually measured, so Olaf ends up working with a much larger PSF than Prevedel does.\
\
The comments in the Olaf documentation (p30) imply that they 
\f1\i think
\f0\i0  they are doing sparse convolutions:\

\f1\i The non-zero values in H(aa_tex,bb_tex, cc) (effective sparse kernel size) directly affect the computation time. The further away a source point is from the native object plane (NOP, depicted in blue in Fig. 4) of the LFM, the larger the LFPSF size on the sensor. This means object depths further away from the NOP require are computationally more expensive to forward/backward-project\

\f0\i0 But in practice this really doesn\'92t seem to be happening! I don\'92t know why that is.}