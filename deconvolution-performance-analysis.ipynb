{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import tifffile\n",
    "import sys, time, os, csv\n",
    "import cProfile, pstats\n",
    "from jutils import tqdm_alias as tqdm\n",
    "\n",
    "import psfmatrix, lfimage\n",
    "import projector, lfdeconv\n",
    "import special_fftconvolve as special\n",
    "import jutils as util\n",
    "import py_light_field as plf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter = 8\n",
    "tileFactor = 2\n",
    "projectorClass = projector.Projector_allC\n",
    "inputImage = lfimage.LoadLightFieldTiff('/Users/jonny/Movies/Nils files/Rectified/Left/Cam_Left_40_X1_N19.tif')\n",
    "hMatrix = psfmatrix.LoadMatrix('PSFmatrix/reducedPSFMatrix_M22.2NA0.5MLPitch125fml3125from-156to156zspacing4Nnum19lambda520n1.33.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance issues to consider\n",
    "- ConvolvePart4 is only threaded over the images, i.e. it is single-threaded if we only have one image! That is definitely not optimal, and I need to work on how to do something about that. Is there any reason I cannot thread over aa,bb? The advantage would be that the threading would be at a higher level. The disadvantage would be that I would only have a limited number of units to thread over (even if there were a large number of images). I suppose I could do both(!). Perhaps the complication is just that I would be threading at quite a high level, with a lot going on below it...  One way or another, I do need to come up with a solution. It's possible that I could thread calculateRow, but that would need care because the work elements would be so small.\n",
    "- Note that the GPU version should not suffer from this issue (because it's threaded at a much lower level anyway).\n",
    "- There is a general trend where work elements that take longer have a lower thread efficiency. It really does seem like what is happening is just natural variation in run time. It is causing a problem because I have hard sync points at which I wait before allowing anything else to continue at all. I may just have to accept that, unless I really want to over-engineer things and restructure my C code.\n",
    "- (I have tried making memory-aligned python arrays, but that does not seem to have speeded anything up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Timing measurements\n",
    "    inputImageXN = np.tile(inputImage[np.newaxis,:,:],(tileFactor,1,1))\n",
    "    # We will only process one plane, in the interests of speed,\n",
    "    # although we must remember that that means the analysis may not \n",
    "    # be representative of a full deconvolution pipeline\n",
    "    planesToRun = range(0,1)\n",
    "    # Prime the cache first\n",
    "    Htf = lfdeconv.BackwardProjectACC(hMatrix, inputImageXN, planes=planesToRun, progress=tqdm, logPrint=False, projector=projectorClass())\n",
    "    # Now actually measure\n",
    "    plf.SetStatsFile('timestats.txt', False)\n",
    "    Htf = lfdeconv.BackwardProjectACC(hMatrix, inputImageXN, planes=planesToRun, progress=tqdm, logPrint=False, projector=projectorClass())\n",
    "    plf.SetStatsFile('', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    rows = []\n",
    "    with open('timestats.txt') as f:\n",
    "        cf = csv.reader(f, delimiter='\\t')\n",
    "        for row in cf:\n",
    "            rows.append(row)\n",
    "    vals = []\n",
    "    delta = np.array(rows[-1][1:]).astype(np.double) - np.array(rows[0][1:]).astype(np.double)\n",
    "    print('Overall efficiency', delta[1]/delta[0], delta[0], delta[1])\n",
    "    thresh = 0.04\n",
    "    plt.figure()\n",
    "    plt.title('Parallelism with tile factor {0}'.format(tileFactor))\n",
    "    deltas = []\n",
    "    categories = dict()\n",
    "    print('Some performance sampling points:')\n",
    "    for i in range(0, len(rows)-1):\n",
    "        row = rows[i]\n",
    "        delta = np.array(rows[i+1][1:]).astype(np.double) - np.array(row[1:]).astype(np.double)\n",
    "        deltas.append(delta)\n",
    "        if (i < 20) or (delta[0] > thresh):\n",
    "            print(' ', i, row[0], delta[0], delta[1], delta[2], delta[1]/delta[0])\n",
    "        vals.append(delta[1]/delta[0])\n",
    "        c='black'\n",
    "        marker='.'\n",
    "        if row[0] == 'FHInit':\n",
    "            c='yellow'\n",
    "        if row[0] == 'FHRun':\n",
    "            c='red'\n",
    "        elif row[0] == 'ConvolvePart4Run':\n",
    "            c='green'\n",
    "        elif row[0] == 'MirrorY':\n",
    "            c='blue'\n",
    "        elif row[0] == 'IRFFT':\n",
    "            c='orange'\n",
    "        elif row[0].endswith('Plan'):\n",
    "            c='brown'\n",
    "        if row[0] in categories:\n",
    "            categories[row[0]] += delta\n",
    "        else:\n",
    "            categories[row[0]] = delta\n",
    "\n",
    "        if (i < 10000):\n",
    "            x = delta[0]\n",
    "            if (x > thresh):\n",
    "                x = thresh\n",
    "            plt.plot(x, delta[1]/delta[0], marker, color=c)\n",
    "    plt.show()\n",
    "\n",
    "deltas = np.array(deltas).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "av = 0\n",
    "weights = 0\n",
    "print('Performance broken down by category')\n",
    "for k in categories:\n",
    "    print(' ', k, categories[k][0], categories[k][1], categories[k][1]/categories[k][0])\n",
    "    weights += categories[k][0]\n",
    "    av += categories[k][0] * categories[k][1]/categories[k][0]\n",
    "av /= weights\n",
    "print('Average CPU load: %.2fx' % av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitor page faults just to check they are not a major issue,\n",
    "# and that they do not correlate with run times\n",
    "plt.figure()\n",
    "plt.plot(np.minimum(deltas[0], thresh), deltas[5], '.', label='minflt')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
