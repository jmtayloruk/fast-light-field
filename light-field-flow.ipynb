{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: my c code can't cope with an array that has been transposed (Probably because it assumes adjacent strides in x?). I should probably fix that, though I doubt it's a performance issue to just .copy() the transposed array, which is what I do at the moment. I should really be swapping the transpose to be the final operation (in the case of square inputs) anyway. However, it looks as if a decent chunk of the fft time is actually being spent in the other ffts (for the reduced arrays) anyway!\n",
    "\n",
    "### Performance investigation\n",
    "\n",
    "Actual thread execution time seems to grow considerably with the number of threads, i.e. efficiency falls. It's less than 50% efficient by the time I hit 12 threads (on an 8-core machine). I am not sure how to try and work out what the cause of that is. I could go back to working on dummy data (no transfers between processes) and see if that makes a difference to *that* in particular. (I think I may have looked only at the dead time overheads - which are also an issue).\n",
    "I looked at user and system cpu time, and with Instruments. Looks like 20% of time is spent in madvise (macbook, 2 threads). I am not sure exactly why or where that is happening. It seems to be related to python memory management in some way. I should check if that grows with number of threads on mac pro, and if it is the same when I use dummy work blocks rather than passing to subprocesses\n",
    "\n",
    "-> revisit this now I am using mmap rather than pickle - hopefully some of this is now fixed.\n",
    "\n",
    "### Performance improvements to make\n",
    "\n",
    "Consider moving transpose to final operation (since it's probably faster than reversing an array - although it may impact subsequent fft performance?), in the case of square arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import scipy.ndimage, scipy.optimize, scipy.io\n",
    "from scipy.ndimage.filters import convolve\n",
    "from scipy.signal import convolve2d, fftconvolve\n",
    "from scipy.optimize import Bounds\n",
    "import os, sys, time, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tifffile\n",
    "import h5py\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "import cProfile, pstats\n",
    "import glob, csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from numba import jit\n",
    "sys.path.insert(0, 'py_symmetry')\n",
    "import py_symmetry as jps\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "import j_py_sad_correlation as jpsad\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# I don't know if these are necessary, but it has been suggested that low-level threading\n",
    "# does not interact well with the joblib Parallel feature.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_DYNAMIC'] = 'FALSE'\n",
    "\n",
    "try:\n",
    "    os.mkdir('perf_diags')\n",
    "except:\n",
    "    pass  # Probably the directory already exists\n",
    "\n",
    "# My code expects these to start as None, and I want to do this right at the top\n",
    "# to minimize the rish of accidentally resetting them to None after I've spent hours\n",
    "# accumulating valuable data in them!\n",
    "shiftHistoryJoint = None\n",
    "shiftHistoryRaw = None\n",
    "shiftHistoryNaive = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPath = 'PSFmatrix/PSFmatrix_M22.2NA0.5MLPitch125fml3125from-110to110zspacing4Nnum19lambda520n1.33.mat'\n",
    "\n",
    "if False:\n",
    "    warnings.warn('WARNING: Switched to faster matrix for testing')\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-26to0zspacing2Nnum15lambda520n1.0.mat'\n",
    "elif True:\n",
    "    warnings.warn('WARNING: Switched to faster and closer-spaced matrix for testing')\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mmapPath = os.path.splitext(matPath)[0]\n",
    "try:\n",
    "    os.mkdir(mmapPath)\n",
    "except:\n",
    "    pass  # Probably the directory already exists\n",
    "\n",
    "_HPathFormat = mmapPath+'/H{z:02d}.array'\n",
    "_HtPathFormat = mmapPath+'/Ht{z:02d}.array'\n",
    "_HReducedShape = []\n",
    "_HtReducedShape = []\n",
    "if True:\n",
    "    # Load the matrices from the .mat file.\n",
    "    # This is slow since they must be decompressed and are rather large! (9.5GB each, in single-precision FP)\n",
    "    with h5py.File(matPath, 'r') as f:\n",
    "        print('Load CAindex')\n",
    "        sys.stdout.flush()\n",
    "        _CAindex = f['CAindex'].value.astype('int')\n",
    "        \n",
    "        print('Load H')\n",
    "        sys.stdout.flush()\n",
    "        _H = f['H'].value.astype('float32')\n",
    "        Nnum = _H.shape[2]\n",
    "        aabbRange = int((Nnum+1)/2)\n",
    "        for cc in tqdm(range(_H.shape[0]), desc='memmap H'):\n",
    "            HCC =  _H[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            _HReducedShape.append(HCC.shape)\n",
    "            a = np.memmap(_HPathFormat.format(z=cc), dtype='float32', mode='w+', shape=HCC.shape)\n",
    "            a[:,:,:,:] = HCC[:,:,:,:]\n",
    "            del a\n",
    "        #del _H        # H is needed for old code\n",
    "        \n",
    "        print('Load Ht')\n",
    "        sys.stdout.flush()\n",
    "        _Ht = f['Ht'].value.astype('float32')\n",
    "        for cc in tqdm(range(_Ht.shape[0]), desc='memmap Ht'):\n",
    "            HtCC =  _Ht[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            _HtReducedShape.append(HtCC.shape)\n",
    "            a = np.memmap(_HtPathFormat.format(z=cc), dtype='float32', mode='w+', shape=HtCC.shape)\n",
    "            a[:,:,:,:] = HtCC[:,:,:,:]\n",
    "            del a\n",
    "        #del _Ht        # Ht is needed for old code\n",
    "    np.save(mmapPath+'/HReducedShape.npy', _HReducedShape)\n",
    "    np.save(mmapPath+'/HtReducedShape.npy', _HtReducedShape)\n",
    "else:\n",
    "    _HReducedShape = np.load(mmapPath+'/HReducedShape.npy')\n",
    "    _HtReducedShape = np.load(mmapPath+'/HtReducedShape.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfftw\n",
    "pyfftw.interfaces.cache.enable()\n",
    "pyfftw.interfaces.cache.set_keepalive_time(10.0)\n",
    "\n",
    "if False:\n",
    "    # Old FFT code\n",
    "    def myFFT2(mat, shape):\n",
    "        # Perform a 'float' FFT on the matrix we are passed.\n",
    "        # It would probably be faster if there was a way to perform the FFT natively on the 'float' type,\n",
    "        # but scipy does not seem to support that option\n",
    "        #\n",
    "        # With my Mac Pro install, we hit a FutureWarning within scipy.\n",
    "        # This wrapper just suppresses that warning.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return scipy.fftpack.fft2(mat, shape).astype('complex64')\n",
    "else:\n",
    "    # New FFT code based on FFTW.\n",
    "    # It may be possible to speed this up slightly be using their \"proper\" interface\n",
    "    # rather than the scipy-like interface (see pyfftw documentation)\n",
    "    def myFFT2(mat, shape):\n",
    "        return pyfftw.interfaces.scipy_fftpack.fft2(mat, shape)\n",
    "\n",
    "    def myIFFT2(mat, shape):\n",
    "        return pyfftw.interfaces.numpy_fft.irfft2(mat, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMatrix:\n",
    "    def __init__(self, HPathFormat, HtPathFormat, HReducedShape, numZ=None, zStart=0):\n",
    "        self.HPathFormat = HPathFormat\n",
    "        self.HtPathFormat = HtPathFormat\n",
    "        self.HReducedShape = HReducedShape   # Same for Ht\n",
    "        if numZ is not None:\n",
    "            self.numZ = numZ\n",
    "        else:\n",
    "            self.numZ = len(HReducedShape)\n",
    "        self.zStart = zStart\n",
    "        self.Hcache = dict()\n",
    "        self.cacheHits = 0\n",
    "        self.cacheMisses = 0\n",
    "        self.cacheSize = 0\n",
    "  \n",
    "    def Hcc(self, cc, useHt):\n",
    "        if useHt:\n",
    "            pathFormat = self.HtPathFormat\n",
    "        else:\n",
    "            pathFormat = self.HPathFormat\n",
    "        result = np.memmap(pathFormat.format(z=cc+self.zStart), dtype='float32', mode='r', shape=tuple(self.HReducedShape[cc+self.zStart]))\n",
    "        return result\n",
    "\n",
    "    def fH_uncached(self, cc, bb, aa, useHt, transposePSF, fshape):\n",
    "        if transposePSF:\n",
    "            return myFFT2(self.Hcc(cc, useHt)[bb, aa].transpose(), fshape)\n",
    "        else:\n",
    "            return myFFT2(self.Hcc(cc, useHt)[bb, aa], fshape)\n",
    "    \n",
    "    def fH(self, cc, bb, aa, useHt, transposePSF, fshape):\n",
    "        key = '%d,%d,%d,%d,%d'%(cc, bb, aa, int(useHt), int(transposePSF))\n",
    "        if not key in self.Hcache:\n",
    "            result = self.fH_uncached(cc, bb, aa, useHt, transposePSF, fshape)\n",
    "            self.Hcache[key] = result\n",
    "            self.cacheSize += result.nbytes\n",
    "            self.cacheMisses += 1\n",
    "        else:\n",
    "            self.cacheHits += 1\n",
    "        return self.Hcache[key]\n",
    "    \n",
    "    def IterableBRange(self, cc):\n",
    "        return range(self.HReducedShape[cc+self.zStart][0])\n",
    "    \n",
    "    def PSFShape(self, cc):\n",
    "        return (self.HReducedShape[cc+self.zStart][2], self.HReducedShape[cc+self.zStart][3])\n",
    "        \n",
    "    def Nnum(self, cc):\n",
    "        return self.HReducedShape[cc+self.zStart][0]*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "LFmovie = tifffile.imread('Data/02_Rectified/exampleData/20131219WORM2_small_full_neg_X1_N15_cropped_uncompressed.tif')\n",
    "LFmovie = LFmovie.transpose()[np.newaxis,:,:]\n",
    "\n",
    "LFIMG = LFmovie[0].astype('float32')\n",
    "if True:\n",
    "    # Actual (cropped) image loaded from disk\n",
    "    inputImage = LFIMG\n",
    "else:\n",
    "    inputImage = np.tile(LFIMG,(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects stored in the .mat file\n",
    "\n",
    "### Optical parameters from GUI: [? means I am not sure if or where it is stored]\n",
    "\n",
    "M<br>\n",
    "NA<br>\n",
    "d    \"fml\" in GUI (stored here in units of m)<br>\n",
    "pixelPitch is \"ML pitch\" / \"Nnum\" (stored here in units of m)<br>\n",
    "? n<br>\n",
    "? wavelength<br>\n",
    "\n",
    "### User parameters from GUI:\n",
    "\n",
    "OSR<br>\n",
    "zspacing<br>\n",
    "? z-min<br>\n",
    "? z-max<br>\n",
    "Nnum<br>\n",
    "\n",
    "\n",
    "### Misc parameter:\n",
    "\n",
    "fobj (can presumably be deduced from mag, NA etc?)<br>\n",
    "\n",
    "### The actual arrays:\n",
    "\n",
    "H:             shape (56, 19, 19, 343, 343), type \"f4\"<br>\n",
    "Ht:            shape (56, 19, 19, 343, 343), type \"f4\"<br>\n",
    "\n",
    "### Information about object space:\n",
    "\n",
    "x1objspace:    x pixel positions in object space (19 elements across one lenslet)<br>\n",
    "x2objspace:    y pixel positions in object space (19 elements across one lenslet)<br>\n",
    "x3objspace:    z pixel positions in object space (56 z planes)<br>\n",
    "x1space:       x pixel positions in lenslet space (19 elements across one lenslet)<br>\n",
    "x2space:       y pixel positions in lenslet space (19 elements across one lenslet)<br>\n",
    "\n",
    "### Not sure what these are exactly:\n",
    "\n",
    "CAindex:       shape (2, 56) - something about the start and end index of the PSF array, for each z plane.<br>\n",
    "CP:            shape (343, 1)<br>\n",
    "MLARRAY:       shape (1141, 1141), type \"|V16\"<br>\n",
    "objspace:      shape (56, 1, 1)<br>\n",
    "settingPSF:    You would think this contains the GUI parameters, but e.g. print(f['settingPSF']['M'].value) gives a strange 3x1 array [50, 50, 46, 50] etc...?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I am a little unsure how to interpret the arrays I have loaded from the .mat.\n",
    "# From looking at how H and CAindex are accessed, it looks as if the shapes I have loaded\n",
    "# are the reversal of the shape ordering as expected in Matlab.\n",
    "# I suppose that makes sense given that matlab is column-major in its array accesses.\n",
    "# The data has been loaded from disk in the order it is *stored*,\n",
    "# and I therefore need to flip around all the matlab array index ordering \n",
    "# (e.g. matlabArray(1,2,3) becomes pythonArray[3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "def noProgressBar(work, **kwargs):\n",
    "    # Dummy function to be used in place of tqdm when we don't want to show a progress bar\n",
    "    return work    \n",
    "\n",
    "def cpuTime(kind):\n",
    "    rus = resource.getrusage(resource.RUSAGE_SELF)    \n",
    "    ruc = resource.getrusage(resource.RUSAGE_CHILDREN)\n",
    "    if (kind == 'self'):\n",
    "        return np.array([rus.ru_utime, rus.ru_stime])\n",
    "    elif (kind == 'children'):\n",
    "        return np.array([ruc.ru_utime, ruc.ru_stime])\n",
    "    else:\n",
    "        return np.array([rus.ru_utime+ruc.ru_utime, rus.ru_stime+ruc.ru_stime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy._lib._version import NumpyVersion\n",
    "from numpy.fft import fft, fftn, rfft, rfftn, irfftn\n",
    "_rfft_mt_safe = (NumpyVersion(np.__version__) >= '1.9.0.dev-e24486e')\n",
    "\n",
    "def _next_regular(target):\n",
    "    \"\"\"\n",
    "    Find the next regular number greater than or equal to target.\n",
    "    Regular numbers are composites of the prime factors 2, 3, and 5.\n",
    "    Also known as 5-smooth numbers or Hamming numbers, these are the optimal\n",
    "    size for inputs to FFTPACK.\n",
    "\n",
    "    Target must be a positive integer.\n",
    "    \"\"\"\n",
    "    if target <= 6:\n",
    "        return target\n",
    "\n",
    "    # Quickly check if it's already a power of 2\n",
    "    if not (target & (target-1)):\n",
    "        return target\n",
    "\n",
    "    match = float('inf')  # Anything found will be smaller\n",
    "    p5 = 1\n",
    "    while p5 < target:\n",
    "        p35 = p5\n",
    "        while p35 < target:\n",
    "            # Ceiling integer division, avoiding conversion to float\n",
    "            # (quotient = ceil(target / p35))\n",
    "            quotient = -(-target // p35)\n",
    "\n",
    "            # Quickly find next power of 2 >= quotient\n",
    "            try:\n",
    "                p2 = 2**((quotient - 1).bit_length())\n",
    "            except AttributeError:\n",
    "                # Fallback for Python <2.7\n",
    "                p2 = 2**(len(bin(quotient - 1)) - 2)\n",
    "\n",
    "            N = p2 * p35\n",
    "            if N == target:\n",
    "                return N\n",
    "            elif N < match:\n",
    "                match = N\n",
    "            p35 *= 3\n",
    "            if p35 == target:\n",
    "                return p35\n",
    "        if p35 < match:\n",
    "            match = p35\n",
    "        p5 *= 5\n",
    "        if p5 == target:\n",
    "            return p5\n",
    "    if p5 < match:\n",
    "        match = p5\n",
    "    return match\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    currsize = np.array(arr.shape)\n",
    "    newsize = np.asarray(newsize)\n",
    "    if (len(currsize) > len(newsize)):\n",
    "        newsize = np.append([currsize[0]], newsize)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "def tempMul(bb,fshape,result):\n",
    "    result *= np.exp(-1j * bb * 2*np.pi / fshape[-2] * np.arange(result.shape[-2],dtype='complex64'))[...,np.newaxis]\n",
    "    return result\n",
    "\n",
    "def expand2(result, bb, aa, Nnum, fshape):\n",
    "    tileFactor = (1,) * (len(result.shape)-2) + (Nnum, 1)\n",
    "    return np.tile(result, tileFactor)\n",
    "\n",
    "def expand(reducedF, bb, aa, Nnum, fshape):\n",
    "    tileFactor = (1,) * (len(reducedF.shape)-1) + (int(Nnum/2+1),)\n",
    "    result = np.tile(reducedF, tileFactor)\n",
    "    result = result[...,:int(fshape[-1]/2+1)]\n",
    "    result *= np.exp(-1j * aa * 2*np.pi / fshape[-1] * np.arange(result.shape[-1],dtype='complex64'))\n",
    "    result = expand2(result, bb, aa, Nnum, fshape)\n",
    "    return tempMul(bb,fshape,result)\n",
    "\n",
    "def special_rfftn(in1, bb, aa, Nnum, fshape):\n",
    "    # Compute the fft of elements in1[bb::Nnum,aa::Nnum], after in1 has been zero-padded out to fshape\n",
    "    # We exploit the fact that fft(masked-in1) is fft(arr[::Nnum,::Nnum]) replicated Nnum times.\n",
    "    reducedShape = ()\n",
    "    for d in fshape:\n",
    "        assert((d % Nnum) == 0)\n",
    "        reducedShape = reducedShape + (int(d/Nnum),)\n",
    "    reduced = in1[...,bb::Nnum,aa::Nnum]\n",
    "\n",
    "    # Compute an array giving rfft(mask(in1))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        reducedF = myFFT2(reduced, reducedShape)\n",
    "    return expand(reducedF, bb, aa, Nnum, fshape)\n",
    "\n",
    "def convolutionShape(in1, in2Shape, Nnum):\n",
    "    # Logic copied from fftconvolve source code\n",
    "    s1 = np.array(in1.shape)\n",
    "    s2 = np.array(in2Shape)\n",
    "    if (len(s1) == 3):   # Cope with case where we are processing multiple reconstructions in parallel\n",
    "        s1 = s1[1:]\n",
    "    shape = s1 + s2 - 1\n",
    "    if False:\n",
    "        # TODO: I haven't worked out if/how I can do this yet.\n",
    "        # This is the original code in fftconvolve, which says:\n",
    "        # Speed up FFT by padding to optimal size for FFTPACK\n",
    "        fshape = [_next_regular(int(d)) for d in shape]\n",
    "    else:\n",
    "        fshape = [int(np.ceil(d/float(Nnum)))*Nnum for d in shape]\n",
    "    fslice = tuple([slice(0, int(sz)) for sz in shape])\n",
    "    return (fshape, fslice, s1)\n",
    "    \n",
    "def _special_fftconvolve_part1(in1, bb, aa, Nnum, in2Shape):\n",
    "    assert((len(in1.shape) == 2) or (len(in1.shape) == 3))\n",
    "    assert(len(in2Shape) == 2)\n",
    "    (fshape, fslice, s1) = convolutionShape(in1, in2Shape, Nnum)\n",
    "    # Pre-1.9 NumPy FFT routines are not threadsafe - this code requires numpy 1.9 or greater\n",
    "    assert(_rfft_mt_safe)\n",
    "    fa = special_rfftn(in1, bb, aa, Nnum, fshape)\n",
    "    return (fa, fshape, fslice, s1)\n",
    "\n",
    "def special_fftconvolve_part3b(fab, fshape, fslice, s1):\n",
    "    assert(len(fab.shape) == 2)\n",
    "    ret = myIFFT2(fab, fshape)[fslice].copy()\n",
    "    return _centered(ret, s1)\n",
    "\n",
    "def special_fftconvolve_part3(fab, fshape, fslice, s1):\n",
    "    # TODO: This gymnastics is probably unnecessary now I call ifft2 rather than fftn\n",
    "    if (len(fab.shape) == 2):\n",
    "        return special_fftconvolve_part3b(fab, fshape, fslice, s1)\n",
    "    else:\n",
    "        results = []\n",
    "        for n in range(fab.shape[0]):\n",
    "            results.append(special_fftconvolve_part3(fab[n], fshape, fslice, s1))\n",
    "        return np.array(results)\n",
    "\n",
    "def _special_fftconvolve(in1, bb, aa, Nnum, in2Shape, accum, fb=None):\n",
    "    '''\n",
    "    in1 consists of subapertures of size Nnum x Nnum pixels.\n",
    "    We are being asked to convolve only pixel (bb,aa) within each subaperture, i.e.\n",
    "        tempSlice = np.zeros(in1.shape, dtype=in1.dtype)\n",
    "        tempSlice[bb::Nnum, aa::Nnum] = in1[bb::Nnum, aa::Nnum]\n",
    "    This allows us to take a significant shortcut in computing the FFT for in1.\n",
    "    '''\n",
    "    (fa, fshape, fslice, s1) = _special_fftconvolve_part1(in1, bb, aa, Nnum, in2Shape)\n",
    "    assert(fa.dtype == np.complex64)   # Keep an eye out for any reversion to double-precision\n",
    "    assert(fb.dtype == np.complex64)   # Keep an eye out for any reversion to double-precision\n",
    "\n",
    "    if accum is None:\n",
    "        accum = fa*fb\n",
    "    else:\n",
    "        accum += fa*fb\n",
    "    assert(accum.dtype == np.complex64)   # Keep an eye out for any reversion to double-precision\n",
    "    return (accum, fshape, fslice, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProjectForZ_old(HCC, realspaceCC):\n",
    "    singleJob = (len(realspaceCC.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        realspaceCC = realspaceCC[np.newaxis,:,:]\n",
    "    # Iterate over each lenslet pixel\n",
    "    Nnum = HCC.shape[1]\n",
    "    TOTALprojection = np.zeros(realspaceCC.shape, dtype='float32')\n",
    "    for bb in tqdm(range(Nnum), leave=False, desc='Forward-project - y'):\n",
    "        for aa in tqdm(range(Nnum), leave=False, desc='Forward-project - x'):\n",
    "            # Extract the part of H that represents this lenslet pixel\n",
    "            Hs = HCC[bb, aa]\n",
    "            for n in range(realspaceCC.shape[0]):\n",
    "                # Create a workspace representing just the voxels cc,bb,aa behind each lenslet (the rest is 0)\n",
    "                tempspace = np.zeros((realspaceCC[n].shape[0], realspaceCC[n].shape[1]), dtype='float32');\n",
    "                tempspace[bb::Nnum, aa::Nnum] = realspaceCC[n, bb::Nnum, aa::Nnum]  # ???? what to do about index ordering?\n",
    "                # Compute how those voxels project onto the sensor, and accumulate\n",
    "                TOTALprojection[n] += fftconvolve(tempspace, Hs, 'same')\n",
    "    if singleJob:\n",
    "        return TOTALprojection[0]\n",
    "    else:\n",
    "        return TOTALprojection\n",
    "    \n",
    "def backwardProjectForZ_old(HtCC, projection, progress=tqdm):\n",
    "    singleJob = (len(projection.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        projection = projection[np.newaxis,:,:]\n",
    "    # Iterate over each lenslet pixel\n",
    "    Nnum = HtCC.shape[1]\n",
    "    tempSliceBack = np.zeros(projection.shape, dtype='float32')        \n",
    "    for aa in progress(range(Nnum), leave=False, desc='y'):\n",
    "        for bb in range(Nnum):\n",
    "            # Extract the part of Ht that represents this lenslet pixel\n",
    "            Hts = HtCC[bb, aa]\n",
    "            for n in range(projection.shape[0]):\n",
    "                # Create a workspace representing just the voxels cc,bb,aa behind each lenslet (the rest is 0)\n",
    "                tempSlice = np.zeros(projection[n].shape, dtype='float32')\n",
    "                tempSlice[bb::Nnum, aa::Nnum] = projection[n, bb::Nnum, aa::Nnum]\n",
    "                # Compute how those voxels back-project from the sensor\n",
    "                tempSliceBack[n] += fftconvolve(tempSlice, Hts, 'same')\n",
    "    if singleJob:\n",
    "        return tempSliceBack[0]\n",
    "    else:\n",
    "        return tempSliceBack\n",
    "\n",
    "def backwardProjectACC_original(Ht, projection, CAindex, progress=tqdm, planes=None):\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "    Backprojection = np.zeros((Ht.shape[0], projection.shape[0], projection.shape[1]), dtype='float32')\n",
    "    # Iterate over each z plane\n",
    "    if planes is None:\n",
    "        planes = range(Ht.shape[0])\n",
    "    for cc in progress(planes, desc='Back-project - z'):\n",
    "        HtCC =  Ht[cc, :, :, CAindex[0,cc]-1:CAindex[1,cc], CAindex[0,cc]-1:CAindex[1,cc]]\n",
    "        Backprojection[cc] = backwardProjectForZ_old(HtCC, projection, progress=progress)\n",
    "    return Backprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvRL(hMatrix, Htf, maxIter, Xguess, logPrint=True):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC(hMatrix, Xguess, logPrint=logPrint)\n",
    "        HXguessBack = backwardProjectACC(hMatrix, HXguess, logPrint=logPrint)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        ttime = time.time() - t0\n",
    "        print('iter %d | %d, took %.1f secs. Max val %f' % (i+1, maxIter, ttime, np.max(Xguess)))\n",
    "    return Xguess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: H.shape in python is (<num z planes>, Nnum, Nnum, <psf size>, <psf size>),\n",
    "#                       e.g. (56, 19, 19, 343, 343)\n",
    "\n",
    "class _Projector(object):\n",
    "    # Note: the variable names in this class mostly imply we are doing the back-projection\n",
    "    # (e.g. Ht, 'projection', etc. However, the same code also does forward-projection!)\n",
    "    def __init__(self, projection, hMatrix, cc):\n",
    "        # Note: H and Hts are not stored as class variables.\n",
    "        # I had a lot of trouble with them and multithreading,\n",
    "        # and eventually settled on having them in shared memory.\n",
    "        # As I encapsulate more stuff in this class, I could bring them back as class variables...\n",
    "\n",
    "        self.cpuTime = np.zeros(2)\n",
    "        \n",
    "        # Nnum: number of pixels across a lenslet array (after rectification)\n",
    "        self.Nnum = hMatrix.Nnum(cc)\n",
    "        \n",
    "        # This next chunk of logic copied from fftconvolve source code.\n",
    "        # s1, s2: shapes of the input arrays\n",
    "        # fshape: shape of the (full, possibly padded) result array in Fourier space\n",
    "        # fslice: slicing tuple specifying the actual result size that should be returned\n",
    "        self.s1 = np.array(projection.shape)\n",
    "        self.s2 = np.array(hMatrix.PSFShape(cc))\n",
    "        shape = self.s1 + self.s2 - 1\n",
    "        if False:\n",
    "            # TODO: I haven't worked out if/how I can do this yet.\n",
    "            # This is the original code in fftconvolve, which says:\n",
    "            # Speed up FFT by padding to optimal size for FFTPACK\n",
    "            self.fshape = [_next_regular(int(d)) for d in shape]\n",
    "        else:\n",
    "            self.fshape = [int(np.ceil(d/float(Nnum)))*Nnum for d in shape]\n",
    "        self.fslice = tuple([slice(0, int(sz)) for sz in shape])\n",
    "        \n",
    "        # rfslice: slicing tuple to crop down full fft array to the shape that would be output from rfftn\n",
    "        self.rfslice = (slice(0,self.fshape[0]), slice(0,int(self.fshape[1]/2)+1))\n",
    "        return\n",
    "    \n",
    "    def _MirrorXArray(self, fHtsFull):\n",
    "        padLength = self.fshape[0] - self.s2[0]\n",
    "        if False:\n",
    "            fHtsFull = fHtsFull.conj() * np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[0]) * np.arange(self.fshape[0],dtype='complex64')[:,np.newaxis])\n",
    "            fHtsFull[:,1::] = fHtsFull[:,1::][:,::-1]\n",
    "            return fHtsFull\n",
    "        else:\n",
    "            temp = np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[0]) * np.arange(self.fshape[0])).astype('complex64')\n",
    "            if True:\n",
    "                result = jps.mirrorX(fHtsFull, temp)\n",
    "            else:\n",
    "                result = np.empty(fHtsFull.shape, dtype=fHtsFull.dtype)\n",
    "                result[:,0] = fHtsFull[:,0].conj()*temp\n",
    "                for i in range(1,fHtsFull.shape[1]):\n",
    "                    result[:,i] = (fHtsFull[:,fHtsFull.shape[1]-i].conj()*temp)\n",
    "            return result\n",
    "\n",
    "    def _MirrorYArray(self, fHtsFull):\n",
    "        padLength = self.fshape[1] - self.s2[1]\n",
    "        if False:\n",
    "            fHtsFull = fHtsFull.conj() * np.exp(1j * (1+padLength) * 2*np.pi / self.fshape[1] * np.arange(self.fshape[1],dtype='complex64'))\n",
    "            fHtsFull[1::] = fHtsFull[1::][::-1]\n",
    "            return fHtsFull\n",
    "        else:\n",
    "            temp = np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[1]) * np.arange(self.fshape[1])).astype('complex64')\n",
    "            if True:\n",
    "                result = jps.mirrorY(fHtsFull, temp)\n",
    "            else:\n",
    "                result = np.empty(fHtsFull.shape, dtype=fHtsFull.dtype)\n",
    "                result[0] = fHtsFull[0].conj()*temp\n",
    "                for i in range(1,fHtsFull.shape[0]):\n",
    "                    result[i] = (fHtsFull[fHtsFull.shape[0]-i].conj()*temp)\n",
    "            return result\n",
    "        \n",
    "    def _convolvePart3(self, projection, bb, aa, fHtsFull, mirrorX, accum):\n",
    "        # TODO: to make this work, I need the full matrix for fHts and then I need to slice it \n",
    "        # to the correct shape when I call through to special_fftconvolve here. Is fshape what I need?\n",
    "        cpu0 = cpuTime('both')\n",
    "        (accum,_,_,_) = _special_fftconvolve(projection,bb,aa,self.Nnum,self.s2,accum,fb=fHtsFull[self.rfslice])\n",
    "        self.cpuTime += cpuTime('both')-cpu0\n",
    "        if mirrorX:\n",
    "            fHtsFull = self._MirrorXArray(fHtsFull)\n",
    "            cpu0 = cpuTime('both')\n",
    "            (accum,_,_,_) = _special_fftconvolve(projection,self.Nnum-bb-1,aa,self.Nnum,self.s2,accum,fb=fHtsFull[self.rfslice]) \n",
    "            self.cpuTime += cpuTime('both')-cpu0\n",
    "        return accum\n",
    "\n",
    "    def _convolvePart2(self, projection, bb, aa, fHtsFull, mirrorY, mirrorX, accum):\n",
    "        accum = self._convolvePart3(projection,bb,aa,fHtsFull,mirrorX,accum)\n",
    "        if mirrorY:\n",
    "            fHtsFull = self._MirrorYArray(fHtsFull)\n",
    "            accum = self._convolvePart3(projection,bb,self.Nnum-aa-1,fHtsFull,mirrorX,accum)\n",
    "        return accum\n",
    "\n",
    "    def _convolve(self, projection, hMatrix, cc, bb, aa, backwards, accum):\n",
    "        cent = int(self.Nnum/2)\n",
    "\n",
    "        mirrorX = (bb != cent)\n",
    "        mirrorY = (aa != cent)\n",
    "        transpose = ((aa != bb) and (aa != (self.Nnum-bb-1)))\n",
    "            \n",
    "        # TODO: it would speed things up if I could avoid computing the full fft for Hts.\n",
    "        # However, it's not immediately clear to me how to fill out the full fftn array from rfftn\n",
    "        # in the case of a 2D transform.\n",
    "        # For 1D it's the reversed conjugate, but for 2D it's more complicated than that.\n",
    "        # It's possible that it's actually nontrivial, in spite of the fact that\n",
    "        # you can get away without it when only computing fft/ifft for real arrays)\n",
    "        fHtsFull = hMatrix.fH(cc, bb, aa, backwards, False, self.fshape)\n",
    "        accum = self._convolvePart2(projection,bb,aa,fHtsFull,mirrorY,mirrorX, accum)\n",
    "        if transpose:\n",
    "            if (self.fshape[0] == self.fshape[1]):\n",
    "                # For a square array, the FFT of the transpose is just the transpose of the FFT.\n",
    "                # The copy() is because my C code currently can't cope with\n",
    "                # a transposed array (non-contiguous strides in x)\n",
    "                fHtsFull = fHtsFull.transpose().copy()    \n",
    "            else:\n",
    "                # For a non-square array, we have to compute the FFT for the transpose.\n",
    "                fHtsFull = hMatrix.fH(cc, bb, aa, backwards, True, self.fshape)\n",
    "\n",
    "            # Note that mx,my need to be swapped following the transpose\n",
    "            accum = self._convolvePart2(projection,aa,bb,fHtsFull,mirrorX,mirrorY, accum) \n",
    "        assert(accum.dtype == np.complex64)   # Keep an eye out for any reversion to double-precision\n",
    "        return accum\n",
    "    \n",
    "def _projectForZY(cc, bb, source, hMatrix, backwards):\n",
    "    f = open('perf_diags/%d_%d.txt'%(cc,bb), \"w\")\n",
    "    t1 = time.time()\n",
    "    singleJob = (len(source.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        source = source[np.newaxis,:,:]\n",
    "    result = None\n",
    "    projector = _Projector(source[0], hMatrix, cc)\n",
    "    projector.cpuTime = np.zeros(2)\n",
    "    for aa in range(bb,int((Nnum+1)/2)):\n",
    "        result = projector._convolve(source, hMatrix, cc, bb, aa, backwards, result)\n",
    "    t2 = time.time()\n",
    "    assert(result.dtype == np.complex64)   # Keep an eye out for any reversion to double-precision\n",
    "    f.write('%d\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (os.getpid(), t1, t2, t2-t1, projector.cpuTime[0], projector.cpuTime[1]))\n",
    "    f.close()\n",
    "    if singleJob:\n",
    "        return (result[0], cc, bb, t2-t1)\n",
    "    else:\n",
    "        return (np.array(result), cc, bb, t2-t1)\n",
    "    \n",
    "def projectForZ2(hMatrix, backwards, cc, source):\n",
    "    result = None\n",
    "    for bb in tqdm(hMatrix.IterableBRange(cc), leave=False, desc='Project - y'):\n",
    "        (thisResult, _, _, _) = _projectForZY(cc, bb, source, hMatrix, backwards)\n",
    "        if (result is None):\n",
    "            result = thisResult\n",
    "        else:\n",
    "            result += thisResult\n",
    "    # Actually, for forward projection we don't need to do this separately for every z,\n",
    "    # but it's easier to do it for symmetry (and this function is not used in performance-critical code anyway)\n",
    "    (fshape, fslice, s1) = convolutionShape(source, hMatrix.PSFShape(cc), hMatrix.Nnum(cc))\n",
    "    return special_fftconvolve_part3(result, fshape, fslice, s1)\n",
    "    \n",
    "# Test the backprojection code against a slower definitive version\n",
    "# (this code is here for now because this is where I have been working on stuff, but it could move)\n",
    "# TODO: would be a better test if I use the hMatrix form of projectForZ\n",
    "#testHtCC = np.random.random((5,5,30,30)).astype(np.float32)\n",
    "#testHtCC = _Ht[13,int(_Ht.shape[1]/2)-2:int(_Ht.shape[1]/2)+3,int(_Ht.shape[2]/2)-2:int(_Ht.shape[2]/2)+3,_CAindex[0,13]-1:_CAindex[1,13], _CAindex[0,13]-1:_CAindex[1,13]]\n",
    "testHCC = _H[13]\n",
    "testHtCC = _Ht[13]\n",
    "\n",
    "for fd in [False, True]:\n",
    "    for shape in [(200,200), (200,300), (300,200)]:\n",
    "        # Test both square and non-square, since they use different code\n",
    "        testHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=13)  # Needs to be in here because caching is confused by changing the image shape\n",
    "        testProjection = np.random.random(shape).astype(np.float32)\n",
    "        if fd:\n",
    "            testResultOld = forwardProjectForZ_old(testHCC, testProjection)\n",
    "            testResultNew = projectForZ2(testHMatrix, False, 0, testProjection)\n",
    "        else:\n",
    "            testResultOld = backwardProjectForZ_old(testHtCC, testProjection)\n",
    "            testResultNew = projectForZ2(testHMatrix, True, 0, testProjection)\n",
    "        comparison = np.max(np.abs(testResultOld - testResultNew))\n",
    "        print('test result (should be <<1): %e' % comparison)\n",
    "        if (comparison > 1e-4):\n",
    "            print(\" -> WARNING: disagreement detected\")\n",
    "        else:\n",
    "            print(\" -> OK\")\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def backwardProjectACC(hMatrix, projection, planes=None, numjobs=multiprocessing.cpu_count(), progress=tqdm, logPrint=True):\n",
    "    singleJob = (len(projection.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        projection = projection[np.newaxis,:,:]\n",
    "    if planes is None:\n",
    "        planes = range(hMatrix.numZ)\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "\n",
    "    ru1 = cpuTime('both')\n",
    "\n",
    "    Backprojection = np.zeros((hMatrix.numZ, projection.shape[0], projection.shape[1], projection.shape[2]), dtype='float32')\n",
    "        \n",
    "    # Set up the work to iterate over each z plane\n",
    "    work = []\n",
    "    for cc in planes:\n",
    "        for bb in hMatrix.IterableBRange(cc):\n",
    "            work.append((cc, bb, projection, hMatrix, True))\n",
    "\n",
    "    # Run the multithreaded work\n",
    "    t0 = time.time()\n",
    "    results = Parallel(n_jobs=numjobs)\\\n",
    "            (delayed(_projectForZY)(*args) for args in progress(work, desc='Back-project - z', leave=False))\n",
    "    ru2 = cpuTime('both')\n",
    "\n",
    "    # Gather together and sum the results for each z plane\n",
    "    t1 = time.time()\n",
    "    fourierZPlanes = [None]*hMatrix.numZ\n",
    "    elapsedTime = 0\n",
    "    for (result, cc, bb, t) in results:\n",
    "        elapsedTime += t\n",
    "        if fourierZPlanes[cc] is None:\n",
    "            fourierZPlanes[cc] = result\n",
    "        else:\n",
    "            fourierZPlanes[cc] += result\n",
    "    \n",
    "    # Compute the FFT for each z plane\n",
    "    for cc in planes:\n",
    "        # A bit complicated here to set up the correct inputs for convolutionShape...\n",
    "        (fshape, fslice, s1) = convolutionShape(projection, hMatrix.PSFShape(cc), hMatrix.Nnum(cc))\n",
    "        Backprojection[cc] = special_fftconvolve_part3(fourierZPlanes[cc], fshape, fslice, s1)        \n",
    "    t2 = time.time()\n",
    "    assert(Backprojection.dtype == np.float32)   # Keep an eye out for any reversion to double-precision\n",
    "   \n",
    "    # Save some diagnostics\n",
    "    if logPrint:\n",
    "        print('work elapsed wallclock time %f'%(t1-t0))\n",
    "        print('work elapsed thread time %f'%elapsedTime)\n",
    "        print('work delta rusage:', ru2-ru1)\n",
    "        print('FFTs took %f'%(t2-t1))\n",
    "    \n",
    "    f = open('overall.txt', 'w')\n",
    "    f.write('%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (t0, t1, t1-t0, t2-t1, (ru2-ru1)[0], (ru2-ru1)[1]))\n",
    "    f.close()\n",
    "\n",
    "    if singleJob:\n",
    "        return Backprojection[:,0]\n",
    "    else:\n",
    "        return Backprojection\n",
    "\n",
    "def forwardProjectACC(hMatrix, realspace, planes=None, numjobs=multiprocessing.cpu_count(), progress=tqdm, logPrint=True):\n",
    "    singleJob = (len(realspace.shape) == 3)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        realspace = realspace[:,np.newaxis,:,:]\n",
    "    if planes is None:\n",
    "        planes = range(hMatrix.numZ)\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "\n",
    "    # Set up the work to iterate over each z plane\n",
    "    work = []\n",
    "    for cc in planes:\n",
    "        for bb in hMatrix.IterableBRange(cc):\n",
    "            work.append((cc, bb, realspace[cc], hMatrix, False))\n",
    "\n",
    "    # Run the multithreaded work\n",
    "    t0 = time.time()\n",
    "    results = Parallel(n_jobs=numjobs)\\\n",
    "                (delayed(_projectForZY)(*args) for args in progress(work, desc='Forward-project - z', leave=False))\n",
    "\n",
    "    # Gather together and sum all the results\n",
    "    t1 = time.time()\n",
    "    fourierProjection = [None]*hMatrix.numZ\n",
    "    elapsedTime = 0\n",
    "    for (result, cc, bb, t) in results:\n",
    "        elapsedTime += t\n",
    "        if fourierProjection[cc] is None:\n",
    "            fourierProjection[cc] = result\n",
    "        else:\n",
    "            fourierProjection[cc] += result\n",
    "\n",
    "    # Compute and accumulate the FFT for each z plane\n",
    "    TOTALprojection = None\n",
    "    for cc in planes:\n",
    "        # A bit complicated here to set up the correct inputs for convolutionShape...\n",
    "        (fshape, fslice, s1) = convolutionShape(realspace[cc], hMatrix.PSFShape(cc), hMatrix.Nnum(cc))\n",
    "        thisProjection = special_fftconvolve_part3(fourierProjection[cc], fshape, fslice, s1)        \n",
    "        if TOTALprojection is None:\n",
    "            TOTALprojection = thisProjection\n",
    "        else:\n",
    "            TOTALprojection += thisProjection\n",
    "    t2 = time.time()\n",
    "    assert(TOTALprojection.dtype == np.float32)   # Keep an eye out for any reversion to double-precision\n",
    "            \n",
    "    # Print out some diagnostics\n",
    "    if (logPrint):\n",
    "        print('work elapsed wallclock time %f'%(t1-t0))\n",
    "        print('work elapsed thread time %f'%elapsedTime)\n",
    "        print('FFTs took %f'%(t2-t1))\n",
    "        \n",
    "    if singleJob:\n",
    "        return TOTALprojection[0]\n",
    "    else:\n",
    "        return TOTALprojection\n",
    "\n",
    "if False:\n",
    "    # Temporary call to test parallelization\n",
    "    temp = backwardProjectACC(hMatrix, inputImage, planes=[0], numjobs=3)\n",
    "    \n",
    "if True:\n",
    "    # Temporary code to test running with an image pair\n",
    "    # This is maybe not a comprehensive test, but it run with two different (albeit proportional)\n",
    "    # images and checks that the result matches the result for two totally independent calls on a single array.\n",
    "    hMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape)\n",
    "    candidate = np.tile(inputImage[np.newaxis,:,:], (2,1,1))\n",
    "    candidate[1] *= 1.4\n",
    "    planesToUse = None\n",
    "    planesToUse = range(3,4)\n",
    "    if planesToUse is None:\n",
    "        numPlanesToUse = hMatrix.numZ\n",
    "    else:\n",
    "        numPlanesToUse = len(planesToUse)\n",
    "    print('Running (%d planes x2)'%numPlanesToUse)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    temp = backwardProjectACC(hMatrix, candidate, planes=planesToUse, numjobs=1, progress=None)\n",
    "    print('New method took', time.time()-t1)\n",
    "\n",
    "    print('Running (%d planes x10)'%numPlanesToUse)\n",
    "    t1 = time.time()\n",
    "    temp = backwardProjectACC(hMatrix, np.tile(candidate, (5,1,1)), planes=planesToUse, numjobs=1, progress=None)\n",
    "    print('New method took', time.time()-t1)\n",
    "\n",
    "    # This is just backprojecting the first image, rather than the image image pair,\n",
    "    # so is doing half the amount of work\n",
    "    t1 = time.time()\n",
    "    temp2 = backwardProjectACC_original(_H, candidate[0], _CAindex, planes=planesToUse, progress=None)\n",
    "    print('Old method took', time.time()-t1)\n",
    "\n",
    "\n",
    "    dualRoundtrip = forwardProjectACC(hMatrix, temp, planes=planesToUse)\n",
    "\n",
    "    temp = backwardProjectACC(hMatrix, candidate[0], planes=planesToUse, numjobs=1)\n",
    "    firstRoundtrip = forwardProjectACC(hMatrix, temp, planes=planesToUse, numjobs=1)    \n",
    "    comparison = np.max(np.abs(firstRoundtrip - dualRoundtrip[0]))\n",
    "    print('test result (should be <<1): %e' % comparison)\n",
    "    if (comparison > 1e-6):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")\n",
    "    \n",
    "    temp = backwardProjectACC(hMatrix, candidate[1], planes=planesToUse, numjobs=1)\n",
    "    secondRoundtrip = forwardProjectACC(hMatrix, temp, planes=planesToUse, numjobs=1)    \n",
    "    comparison = np.max(np.abs(secondRoundtrip - dualRoundtrip[1]))\n",
    "    print('test result (should be <<1): %e' % comparison)\n",
    "    if (comparison > 1e-6):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def AnalyzeTestResults():\n",
    "    with open('overall.txt') as f:\n",
    "        csv_reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            pass\n",
    "    startTime = float(row[0])\n",
    "    endTime = float(row[1])\n",
    "    userTime = float(row[4])\n",
    "    sysTime = float(row[5])\n",
    "\n",
    "    rows = []\n",
    "    for fn in glob.glob('perf_diags/*_*.txt'):\n",
    "        with open(fn) as f:\n",
    "            csv_reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in csv_reader:\n",
    "                pass\n",
    "            rows.append(row)\n",
    "    rows = np.array(rows).astype('float').transpose()\n",
    "    firstPid = np.min(rows[0])\n",
    "    rows[0] -= firstPid\n",
    "    rows[1:3] -= startTime\n",
    "    rows = rows[:,np.argsort(rows[1],kind='mergesort')]\n",
    "    rows = rows[:,rows[0].argsort(kind='mergesort')]\n",
    "\n",
    "    deadTimeStart = 0\n",
    "    deadTimeMid = 0\n",
    "    deadTimeEnd = 0\n",
    "    threadWorkTime = 0\n",
    "    thisThreadStartTime = 0\n",
    "    longestThreadRunTime = 0\n",
    "    longestThreadRunPid = -1\n",
    "    latestStartTime = 0\n",
    "    userTimeBreakdown = 0\n",
    "    sysTimeBreakdown = 0\n",
    "    for i in range(rows.shape[1]):\n",
    "        pid = rows[0,i]\n",
    "        t0 = rows[1,i]\n",
    "        t1 = rows[2,i]\n",
    "        userTimeBreakdown += rows[4,i]\n",
    "        sysTimeBreakdown += rows[5,i]\n",
    "        if (i == 0):\n",
    "            deadTimeStart += t0\n",
    "            thisThreadStartTime = t0\n",
    "            latestStartTime = t0\n",
    "        else:\n",
    "            if (pid == rows[0,i-1]):\n",
    "                deadTimeMid += t0 - rows[2,i-1]\n",
    "            else:\n",
    "                latestStartTime = max(latestStartTime, t0)\n",
    "                thisThreadRunTime = rows[2,i-1]-thisThreadStartTime  # For previous pid\n",
    "                if (thisThreadRunTime > longestThreadRunTime):\n",
    "                    longestThreadRunPid = rows[0,i-1]\n",
    "                    longestThreadRunTime = thisThreadRunTime\n",
    "                thisThreadStartTime = t0\n",
    "                deadTimeStart += t0\n",
    "                deadTimeEnd += (endTime-startTime) - rows[2,i-1]\n",
    "        threadWorkTime += t1-t0\n",
    "        plt.plot([t0, t1], [pid, pid])\n",
    "        plt.plot(t0, pid, 'x')\n",
    "    thisThreadRunTime = t1-thisThreadStartTime\n",
    "    if (thisThreadRunTime > longestThreadRunTime):\n",
    "        longestThreadRunPid = pid\n",
    "        longestThreadRunTime = thisThreadRunTime\n",
    "    deadTimeEnd += (endTime-startTime) - rows[2,-1]\n",
    "    print('Elapsed time', endTime-startTime)\n",
    "    print('Longest thread run time', longestThreadRunTime, 'pid', int(longestThreadRunPid))\n",
    "    print('Latest start time', latestStartTime)\n",
    "    print('Thread work time', threadWorkTime)\n",
    "    print('Dead time', deadTimeStart, deadTimeMid, deadTimeEnd)\n",
    "    print(' Total', deadTimeStart + deadTimeMid + deadTimeEnd)\n",
    "    print('User cpu time', userTime)\n",
    "    print('System cpu time', sysTime)\n",
    "    print('User cpu time for subset', userTimeBreakdown)\n",
    "    print('System cpu time for subset', sysTimeBreakdown)\n",
    "\n",
    "    with open('stats.txt', 'a') as f:\n",
    "        f.write('%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (numJobsForTesting, endTime-startTime, threadWorkTime, \\\n",
    "                        longestThreadRunTime, latestStartTime, deadTimeStart, deadTimeMid, deadTimeEnd, userTime, sysTime))\n",
    "\n",
    "    plt.xlim(0, endTime-startTime)\n",
    "    plt.ylim(-0.5,np.max(rows[0])+0.5)\n",
    "    plt.show()\n",
    "    \n",
    "if False:\n",
    "    for numJobsForTesting in range(1,13):\n",
    "        ru1 = cpuTime('both')\n",
    "        temp = backwardProjectACC(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), inputImage, numjobs=numJobsForTesting, planes=None)\n",
    "        ru2 = cpuTime('both')\n",
    "        print('overall delta rusage:', ru2-ru1)\n",
    "        AnalyzeTestResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomment(csvfile):\n",
    "    for row in csvfile:\n",
    "        raw = row.split('#')[0].strip()\n",
    "        if raw: yield raw\n",
    "\n",
    "def AnalyzeTestResults2(fn):\n",
    "    rows = []\n",
    "    with open(fn) as f:\n",
    "        csv_reader = csv.reader(decomment(f), delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "    rows = np.array(rows).astype(np.float).transpose()\n",
    "\n",
    "    plt.plot(rows[0], rows[2]/rows[2,0], label='work time')\n",
    "    plt.plot(rows[0], np.sum(rows[5:8], axis=0)/(rows[0]*rows[1]), label='dead time')\n",
    "    plt.plot(rows[0], rows[5]/(rows[0]*rows[1]), label='dead start')\n",
    "    plt.plot(rows[0], rows[1]/(rows[1,0]/rows[0]), label='runtime excess')\n",
    "    plt.ylim(0,2.5)\n",
    "    plt.legend(loc=2)\n",
    "    plt.show()\n",
    "\n",
    "plt.title('Dummy work on empty arrays')\n",
    "AnalyzeTestResults2('stats-dummy.txt')\n",
    "plt.title('Real work')\n",
    "AnalyzeTestResults2('stats-realwork.txt')\n",
    "plt.title('Smaller memory footprint - no improvement')\n",
    "AnalyzeTestResults2('stats-no-H.txt')\n",
    "plt.title('New code')\n",
    "AnalyzeTestResults2('stats-new-code.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a single backprojection and compare against definitive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(testHMatrix.cacheMisses, testHMatrix.cacheHits, testHMatrix.cacheSize)\n",
    "planesToProcess = None#range(6)\n",
    "if False:\n",
    "    t0 = time.time()\n",
    "    Htf = backwardProjectACC_original(_Ht, inputImage, _CAindex, planes=planesToProcess, progress=None)\n",
    "    print('Original code took %f'%(time.time()-t0))\n",
    "elif True:\n",
    "    # Profile my code (single-threaded) on a cropped version of Prevedel's data\n",
    "    myStats = cProfile.run('Htf = backwardProjectACC(testHMatrix, inputImage, planes=planesToProcess, numjobs=1, progress=None)', 'mystats')\n",
    "    p = pstats.Stats('mystats')\n",
    "    p.strip_dirs().sort_stats('cumulative').print_stats(40)\n",
    "elif False:\n",
    "    # Profile my code (single-threaded) in the sort of scenario I would expect to run it in for my PIV experiments\n",
    "    tempInputImage = np.zeros((2,Nnum*20,Nnum*20))\n",
    "    myStats = cProfile.run('temp = backwardProjectACC(testHMatrix, tempInputImage, planes=planesToProcess, numjobs=1)', 'mystats')\n",
    "    p = pstats.Stats('mystats')\n",
    "    p.strip_dirs().sort_stats('cumulative').print_stats(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against definitive version generated from Matlab\n",
    "try:\n",
    "    if planesToProcess is not None:\n",
    "        print('WARNING: the following test is not valid because not all planes were processed')\n",
    "    if False:\n",
    "        definitive = tifffile.imread('Data/03_Reconstructed/exampleData/definitive_worm_crop_X15_backproject.tif')\n",
    "        definitive = np.transpose(definitive, axes=(0,2,1))\n",
    "        comparison = np.max(np.abs(definitive[4] - Htf[4]*10))\n",
    "    else:\n",
    "        definitive = np.load('semi-definitive.npy')\n",
    "        comparison = np.max(np.abs(definitive - Htf))\n",
    "    print('Compare against matlab result (should be <1.0): %f' % comparison)\n",
    "    if (comparison > 1.0):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")\n",
    "except NameError:\n",
    "    warnings.warn('Cannot compare - previous cell was probably not run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a full deconvolution and compare against definitive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    Xguess = Htf.copy();\n",
    "    maxIter = 8\n",
    "    deconvolvedResult = deconvRL(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), Htf, maxIter, Xguess)\n",
    "else:\n",
    "    deconvolvedResult = 1   # Just set the variable to something so the next cell doesn't fail to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against definitive version generated from Matlab\n",
    "definitive = tifffile.imread('Data/03_Reconstructed/exampleData/definitive_worm_crop_X15_iter8.tif')\n",
    "definitive = np.transpose(definitive, axes=(0,2,1))\n",
    "comparison = np.max(np.abs(definitive - deconvolvedResult*1e3))\n",
    "print('Compare against matlab result (should be <1.0): %f' % comparison)\n",
    "if (comparison > 1.0):\n",
    "    print(\" -> WARNING: disagreement detected\")\n",
    "else:\n",
    "    print(\" -> OK\")\n",
    "\n",
    "#tifffile.imsave('iter8.tif', np.transpose(Xguess*1e3, axes=(0,2,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for flow field (single-plane toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two identical images of the same synthetic object,\n",
    "# which for now consists of a cloud of random gaussian spots\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "if False:\n",
    "    numSpots = 100\n",
    "    imageSize = 240\n",
    "    sigma = 8\n",
    "    controlPointSpacing = 30    \n",
    "elif False:\n",
    "    numSpots = 400\n",
    "    imageSize = 120\n",
    "    sigma = 2\n",
    "    controlPointSpacing = 30\n",
    "elif True:\n",
    "    numSpots = 1000\n",
    "    imageSize = 180\n",
    "    sigma = 2\n",
    "    controlPointSpacing = 30\n",
    "    previouslySavedSynthetic = '2019-06-24 14.02.53 syntheticInput.npy'\n",
    "elif True:\n",
    "    numSpots = 250\n",
    "    imageSize = 90\n",
    "    sigma = 1\n",
    "    controlPointSpacing = 15\n",
    "    previouslySavedSynthetic = '2019-06-24 14.32.19 syntheticInput.npy'\n",
    "\n",
    "syntheticImageExtendSize = 30\n",
    "\n",
    "syntheticObjectExt = np.zeros((1, imageSize+syntheticImageExtendSize, imageSize))\n",
    "syntheticObjectExt[0, (np.random.random(numSpots)*syntheticObjectExt.shape[1]).astype('int'), \\\n",
    "                      (np.random.random(numSpots)*syntheticObjectExt.shape[2]).astype('int')] = 1\n",
    "syntheticObjectExt = gaussian_filter(syntheticObjectExt, sigma=(0,sigma,sigma))\n",
    "plt.imshow(syntheticObjectExt[0])\n",
    "if False:\n",
    "    import datetime\n",
    "    fn = datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S syntheticInput.npy\")\n",
    "    np.save(fn, syntheticObjectExt[0])\n",
    "else:\n",
    "    syntheticObjectExt[0] = np.load(previouslySavedSynthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PSF that we will use\n",
    "\n",
    "# First check we're using the expected PSF - the plane choices used here are intended to work with this PSF.\n",
    "assert(matPath == 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat')\n",
    "\n",
    "zPlaneToModel = _H.shape[0]-1   # Modelling native focal plane\n",
    "zPlaneToModel = 22   # Modelling some way from the native focal plane, which should perform fairly well\n",
    "zPlaneToModel = _H.shape[0]-3   # Modelling close to native focal plane. This has artefacts - prev one is fairly artefact-free\n",
    "zPlaneToModel = _H.shape[0]-2\n",
    "\n",
    "pivHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=zPlaneToModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    shiftType = 'piv'\n",
    "    source = 'synthetic'\n",
    "    actualImageExtendSize = syntheticImageExtendSize\n",
    "    # Allowing an x search range is fairer, but it makes little difference for vertical flow\n",
    "    xMotionPermitted = False\n",
    "    xSearchRange = 0\n",
    "    ySearchRange = 10\n",
    "else:\n",
    "    shiftType = 'piv-zeroedge'\n",
    "    source = 'piv'\n",
    "    actualImageExtendSize = 0\n",
    "    xMotionPermitted = True\n",
    "    xSearchRange = 8\n",
    "    ySearchRange = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProjectACC_PIV(hMatrix, obj, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return forwardProjectACC(hMatrix, dualObject, logPrint=False, progress=None)\n",
    "\n",
    "def dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    # Compute the reverse transform given the AB images (B image shifted by shiftYX).\n",
    "    # First we do the reverse transformation on both images\n",
    "    dualObject = backwardProjectACC(hMatrix, dualProjection, logPrint=False, progress=None)\n",
    "    # Now we reverse the shift on the B object\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    # Now, ideally the objects would match, but of course in practice there will be discrepancies,\n",
    "    # especially if we are not using the correct shiftDescription.\n",
    "    # To make the operation match the transpose of the forward operation,\n",
    "    # we add the two objects and divide by 2 here\n",
    "    return dualObject\n",
    "\n",
    "def fusedBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def deconvRL_PIV_OLD(hMatrix, imageAB, maxIter, Xguess, shiftDescription):\n",
    "    # I believed this to be the RL algorithm in the way I have written it in the past.\n",
    "    # However, this gives different results to Prevedel's implementation\n",
    "    # (mine seems to converge more slowly).\n",
    "    # TODO: I should look into this and see if I've just made a mistake or if they are actually different.\n",
    "    \n",
    "    # Xguess is our single combined guess of the object\n",
    "    Xguess = Xguess.copy()    # Because we will be updating it, and caller may not always be expecting that\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        relativeBlurDual = imageAB / forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        Xguess *= fusedBackwardProjectACC_PIV(hMatrix, relativeBlurDual, shiftDescription)\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def deconvRL_PIV(hMatrix, imageAB, maxIter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    Htf = fusedBackwardProjectACC_PIV(hMatrix, imageAB, shiftDescription)\n",
    "    Xguess = Htf.copy()\n",
    "    print('Deconv')\n",
    "    for i in noProgressBar(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        HXguessBack = fusedBackwardProjectACC_PIV(hMatrix, HXguess, shiftDescription)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def RollNoninteger(obj, amount, axis=0):\n",
    "    intAmount = int(amount)\n",
    "    frac = amount - intAmount\n",
    "    result1 = np.roll(obj, intAmount, axis=axis)\n",
    "    result2 = np.roll(obj, intAmount+1, axis=axis)\n",
    "    return result1 * (1-frac) + result2 * frac\n",
    "\n",
    "\n",
    "# Some replacement functions to use for testing (effective PSF is a delta function, 1:1 mapping from image to object)\n",
    "def forwardProjectTrivial(hMatrix, obj, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return dualObject[0]\n",
    "\n",
    "def dualBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualProjection[np.newaxis].copy()\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    return dualObject\n",
    "\n",
    "def fusedBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def deconvRLTrivial(hMatrix, imageAB, maxIter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    return fusedBackwardProjectTrivial(hMatrix, imageAB, shiftDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (shiftType == 'uniform') or (shiftType == 'uniformSK'):\n",
    "    if shiftType == 'uniform':\n",
    "        def ShiftObject(obj, shiftYX):\n",
    "            # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "            # For now I just consider a uniform translation in xy\n",
    "            # \n",
    "            # TODO: We need to worry about conserving energy during the shift. \n",
    "            # For now I will do a circular shift in order to avoid having to worry about this!\n",
    "            result = RollNoninteger(obj, shiftYX[0,0], axis=len(obj.shape)-2)\n",
    "            return RollNoninteger(result, shiftYX[0,1], axis=len(obj.shape)-1)\n",
    "    else:\n",
    "        # A lot of code duplication here, but it's just an experiment for now\n",
    "        def ShiftObject(obj, shiftYX):\n",
    "            # Generate control points in the corners of the image\n",
    "            src_cols = np.arange(0, obj.shape[-1]+1, obj.shape[-1])\n",
    "            src_rows = np.arange(0, obj.shape[-2]+1, obj.shape[-2])\n",
    "            src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "            src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "            dst = src + shiftYX[0]\n",
    "            tform = PiecewiseAffineTransform()\n",
    "            tform.estimate(src, dst)\n",
    "            # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "            maxVal = np.max(np.abs(obj))\n",
    "            if len(obj.shape) == 3:\n",
    "                result = np.zeros(obj.shape)\n",
    "                for cc in range(obj.shape[0]):\n",
    "                    result[cc] = warp(obj[cc]/maxVal, tform, mode='edge') * maxVal\n",
    "                return result\n",
    "            else:\n",
    "                return warp(obj/maxVal, tform, mode='edge') * maxVal\n",
    "    \n",
    "    def ExampleShiftDescriptionForObject(obj):\n",
    "        return np.array([[-10, 20]])\n",
    "    \n",
    "    def VelocityShapeForObject(obj):\n",
    "        return (2,)\n",
    "\n",
    "    def IWCentresForObject(obj):\n",
    "        return np.array([[int(obj.shape[-2]/2), int(obj.shape[-1]/2)]])\n",
    "\n",
    "else:\n",
    "    # Arbitrary motion described in terms of an array of control points at IWCentresForObject\n",
    "    assert((shiftType == 'piv') or (shiftType == 'piv-zeroedge'))\n",
    "    def IWCentresForObject(obj, st=shiftType):\n",
    "        startPos = 0\n",
    "        # Reusing the code from the skimage example, since that actualy does what we need:\n",
    "        if st == 'piv-zeroedge':\n",
    "            src_cols = np.arange(controlPointSpacing, obj.shape[-1], controlPointSpacing)\n",
    "            src_rows = np.arange(controlPointSpacing, obj.shape[-2]-actualImageExtendSize, controlPointSpacing)\n",
    "        else:\n",
    "            src_cols = np.arange(startPos, obj.shape[-1]+1, controlPointSpacing)\n",
    "            src_rows = np.arange(startPos, obj.shape[-2]+1-actualImageExtendSize, controlPointSpacing)\n",
    "        src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "        return np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    def VelocityShapeForObject(obj):\n",
    "        return IWCentresForObject(obj).shape\n",
    "    \n",
    "    def ExampleShiftDescriptionForObject(obj):\n",
    "        peakVelocity = 7\n",
    "        iwPos = IWCentresForObject(obj)\n",
    "        shiftDescription = np.zeros(VelocityShapeForObject(obj))\n",
    "        width = obj.shape[-1]\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            quadraticProfile = ((width/2.)**2 - (iwPos[n,0]-width/2.)**2)\n",
    "            quadraticProfile = quadraticProfile / ((width/2.)**2) * peakVelocity\n",
    "            shiftDescription[n,1] = quadraticProfile\n",
    "        if xMotionPermitted:\n",
    "            return shiftDescription\n",
    "        else:\n",
    "            return shiftDescription[:,1:2]\n",
    "\n",
    "    def ExtraDuplicateRow(shifts, add=None):\n",
    "        assert(len(shifts.shape) == 2)\n",
    "        rowLength = int(np.sqrt(shifts.shape[0]))\n",
    "        shifts = np.reshape(shifts, (rowLength, rowLength, shifts.shape[1]))\n",
    "        toAppend = shifts[:,-1:,:].copy()\n",
    "        if add is not None:\n",
    "            toAppend += add\n",
    "        result = np.append(shifts, toAppend, axis=1)\n",
    "        return result.reshape(result.shape[0]*result.shape[1], result.shape[2])\n",
    "\n",
    "    def AddZeroEdgePadding(obj, src, shiftYX):\n",
    "        paddedSrc = IWCentresForObject(obj, st='piv')\n",
    "        paddedShifts = np.zeros(paddedSrc.shape)\n",
    "        for i in range(src.shape[0]):\n",
    "            match = False\n",
    "            for j in range(paddedSrc.shape[0]):\n",
    "                if (src[i] == paddedSrc[j]).all():\n",
    "                    match = True\n",
    "                    paddedShifts[j] = shiftYX[i]\n",
    "            assert(match)\n",
    "        return paddedSrc, paddedShifts\n",
    "        \n",
    "    def ShiftObject(obj, shiftYX):\n",
    "        # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "        # I use a piecewise affine transformation that should approximately correspond to\n",
    "        # what I use for PIV analysis\n",
    "        src = IWCentresForObject(obj)\n",
    "        if (src.shape[0] != shiftYX.shape[0]):\n",
    "            print(src.shape, shiftYX.shape, obj.shape)\n",
    "            assert(src.shape[0] == shiftYX.shape[0])\n",
    "            \n",
    "        if (shiftType == 'piv-zeroedge'):\n",
    "            (src, shiftYX) = AddZeroEdgePadding(obj, src, shiftYX)\n",
    "        \n",
    "        if (actualImageExtendSize > 0):\n",
    "            src = ExtraDuplicateRow(src, add=np.array([0, actualImageExtendSize]))\n",
    "            if xMotionPermitted:\n",
    "                dst = src + ExtraDuplicateRow(shiftYX)\n",
    "            else:\n",
    "                dst = src.copy().astype(shiftYX.dtype)\n",
    "                dst[:,1] = dst[:,1] + ExtraDuplicateRow(shiftYX)[:,0]\n",
    "        else:\n",
    "            dst = src.copy().astype(shiftYX.dtype) + shiftYX\n",
    "            \n",
    "        tform = PiecewiseAffineTransform()\n",
    "        tform.estimate(src, dst)\n",
    "        # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "        maxVal = np.max(np.abs(obj))\n",
    "        if len(obj.shape) == 3:\n",
    "            result = np.zeros(obj.shape)\n",
    "            for cc in range(obj.shape[0]):\n",
    "                result[cc] = warp(obj[cc]/maxVal, tform, mode='edge') * maxVal\n",
    "            return result\n",
    "        else:\n",
    "            assert(len(obj.shape) == 2)\n",
    "            return warp(obj/maxVal, tform, mode='edge') * maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if source == 'synthetic':\n",
    "    # Generate a synthetic shift in the B image\n",
    "    dualObject = np.tile(syntheticObjectExt[:,np.newaxis,:,:], (1,2,1,1)) *1e3#* 1e7\n",
    "    if False:\n",
    "        warnings.warn('Loading previously-saved dualObject')\n",
    "        dualObject = np.load('dualObject5.npy')\n",
    "    \n",
    "    shiftDescription = ExampleShiftDescriptionForObject(dualObject)\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "\n",
    "    # Since I am only using a local minimizer, we need to start with a decent guess as to the flow.\n",
    "    # I think that's ok though: we should have that from a PIV estimate on the with-artefacts AB images\n",
    "    #initialShiftGuess = np.zeros(VelocityShapeForObject(dualObject))\n",
    "    initialShiftGuess = shiftDescription + np.random.random(shiftDescription.shape) * 4.0\n",
    "else:\n",
    "    assert(source == 'piv')\n",
    "    pivImagePair = tifffile.imread('piv-raw-data/038298.tif')[24:26,:15*20,:15*16].astype('float64')\n",
    "    # Note: frames 57-58 (wrong pair) would be an option to investigate bigger motion (~16px) with imperfect AB matches\n",
    "    #              64-65 (correct pair) are another example of small movement (0-3px)\n",
    "    dualObject = pivImagePair[np.newaxis]\n",
    "    # For now, I just guess an initial shift of zero\n",
    "    shiftDescription = np.zeros(VelocityShapeForObject(dualObject)).astype('float64')\n",
    "    initialShiftGuess = shiftDescription.copy()\n",
    "    \n",
    "    \n",
    "lb = []\n",
    "ub = []\n",
    "if xMotionPermitted:\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-xSearchRange, shiftDescription[n,1]-ySearchRange])\n",
    "        ub.extend([shiftDescription[n,0]+xSearchRange, shiftDescription[n,1]+ySearchRange])\n",
    "else:\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-ySearchRange])\n",
    "        ub.extend([shiftDescription[n,0]+ySearchRange])\n",
    "shiftSearchBounds = scipy.optimize.Bounds(lb, ub, True)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dualObject[0,0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dualObject[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used for investigations in which I directly warp the input object/images,\n",
    "# without any use of light field PSFs and deconvolution\n",
    "\n",
    "def ScoreShift2(candidateShiftYX, method, imageAB, hMatrix=None, shiftHistory=None, scaling=1.0, log=True, comparator=None, maxIter=8):\n",
    "    return ScoreShift3(candidateShiftYX, method, imageAB, hMatrix, shiftHistory, scaling, log, comparator, maxIter=maxIter)[0]\n",
    "\n",
    "def ScoreShift3(candidateShiftYX, method, imageAB, hMatrix=None, shiftHistory=None, scaling=1.0, log=True, comparator=None, maxIter=8):\n",
    "    # Our input parameters get flattened, so we need to reshape them to Nx2 like my code is expecting\n",
    "    # 'scaling' is useful for optimizers that insist on initial very small step sizes\n",
    "    if xMotionPermitted:\n",
    "        candidateShiftYX = candidateShiftYX.reshape(int(candidateShiftYX.shape[0]/2),2) * scaling\n",
    "    else:\n",
    "        candidateShiftYX = candidateShiftYX.reshape(candidateShiftYX.shape[0],1) * scaling\n",
    "    # Sanity check and reminder that we have a 2xMxN AB image pair\n",
    "    assert(len(imageAB.shape) == 3)  \n",
    "    assert(imageAB.shape[0] == 2)\n",
    "        \n",
    "    if log:\n",
    "#        print('======== Score shift ========', candidateShiftYX.T)\n",
    "#        print('======== Score shift ========')\n",
    "        pass\n",
    "\n",
    "    if method == 'joint':\n",
    "        # Perform the joint deconvolution to recover a single object\n",
    "        res = deconvRL_PIV(hMatrix, imageAB, maxIter=maxIter, shiftDescription=candidateShiftYX)\n",
    "        # Evaluate how well the forward-projected result matches the actual camera images, using SSD\n",
    "        candidateImageAB = forwardProjectACC_PIV(hMatrix, res, candidateShiftYX)\n",
    "    elif method == 'joint-test-trivial':\n",
    "        # Debugging method in which I use trivial projectors that behave like a delta function PSF\n",
    "        res = deconvRLTrivial(hMatrix, imageAB, maxIter=maxIter, shiftDescription=candidateShiftYX)\n",
    "        candidateImageAB = forwardProjectTrivial(hMatrix, res, candidateShiftYX)\n",
    "    else:\n",
    "        # Just warp the raw B image manually and look at how the two images compare\n",
    "        assert(method == 'naive')\n",
    "        candidateImageAB = imageAB.copy()\n",
    "        # A bit of dimensional gymnastics here, because ShiftObject expects an *object*,\n",
    "        # i.e. a 3D volume, whereas in this case we just have a 2D image\n",
    "        candidateImageAB[1,:,:] = ShiftObject(candidateImageAB[np.newaxis,0,:,:], candidateShiftYX)[0]  \n",
    "        res = None  # So that we have something to return\n",
    "    # Sanity check and reminder that we have a 2xMxN AB image pair\n",
    "    assert(len(candidateImageAB.shape) == 3)  \n",
    "    assert(candidateImageAB.shape[0] == 2)\n",
    "\n",
    "    imageToScore = candidateImageAB[:, 1:-1-actualImageExtendSize, 1:-1-actualImageExtendSize]\n",
    "    referenceImage = imageAB[:, 1:-1-actualImageExtendSize, 1:-1-actualImageExtendSize]\n",
    "    # Score by comparing the A and B images to the ones we are optimizing on.\n",
    "    # Note: in some simulated or naive cases, the A camera images will always be a perfect match,\n",
    "    # but for the real case the joint solution will be a compromise for both the A and B camera images.\n",
    "    #\n",
    "    # I have tried to renormalize to aid comparison between the images - based on the relative intensity\n",
    "    # of the candidate and observed A images. I chose the A images because they will be identical in the case\n",
    "    # of the 'naive' method (direct warping). However, for the 'joint' method they won't be.\n",
    "    # TODO: I need to think more about whether this normalization is necessary and appropriate.\n",
    "    # (I think I introduced it in the hope of fixing a problem,\n",
    "    # but lack of normalization wasn't the fundamental issue in the end)\n",
    "    renormHack = np.average(candidateImageAB[0]) / np.average(imageAB[0])\n",
    "    ssdScore = np.sum((imageToScore/renormHack - referenceImage)**2)\n",
    "\n",
    "    if comparator is not None:\n",
    "        maxLoc = np.argmax(np.abs(imageToScore - comparator)[1:-1,1:-1])\n",
    "        maxVal =    np.max(np.abs(imageToScore - comparator)[1:-1,1:-1])\n",
    "        print('showing B image diffs')\n",
    "        plt.imshow((imageToScore[1] - comparator)[170:,150:])\n",
    "        plt.colorbar()\n",
    "        plt.title('BRel (max %e)'%maxVal)\n",
    "        print('Max val %f at %d (image scale %d)' % (maxVal, maxLoc, np.max(comparator)))\n",
    "        plt.show()\n",
    "\n",
    "    if shiftHistory is not None:\n",
    "        shiftHistory.Update(candidateShiftYX, ssdScore)\n",
    "        if log:\n",
    "            if shiftHistory.PlotHistory(onlyPlotEvery=50):\n",
    "                if method == 'joint':\n",
    "                    dualObject = np.tile(res[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "                    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "                    ShowDualObjectAndFlow(dualObject, candidateShiftYX)\n",
    "                else:\n",
    "                    ShowDualObjectAndFlow(candidateImageAB, candidateShiftYX)\n",
    "                print('Last trial shift: ', candidateShiftYX.T)\n",
    "\n",
    "    if log:\n",
    "        #print('return %e' % ssdScore)\n",
    "        pass\n",
    "    return (ssdScore, renormHack, np.average(candidateImageAB[0]), np.average(imageAB), candidateImageAB, res)\n",
    "\n",
    "def ShowDualObjectAndFlow(dualObject, shiftDescription, otherObject=None, otherObject2=None, destFilename=None, suppressDark=0, histogram=0):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if (len(dualObject.shape) == 4):\n",
    "        assert(dualObject.shape[1] == 2)\n",
    "        plt.imshow(dualObject[0,0])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(dualObject[0,1])\n",
    "        windowSource = dualObject[0,0]\n",
    "    else:\n",
    "        assert(len(dualObject.shape) == 3)  # It's actually a dual image not an object\n",
    "        assert(dualObject.shape[0] == 2)\n",
    "        plt.imshow(dualObject[1])\n",
    "        windowSource = dualObject[0]\n",
    "    iwPos = IWCentresForObject(dualObject)\n",
    "    velocities = []\n",
    "    for n in range(iwPos.shape[0]):\n",
    "        aWindow = windowSource[np.maximum(iwPos[n,1]-int(controlPointSpacing/2),0):np.minimum(iwPos[n,1]+int(controlPointSpacing/2),dualObject.shape[-2]),\\\n",
    "                                   np.maximum(iwPos[n,0]-int(controlPointSpacing/2),0):np.minimum(iwPos[n,0]+int(controlPointSpacing/2),dualObject.shape[-1])]\n",
    "        if (aWindow.sum() > suppressDark):\n",
    "            if xMotionPermitted == False:\n",
    "                velocities.append(shiftDescription[n,0])\n",
    "                plt.plot([iwPos[n,0], iwPos[n,0]], \\\n",
    "                         [iwPos[n,1], iwPos[n,1] - shiftDescription[n,0]/2.], color='red')\n",
    "            else:\n",
    "                velocities.append(np.sqrt(shiftDescription[n,0]**2 + shiftDescription[n,1]**2))\n",
    "\n",
    "                plt.plot([iwPos[n,0], iwPos[n,0] - shiftDescription[n,0]/2.], \\\n",
    "                         [iwPos[n,1], iwPos[n,1] - shiftDescription[n,1]/2.], color='red')\n",
    "    plt.xlim(0, dualObject.shape[-1])\n",
    "    plt.ylim(dualObject.shape[-2], 0)\n",
    "    if destFilename is not None:\n",
    "        plt.savefig(destFilename, dpi=200)\n",
    "    plt.show()\n",
    "    if (histogram > 0):\n",
    "        plt.hist(velocities, range=(0,histogram), bins=20)\n",
    "        plt.show()\n",
    "    if otherObject is not None:\n",
    "        plt.imshow(otherObject[0])\n",
    "        plt.show()        \n",
    "    if otherObject2 is not None:\n",
    "        plt.imshow(otherObject2[0])\n",
    "        plt.show()   \n",
    "    return np.array(velocities)\n",
    "        \n",
    "def CheckConvergence(funcToCall, convergedShift, args):\n",
    "    initialScore = funcToCall(convergedShift.flatten(), *args)\n",
    "    print('initial score %e' % initialScore)\n",
    "    for du in [0.5, -0.5, 1.5, -1.5]:\n",
    "        for n in [7, 8, 12, 13]:\n",
    "            temp = convergedShift.copy()\n",
    "            temp[n] += du\n",
    "            score = funcToCall(temp, *args)\n",
    "            print('offset score %e' % score)\n",
    "            if (score < initialScore):\n",
    "                print(n, du, 'BETTER! (by %f%%)' % ((initialScore-score)/score*100))\n",
    "\n",
    "def ReportOnOptimizerConvergence(shiftHistory, method, obj, hMatrix=None):\n",
    "    if shiftHistory is None:\n",
    "        print('ReportOnOptimizerConvergence returning - called with shiftHistory=None')\n",
    "        return\n",
    "    bestShift = shiftHistory.BestShift()\n",
    "    print('Best score: %e' % shiftHistory.BestScore())\n",
    "    print('Best shift: np.array([', end='')\n",
    "    for n in bestShift.flatten():\n",
    "        print('%f, '%n, end='')\n",
    "    print('])')\n",
    "    CheckConvergence(ScoreShift2, bestShift.flatten(), (method, obj, hMatrix, None, 1.0, False))\n",
    "    return bestShift\n",
    "                \n",
    "class ShiftHistory:\n",
    "    def __init__(self):\n",
    "        self.Reset()\n",
    "\n",
    "    def __copy__(self):\n",
    "        result = ShiftHistory()\n",
    "        result.shiftHistory = self.shiftHistory\n",
    "        result.scoreHistory = self.scoreHistory\n",
    "        result.counter = self.counter\n",
    "        return result\n",
    "\n",
    "    def Reset(self):\n",
    "        self.scoreHistory = []\n",
    "        self.shiftHistory = []\n",
    "        self.counter = 0\n",
    "    \n",
    "    def Update(self, shift, score):\n",
    "        self.shiftHistory.append(shift)\n",
    "        self.scoreHistory.append(score)\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "    def BestScore(self):\n",
    "        return np.min(self.scoreHistory)\n",
    "\n",
    "    def BestShift(self):\n",
    "        return self.shiftHistory[np.argmin(self.scoreHistory)]\n",
    "\n",
    "    def PlotHistory(self, onlyPlotEvery=1):\n",
    "        if ((self.counter%onlyPlotEvery) == 0) and (len(self.shiftHistory) > 0):\n",
    "            print('best score so far: %e' % np.min(self.scoreHistory))\n",
    "            # Plot one of the shifts\n",
    "            shiftShape = self.shiftHistory[0].shape\n",
    "            selectedItem = np.minimum(int(np.sqrt(shiftShape[0])/2), shiftShape[0]-1)\n",
    "            selectedShift = np.array(self.shiftHistory)[:, selectedItem, -1]\n",
    "            plt.plot(selectedShift)\n",
    "            plt.show()\n",
    "            # Plot scores, with a suitable y axis scaling to see the interesting parts.\n",
    "            # We limit the y axis to avoid stupid guesses distorting the plot.\n",
    "            improvement = self.scoreHistory[0] - np.min(self.scoreHistory)\n",
    "            plt.ylim(np.min(self.scoreHistory), self.scoreHistory[0]+2*improvement)\n",
    "            plt.plot(self.scoreHistory)\n",
    "            plt.show()\n",
    "            # Plot an indication of which values are being updated on which iteration\n",
    "            for n in range(1, len(self.scoreHistory)):\n",
    "                changes = np.array(np.where((self.shiftHistory[n] == self.shiftHistory[n-1]).flatten() == False))\n",
    "                if (changes.size > 0):\n",
    "                    plt.plot(n, changes, 'x', color='red')\n",
    "            plt.show()\n",
    "\n",
    "            with open('scores.txt', 'a') as f:\n",
    "                f.write('%f\\t' % self.scoreHistory[-1])\n",
    "                for n in self.shiftHistory[-1]:\n",
    "                    if xMotionPermitted:\n",
    "                        f.write('%f\\t%f\\t' % (n[0], n[1]))\n",
    "                    else:\n",
    "                        f.write('%f\\t' % (n[0]))\n",
    "                f.write('\\n')\n",
    "            return True\n",
    "        else:\n",
    "            return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate synthetic light-field-recovered AB images (doing it the naive way, not using my new joint deconvolution)\n",
    "# Run the imaging cycle on each of the AB images individually (i.e. introduce artefacts into them)\n",
    "dualObjectRecovered = dualObject.copy()\n",
    "for n in [0, 1]:\n",
    "    cameraImage = forwardProjectACC(pivHMatrix, dualObject[:,n,:,:], logPrint=False)\n",
    "    backProjected = backwardProjectACC(pivHMatrix, cameraImage, logPrint=False)\n",
    "    \n",
    "    # With the shifted images, we have problems with true zeroes in regions that have no features remaining.\n",
    "    # To avoid this, I apply a very small nonzero background so that the deconvolution doesn't fail.\n",
    "    backProjected = np.maximum(backProjected, 1e-5*np.max(backProjected))\n",
    "    \n",
    "    dualObjectRecovered[:,n,:,:] = deconvRL(pivHMatrix, backProjected, maxIter=8, Xguess=backProjected, logPrint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original object')\n",
    "iwPos = IWCentresForObject(dualObject)\n",
    "ShowDualObjectAndFlow(dualObject, shiftDescription)\n",
    "print('Recovered from light field images (plane %d)' % zPlaneToModel)\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, shiftDescription)\n",
    "plt.imsave('syntheticInput.tif', dualObject[0,0])\n",
    "plt.imsave('syntheticInputB.tif', dualObject[0,1])\n",
    "\n",
    "plt.imsave('syntheticA.tif', dualObjectRecovered[0,0])\n",
    "plt.imsave('syntheticB.tif', dualObjectRecovered[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CalcFlowUsingVanillaPIV(imagePair, iwPos):\n",
    "    # Calculate the flow based on traditional window-based PIV analysis\n",
    "    shiftDescriptionPIV = np.zeros(iwPos.shape)\n",
    "    smallIWSize = controlPointSpacing\n",
    "    largeIWSize = 2 * controlPointSpacing\n",
    "    for n in range(iwPos.shape[0]):\n",
    "        a = imagePair[0, iwPos[n,1]-int(smallIWSize/2):iwPos[n,1]+int(smallIWSize/2),\\\n",
    "                             iwPos[n,0]-int(smallIWSize/2):iwPos[n,0]+int(smallIWSize/2)]\n",
    "        b = imagePair[1, iwPos[n,1]-int(largeIWSize/2):iwPos[n,1]+int(largeIWSize/2),\\\n",
    "                             iwPos[n,0]-int(largeIWSize/2):iwPos[n,0]+int(largeIWSize/2)]\n",
    "        sad_using_c_code = jpsad.sad_correlation(a, b)\n",
    "        zeroPoint = np.array([1,1])*int((largeIWSize-smallIWSize)/2)\n",
    "        shiftDescriptionPIV[n] = -(np.array(np.unravel_index(sad_using_c_code.argmin(), sad_using_c_code.shape))[::-1]-zeroPoint)\n",
    "    if xMotionPermitted:\n",
    "        return shiftDescriptionPIV\n",
    "    else:\n",
    "        return shiftDescriptionPIV[:,1:]\n",
    "\n",
    "if source == 'synthetic':\n",
    "    thresh = 0\n",
    "else:\n",
    "    # Experimental PIV images\n",
    "    thresh = 6e5\n",
    "    \n",
    "shiftDescriptionPIVRaw = CalcFlowUsingVanillaPIV(dualObject[0], iwPos)\n",
    "ShowDualObjectAndFlow(dualObject, shiftDescriptionPIVRaw*3, suppressDark=thresh)\n",
    "shiftDescriptionPIVReconstructed = CalcFlowUsingVanillaPIV(dualObjectRecovered[0], iwPos)\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, shiftDescriptionPIVReconstructed*3, suppressDark=thresh)\n",
    "\n",
    "#knownGood = np.array([4.179692, 2.422054, 2.277945, -3.442326, 2.588265, -1.628299, -0.701406, -0.351879, 1.371176, -0.887983, -0.329903, -1.814173, -0.039174, -1.546245, 4.530734, 6.433376, -3.923658, 0.765194, -3.139235, 11.998391, 0.159123, 4.712269, 0.000467, 1.881291, -1.076288, 2.571115, -0.752311, 6.346806, 0.705785, 1.599266, 0.526477, 0.520794, 1.613503, -0.944800, -4.052433, 0.938896, -9.285762, 9.058932, -1.427279, 3.465706, -2.667963, 6.611281, -2.711337, 6.691590, 1.149587, 6.157966, 5.232333, 7.419857, 3.860831, 0.035423, 1.096535, -0.919879, 1.315764, 0.783761, -1.649745, 1.829128, -1.506330, 2.903395, -2.640247, 6.333610, -2.974801, 5.116153, -1.640844, 6.727836, 6.771447, 5.497423, 7.318270, 3.963571, -1.879130, 0.376258, -2.545277, 3.033343, -1.405359, 2.988077, -3.664550, 3.713645, -2.404847, 3.906314, -0.068660, 0.731329, 3.443943, 1.132651, 8.621877, 2.114740, 4.915054, 3.548191, 3.346262, 5.315995, -2.250714, 3.869669, -3.046189, 2.948226, -1.592374, 0.569959, -0.875566, 0.699708, -0.309011, -0.220754, 2.785740, 4.885732, 1.892708, 2.223612, 5.977712, 3.248553, 1.007629, 3.325284, -0.803304, 5.829418, -2.376718, 0.837404, 0.982720, 0.897666, -1.992212, 4.365900, -0.497122, 3.024971, -0.809540, 2.668115, 3.179223, -4.673659, 3.866968, 0.850031, 2.411868, 0.370574, 3.250005, 2.128673]).reshape(shiftDescription.shape)\n",
    "#ShowDualObjectAndFlow(dualObject, knownGood*3, suppressDark=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp: visualize flow as computer for the PIV dataset using the two runs I had going on my mac pro\n",
    "correct = np.array([4.179692, 2.422054, 2.277945, -3.442326, 2.588265, -1.628299, -0.701406, -0.351879, 1.371176, -0.887983, -0.329903, -1.814173, -0.039174, -1.546245, 4.530734, 6.433376, -3.923658, 0.765194, -3.139235, 11.998391, 0.159123, 4.712269, 0.000467, 1.881291, -1.076288, 2.571115, -0.752311, 6.346806, 0.705785, 1.599266, 0.526477, 0.520794, 1.613503, -0.944800, -4.052433, 0.938896, -9.285762, 9.058932, -1.427279, 3.465706, -2.667963, 6.611281, -2.711337, 6.691590, 1.149587, 6.157966, 5.232333, 7.419857, 3.860831, 0.035423, 1.096535, -0.919879, 1.315764, 0.783761, -1.649745, 1.829128, -1.506330, 2.903395, -2.640247, 6.333610, -2.974801, 5.116153, -1.640844, 6.727836, 6.771447, 5.497423, 7.318270, 3.963571, -1.879130, 0.376258, -2.545277, 3.033343, -1.405359, 2.988077, -3.664550, 3.713645, -2.404847, 3.906314, -0.068660, 0.731329, 3.443943, 1.132651, 8.621877, 2.114740, 4.915054, 3.548191, 3.346262, 5.315995, -2.250714, 3.869669, -3.046189, 2.948226, -1.592374, 0.569959, -0.875566, 0.699708, -0.309011, -0.220754, 2.785740, 4.885732, 1.892708, 2.223612, 5.977712, 3.248553, 1.007629, 3.325284, -0.803304, 5.829418, -2.376718, 0.837404, 0.982720, 0.897666, -1.992212, 4.365900, -0.497122, 3.024971, -0.809540, 2.668115, 3.179223, -4.673659, 3.866968, 0.850031, 2.411868, 0.370574, 3.250005, 2.128673])\n",
    "correct.shape = (63,2)\n",
    "joint_startedWithCorrect = np.array([[-3.46956446e-03, 9.61095429e-01, 4.44415111e-01, -1.53527275e+00, 6.77153487e+00, -7.44146838e-01, 7.12031474e-01, -1.55401929e-02, 6.28613798e-03, -2.20445130e+00, 2.43331717e+00, 1.77874576e-01, -1.95849488e+00, -8.39130055e-01, 2.22057487e-01, 3.90672635e-01, -4.60806967e-01, -6.64075497e+00, -8.61081872e+00, -3.43562023e+00, -5.25693558e+00, -3.31455813e+00, 2.50891016e+00, 3.24509438e+00, 3.43248569e+00, 1.81482624e+00, 1.10590141e+01, -1.26329974e+00, -8.86442327e-01, -2.43612245e+00, -8.36238900e+00, -1.63782961e+00, 7.49045984e+00, 6.76073641e+00, -1.32362267e+01, 2.66819084e-05, -1.69414204e+00, -5.65765566e+00, -1.57664842e+00, 1.23941049e-01, 5.14833019e+00, 7.20529915e+00, 3.31522269e+00, 6.73114159e+00, -4.61407200e+00, -2.97814883e+00, -1.37762656e+00, -1.30854667e+00, 1.42302575e+00, -9.49780114e+00, -8.79775153e+00, 7.30119133e+00, -5.74808622e-01, -1.33123648e+00, -1.30922297e+00, 1.20205418e-04, -9.54930869e-02, -2.01473122e+00, -2.29875358e-01, -6.98139516e-01, 6.65668593e+00, 3.14743091e+00, 4.61573888e+00], [3.16409852e-03, -1.21057022e+00, -1.72096836e+00, 5.94088666e+00, -4.37610627e+00, -4.42214068e+00, -1.76644728e+00, 1.11310822e+01, -9.76478955e-01, 1.93427152e-02, 9.47330916e-01, 4.03117276e+00, 2.12529200e+00, 8.32911533e+00, 4.54480084e+00, -4.27711971e-02, -1.61438429e+00, 1.63542459e+00, 1.00859262e+01, 5.05902506e+00, 1.00863257e+01, 6.58395411e+00, 4.98800108e+00, 1.08599663e+01, -7.30342801e-02, -8.44590403e-01, -8.67462769e+00, 1.81321632e+00, 1.52006223e+00, 1.10191056e+01, 2.66531654e+00, 8.49432347e+00, 5.32421002e+00, 3.92532685e+00, 2.16013667e+00, 3.34837423e+00, 2.22416192e+00, 4.54662917e+00, 3.01834475e+00, 1.12590205e+00, -1.25525510e+00, 2.63074618e+00, 3.28669257e+00, 4.05507128e+00, 6.10703573e+00, 4.12589471e+00, 1.49870093e+00, 5.34812442e-01, -9.01271928e-01, 1.04613605e+01, 5.23274857e+00, 1.84320015e+00, 3.08904788e+00, 4.64561095e+00, 2.20611416e-03, -1.63987044e+00, -6.83487990e+00, 7.02743302e+00, 3.10466764e+00, -3.26659385e+00, -3.96403584e-01, -5.86124215e-01, 3.43776836e+00]]).T\n",
    "\n",
    "#ShowDualObjectAndFlow(dualObjectRecovered, (correct)*4, suppressDark=thresh)\n",
    "\n",
    "velocityMultiplier = 2\n",
    "ShowDualObjectAndFlow(dualObject, correct*velocityMultiplier, suppressDark=thresh)\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, joint_startedWithCorrect*velocityMultiplier, suppressDark=thresh)\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, shiftDescriptionPIVReconstructed*velocityMultiplier, suppressDark=thresh)\n",
    "\n",
    "\n",
    "magnitudesJoint = ShowDualObjectAndFlow(dualObjectRecovered, (joint_startedWithCorrect - correct)*velocityMultiplier, suppressDark=thresh)/velocityMultiplier\n",
    "\n",
    "magnitudesNaive = ShowDualObjectAndFlow(dualObjectRecovered, (shiftDescriptionPIVReconstructed - correct)*velocityMultiplier, suppressDark=thresh)/velocityMultiplier\n",
    "\n",
    "#magnitudesPIV = ShowDualObjectAndFlow(dualObjectRecovered, (shiftDescriptionPIVRaw - correct)*velocityMultiplier, suppressDark=thresh)/velocityMultiplier\n",
    "\n",
    "\n",
    "plt.hist([magnitudesJoint, magnitudesNaive], range=(0,30), bins=20, label=['joint', 'naive'])\n",
    "plt.legend()\n",
    "plt.xlabel('|Error|^2')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # If I want to give the algorithm the best possible starting point,\n",
    "    # I can give it the actual true shift values as its starting point\n",
    "    # (but it still may iterate away from that...)\n",
    "    warnings.warn(\"WARNING: starting guess is actually the correct flow description\")\n",
    "    startShiftForOptimizer = shiftDescription.copy()\n",
    "else:\n",
    "    startShiftForOptimizer = 0.0 * initialShiftGuess.copy()\n",
    "    \n",
    "def OptimizeToRecoverFlowField(method, imageAB, hMatrix, shiftDescription, initialShiftGuess, shiftHistory=None):\n",
    "    imageAB = imageAB.copy()    # This is just paranoia - I don't think it should get manipulated\n",
    "    print('True shift:', shiftDescription.T)\n",
    "\n",
    "    if shiftHistory is not None:\n",
    "        warnings.warn('Overriding initial shift guess with best shift from history')\n",
    "        initialShiftGuess = shiftHistory.BestShift()\n",
    "        \n",
    "    if False:\n",
    "        plt.imshow(imageAB[0,:,:])\n",
    "        plt.show()\n",
    "        plt.imshow(imageAB[1,:,:])\n",
    "        plt.show()\n",
    "\n",
    "    if False:\n",
    "        print('Score for correct shift:', ScoreShift2(shiftDescription.flatten(), method, imageAB, hMatrix))\n",
    "        print('Score for initial guess:', ScoreShift2(initialShiftGuess.flatten(), method, imageAB, hMatrix))\n",
    "\n",
    "    if True:\n",
    "        optimizationAlgorithm = 'Powell'\n",
    "        options = {'xtol': 1e-2}\n",
    "    elif True:\n",
    "        optimizationAlgorithm = 'L-BFGS-B'\n",
    "        options = {'eps': 5e-03, 'gtol': 1e-6}\n",
    "    else:\n",
    "        optimizationAlgorithm = 'Nelder-Mead'\n",
    "        options = {'eps': 5e-03, 'xatol': 1e-2, 'adaptive': True}\n",
    "\n",
    "    if shiftHistory is None:\n",
    "        shiftHistory = ShiftHistory()\n",
    "\n",
    "    # Optimize to obtain the best-matching shift\n",
    "    try:\n",
    "        shift = scipy.optimize.minimize(ScoreShift2, initialShiftGuess, bounds=shiftSearchBounds, args=(method, imageAB, hMatrix, shiftHistory), method=optimizationAlgorithm, options=options)\n",
    "        print('Optimizer finished:', str(shift.message), 'Final shift:', shift.x.T)\n",
    "    except KeyboardInterrupt:\n",
    "        # Catch keyboard interrupts so that we still return whatever shiftHistory we have built up so far.\n",
    "        print('KEYBOARD INTERRUPT DURING OPTIMIZATION')\n",
    "    return shiftHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using direct shift-matching of the raw input images (real experimental SPIM images)\n",
    "if False:\n",
    "    shiftHistoryRaw = OptimizeToRecoverFlowField('naive', dualObject[0], None, shiftDescription, startShiftForOptimizer)\n",
    "\n",
    "# Note: if continuing a previously-interrupted run then we can do this to pick up roughly where we left off.\n",
    "# i.e. provide BestShift() for the two shift-related input parameters, and pass the existing shift history as the final (optional) parameter\n",
    "#    shiftHistoryRaw = OptimizeToRecoverFlowField('naive', dualObject[0], None, shiftHistoryRaw.BestShift(), shiftHistoryRaw.BestShift(), shiftHistoryRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bestShift = ReportOnOptimizerConvergence(shiftHistoryRaw, 'naive', dualObject[0])\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using direct shift-matching of the light-field-deconvolved images\n",
    "if True:\n",
    "    shiftHistoryNaive = OptimizeToRecoverFlowField('naive', dualObjectRecovered[0], None, shiftDescription, startShiftForOptimizer, shiftHistoryNaive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ReportOnOptimizerConvergence(shiftHistoryNaive, 'naive', dualObjectRecovered[0])\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using my new joint algorithm\n",
    "if True:\n",
    "    # Generate a camera image pair from the object.\n",
    "    if source == 'piv':\n",
    "        # The camera AB images are determined by separate forward projection of the AB spim images in dualObject\n",
    "        imageAB = forwardProjectACC(pivHMatrix, dualObject)\n",
    "    else:\n",
    "        # The synthetic B image is determined with the help of the chosen shift transform.\n",
    "        imageAB = forwardProjectACC_PIV(pivHMatrix, dualObject[:,0], shiftDescription)\n",
    "\n",
    "    if False:\n",
    "        # Try starting using the solution obtained by direct warping of AB image pair,\n",
    "        # to see if that yields a better minimum than the one I had found so far\n",
    "        startShiftForOptimizer = np.array([4.179692, 2.422054, 2.277945, -3.442326, 2.588265, -1.628299, -0.701406, -0.351879, 1.371176, -0.887983, -0.329903, -1.814173, -0.039174, -1.546245, 4.530734, 6.433376, -3.923658, 0.765194, -3.139235, 11.998391, 0.159123, 4.712269, 0.000467, 1.881291, -1.076288, 2.571115, -0.752311, 6.346806, 0.705785, 1.599266, 0.526477, 0.520794, 1.613503, -0.944800, -4.052433, 0.938896, -9.285762, 9.058932, -1.427279, 3.465706, -2.667963, 6.611281, -2.711337, 6.691590, 1.149587, 6.157966, 5.232333, 7.419857, 3.860831, 0.035423, 1.096535, -0.919879, 1.315764, 0.783761, -1.649745, 1.829128, -1.506330, 2.903395, -2.640247, 6.333610, -2.974801, 5.116153, -1.640844, 6.727836, 6.771447, 5.497423, 7.318270, 3.963571, -1.879130, 0.376258, -2.545277, 3.033343, -1.405359, 2.988077, -3.664550, 3.713645, -2.404847, 3.906314, -0.068660, 0.731329, 3.443943, 1.132651, 8.621877, 2.114740, 4.915054, 3.548191, 3.346262, 5.315995, -2.250714, 3.869669, -3.046189, 2.948226, -1.592374, 0.569959, -0.875566, 0.699708, -0.309011, -0.220754, 2.785740, 4.885732, 1.892708, 2.223612, 5.977712, 3.248553, 1.007629, 3.325284, -0.803304, 5.829418, -2.376718, 0.837404, 0.982720, 0.897666, -1.992212, 4.365900, -0.497122, 3.024971, -0.809540, 2.668115, 3.179223, -4.673659, 3.866968, 0.850031, 2.411868, 0.370574, 3.250005, 2.128673])\n",
    "\n",
    "    # Run the joint optimizer optimizer to find the shift value for an input frame pair\n",
    "    shiftHistoryJoint = OptimizeToRecoverFlowField('joint', imageAB, pivHMatrix, shiftDescription, startShiftForOptimizer, shiftHistoryJoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    np.save('shiftHistoryJoint.npy', shiftHistoryJoint.shiftHistory)\n",
    "    np.save('scoreHistoryJoint.npy', shiftHistoryJoint.scoreHistory)\n",
    "    np.save('dualObjectJoint.npy', dualObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ReportOnOptimizerConvergence(shiftHistoryJoint, 'joint', imageAB, pivHMatrix)\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at how the scores are evolving during the powell iterations\n",
    "\n",
    "if True:\n",
    "    vals = np.array(shiftHistoryJoint.shiftHistory)\n",
    "    scores = np.array(shiftHistoryJoint.scoreHistory)\n",
    "else:\n",
    "    # Load from files previously saving using:\n",
    "    #   np.save('scoreHistory.npy', np.array(shiftHistoryJoint.scoreHistory))\n",
    "    #   np.save('shiftHistory.npy', np.array(shiftHistoryJoint.shiftHistory))\n",
    "    vals = np.load('/Users/jonny/Desktop/shiftHistory.npy')\n",
    "    scores = np.load('/Users/jonny/Desktop/scoreHistory.npy')\n",
    "iwOfInterest = 5*7+3\n",
    "iwOfInterest = 5*7+6# Looking at border control point for shiftHistoryNaive\n",
    "x = []\n",
    "y = []\n",
    "y2 = []\n",
    "\n",
    "if False:\n",
    "    # Compare the results from different control points\n",
    "    sh = vals[3020].flatten()\n",
    "    sh[iwOfInterest] = 5.011\n",
    "    (_,_,_,_,comp) = ScoreShift3(sh, 'naive', objectToUse, log=False)    \n",
    "    for d in [5.012, 5.0135, 5.0145]:\n",
    "        sh[iwOfInterest] = d\n",
    "        sc = ScoreShift2(sh, 'naive', objectToUse[0], log=False, comparator=comp)\n",
    "        print('score', sc)\n",
    "\n",
    "if True:\n",
    "    for iw in [iwOfInterest]:\n",
    "#    for iw in range(49):\n",
    "        for n in range(0,vals.shape[0]-1):\n",
    "            if (vals[n,iw,0] != vals[n+1,iw,0]):\n",
    "                x.append(vals[n,iw,0])\n",
    "                y.append(scores[n])\n",
    "            else:\n",
    "                if (len(x) > 0):\n",
    "                    if (len(x) > 2):\n",
    "                        plt.plot(x, y, 'x')\n",
    "                        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "                        plt.show()\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    y2 = []\n",
    "                nStart = n\n",
    "    if (len(x) > 2):\n",
    "        plt.plot(x, y, 'x')\n",
    "        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code useful for understanding how two images differ, since I have been having\n",
    "# a lot of problems related to warp(), where tiny changes in shifts make a difference to the result\n",
    "# (these are largely due to edge effects of one type or another)\n",
    "def ShowDifferences(im1, im2, fullIm1, sh):\n",
    "    diff = im1-im2\n",
    "    print(diff.shape)\n",
    "    print('Largest difference', np.max(np.abs(diff)), 'loc', np.argmax(np.abs(diff)), \\\n",
    "          np.argmax(np.abs(diff))%diff.shape[1], int(np.argmax(np.abs(diff))/diff.shape[1]))\n",
    "    plt.imshow(diff)\n",
    "    iwPos = IWCentresForObject(dualObject, st='piv')\n",
    "    if False:\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            plt.plot(iwPos[n,0], iwPos[n,1], 'x', color='red')\n",
    "    elif True:\n",
    "        src = IWCentresForObject(fullIm1[np.newaxis])\n",
    "        if (src.shape[0] != sh.shape[0]):\n",
    "            assert(src.shape[0] == sh.shape[0])\n",
    "        if (shiftType == 'piv-zeroedge'):\n",
    "            (src, sh) = AddZeroEdgePadding(fullIm1[np.newaxis], src, sh)\n",
    "            print('padded')\n",
    "        for n in range(sh.shape[0]):\n",
    "            plt.plot([iwPos[n,0], iwPos[n,0]+sh[n,0]*1e9], \\\n",
    "                     [iwPos[n,1], iwPos[n,1]+sh[n,1]*1e9], color='red')\n",
    "            if not sh[n,0] == 0:\n",
    "                print('x', [iwPos[n,0], iwPos[n,0]+sh[n,0]*1e9])\n",
    "                print('y', [iwPos[n,1], iwPos[n,1]+sh[n,1]*1e9])\n",
    "    plt.xlim(-10,60)\n",
    "    plt.ylim(80,-10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand how the optimizer is behaving, scan the search space rather than optimizing\n",
    "\n",
    "# Generate a camera image pair from the object.\n",
    "# The B image is determined with the help of the chosen shift transform.\n",
    "imageAB = forwardProjectACC_PIV(pivHMatrix, dualObject[:,0,:,:], shiftDescription)\n",
    "# Run the joint optimizer optimizer to find the shift value for an input frame pair\n",
    "shiftHistorySearch = ShiftHistory()\n",
    "candidateShiftYX = startShiftForOptimizer.copy()\n",
    "for dx in range(-4,5,1):\n",
    "#    candidateShiftYX[4*11+3] = dx\n",
    "#    [5147746000.0, 4475782000.0, 3882488600.0, 3441547500.0, 3223274800.0, 3499643600.0, 4056565800.0, 4845896000.0, 5856099300.0]\n",
    "    candidateShiftYX[3*11+5] = dx\n",
    "    ScoreShift2(candidateShiftYX.flatten(), 'joint', imageAB, pivHMatrix, shiftHistorySearch, log=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shiftHistorySearch.scoreHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary: plotting velocity curves because I don't seem to have that code on my laptop\n",
    "oneLens = np.array([10.862958, -1.443047, 0.332139, 4.405934, -0.153823, -1.755634, 4.066662, 1.899461, 4.774937, 4.288873, 6.098334, 2.156575, 3.283804, 4.029672, 13.566075, 1.801321, 15.448385, 6.394007, 7.178400, 7.106718, 12.273373, -14.666837, 5.111868, 7.882884, 8.721239, 6.867755, 5.641365, 3.340085, 5.588366, 9.117049, 2.237782, -1.251710, 23.535857, 6.499464, 10.420452, 69.905325, -13.358900, 1.926929, 0.526439, 2.005965, 32.774536, 17.063480, 7.802566, -50.389157, 9.439552, -19.231901, -0.933729, -0.905371, -0.275877]).reshape((7,7))\n",
    "oneLensNaive = []\n",
    "\n",
    "twoLens = np.array([1.547096, -0.756477, 1.007048, -0.561828, -0.637234, -0.029966, -0.121392, 2.424037, 2.237319, 2.821429, 4.160425, 4.127186, 4.236659, 5.169546, 7.444215, 7.127218, 7.198190, 5.474373, 6.800737, 7.369968, -2.075165, 5.773002, 5.458451, 7.014281, 7.210561, 6.977147, 6.512999, 8.365205, 16.284319, 7.652777, 5.594855, 7.790051, 5.770755, 6.528609, 5.977414, 0.228023, 1.916074, 4.929982, 4.181229, 3.963583, 5.231549, 5.995688, -31.022106, 37.960189, -12.175012, -98.216332, -51.273363, 27.641667, 47.129537]).reshape((7,7))\n",
    "twoLensNaive = np.array([-0.107739, -0.104656, -0.620940, 0.090302, -0.113247, -0.088426, -0.019108, 1.940174, 1.725361, 6.280136, 2.387378, 2.177253, 2.064151, 2.577545, 26.687781, 1.039631, 12.572762, 4.809212, 7.036026, 13.494221, -15.283873, 4.558655, 7.806684, 10.972292, 6.193278, 12.258869, 9.973479, -7.100600, 16.527190, 10.775738, 4.459501, 3.930470, 1.990099, 8.893538, 15.374002, -1.771851, 4.710975, 1.144725, 9.085837, 3.763832, 1.091623, 0.591693, 6.000000, 6.000000, 6.000000, 6.000000, 6.000000, 6.000000, 6.000000]).reshape((7,7))\n",
    "# This is when starting with initial values of zero - slightly different, but not significantly worse:\n",
    "twoLensNaive2 = np.array([-0.051553, -0.065844, -0.612783, 0.116099, -0.028148, -0.169299, 0.049512, 1.905477, 1.603818, 7.074075, 2.340491, 2.159303, 2.307213, 2.529498, 27.071832, 0.968882, 12.458521, 4.884523, 7.116204, 10.276534, 2.921531, 4.574736, 7.607359, 11.039444, 7.017050, 12.942378, 8.733590, -4.089224, 16.927030, 10.635423, 8.563132, 3.564145, 1.755013, 9.761919, 14.704044, 2.132546, -3.809558, 0.647797, 9.273659, 3.640461, 1.220848, 0.116608, 8.569018, 8.569018, 8.569018, 8.569018, 8.569018, 8.569018, 8.569018]).reshape((7,7))\n",
    "\n",
    "oneLensDenser = np.array([-2.313951, 3.275988, -1.644593, 0.457744, 2.147303, -3.169811, -10.748788, 8.166339, 3.943775, 5.205276, 2.117024, 3.686519, 3.675942, 5.991241, -4.256257, 7.061367, 5.557434, 5.541006, 8.694494, 8.640133, 2.737254, 4.108934, 3.756802, 5.282122, 3.612750, 3.468806, 5.793371, 6.974820, 10.620995, 5.383104, 7.767305, 14.500105, 7.411558, 9.273295, -6.232036, 6.822856, 19.625258, 4.494330, 6.437424, 32.533403, 7.687231, 13.015959, -85.315085, 10.075143, -1.329189, -0.484777, 11.570230, 0.530341, 1.088226]).reshape((7,7))\n",
    "# This one may not have converged yet:\n",
    "oneLensDenserNaive = np.array([8.251714, 0.387290, -2.420769, -0.426543, 1.785727, -0.610097, 2.794295, 8.791857, 0.559260, 7.891976, 0.333506, 1.765845, 1.967897, 4.581975, -0.752497, 12.003070, 12.364237, 3.017486, 12.380995, 13.466941, -0.231960, -4.632797, 12.006906, 0.070485, 11.010837, 0.266687, 13.347549, -0.412399, 11.485217, 12.216079, 0.106411, 17.199250, 1.174043, 2.937269, -15.987668, 11.027095, 11.027095, 11.027095, 11.027095, 11.027095, 11.027095, 11.027095, 7.138206, 7.138206, 7.138206, 7.138206, 7.138206, 7.138206, 8.138206]).reshape((7,7))\n",
    "\n",
    "vPoints = 7*(1-((np.arange(1,6)-3)**2/9.0))\n",
    "x = np.arange(0,7,0.01)\n",
    "xPoints = np.arange(1,6) * 30\n",
    "vCurve = 7*(1-((x-3)**2/9))\n",
    "plt.plot(x*30, vCurve, color='black', label='true')\n",
    "errs = []\n",
    "errsNaive = []\n",
    "for n in range(1,6):\n",
    "    l = None\n",
    "    if n == 1:\n",
    "        l = 'joint'\n",
    "    plt.plot(xPoints, twoLens[1:6,n], 'x', color='green', label=l)\n",
    "    if n == 1:\n",
    "        l = 'naive'\n",
    "    plt.plot(xPoints, twoLensNaive[1:6,n], '+', color='red', label=l)\n",
    "    errs.append(twoLens[1:6,n]-vPoints)\n",
    "    errsNaive.append(twoLensNaive[1:6,n]-vPoints)\n",
    "errs = np.array(errs).flatten()\n",
    "errsNaive = np.array(errsNaive).flatten()\n",
    "print('joint stdev', np.std(errs))\n",
    "print('naive stdev', np.std(errsNaive))\n",
    "plt.xlim(0,6*30)\n",
    "plt.ylim(0,15)\n",
    "plt.xlabel('position (px)')\n",
    "plt.ylabel('velocity (px)')\n",
    "plt.legend()\n",
    "plt.savefig('TwoLensParabola.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "for n in range(7):\n",
    "    plt.plot(np.arange(1,6), oneLensDenser[1:6,n], 'x', color='green')\n",
    "    plt.plot(np.arange(1,6), oneLensDenserNaive[1:6,n], '+', color='red')    \n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0,15)\n",
    "plt.show()\n",
    "\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, twoLensNaive.reshape(49,1)*3, destFilename='NaiveSyntheticFlow.png')\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, twoLens.reshape(49,1)*3, destFilename='JointSyntheticFlow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
