{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status: my new code (which eliminates some of the FFTs) takes 16 seconds instead of 63, on my laptop - for a 2x2 tiled-up input [I did this to give more reproducible timings with a larger work size].\n",
    "\n",
    "Without exploiting symmetries it takes 23 seconds. I had to write C code to speed up the generation of the reflected/transposed FFT matrices - without that it was barely any faster than just computing the rfftn for all aa,bb.\n",
    "\n",
    "Now, 2/3rds of the time is spent in fft2, so that is the bottleneck. If I insist on a square array then I could halve that, but that would be a limitation. I could, I suppose, make it a *recommendation* that allows the code to run faster. I could certainly take advantage of that for my own work.\n",
    "\n",
    "For the original dataset size, on my mac pro, my code takes 6.5s (single-threaded) to back-project plane 4, compared to Matlab's 2.2s (multithreaded). \n",
    "\n",
    "On my mac pro, full backprojection takes 96s single-threaded or 13s parallel(!), of which 1s is on the merging at the end (which I should be able to speed up too). Matlab with multithreading took 28s, so I have achieved a >2x speedup. More would have been nice, but it's still fairly respectable.\n",
    "\n",
    "\n",
    "NOTE: my c code can't cope with an array that has been transposed (Probably because it assumes adjacent strides in x?). I should probably fix that, though I doubt it's a performance issue to just .copy() the transposed array, which is what I do at the moment. I should really be swapping the transpose to be the final operation (in the case of square inputs) anyway. However, it looks as if a decent chunk of the fft time is actually being spent in the other ffts (for the reduced arrays) anyway!\n",
    "\n",
    "### Performance investigation\n",
    "\n",
    "Actual thread execution time seems to grow considerably with the number of threads, i.e. efficiency falls. I am not sure how to try and work out what the cause of that is. I could go back to working on dummy data (no transfers between processes) and see if that makes a difference to *that* in particular. (I think I may have looked only at the dead time overheads - which are also an issue).\n",
    "I looked at user and system cpu time, and with Instruments. Looks like 20% of time is spent in madvise (macbook, 2 threads). I am not sure exactly why or where that is happening. It seems to be related to python memory management in some way. I should check if that grows with number of threads on mac pro, and if it is the same when I use dummy work blocks rather than passing to subprocesses\n",
    "\n",
    "-> revisit this now I am using mmap rather than pickle - hopefully much of this is now fixed.\n",
    "\n",
    "### Performance improvements to make\n",
    "\n",
    "Move transpose to final operation (since it's probably faster than reversing an array - although it may impact subsequent fft performance?), in the case of square arrays\n",
    "\n",
    "fft2 returns a double array (on macbook, at least) for float input. I would much prefer it to return complex64. I could well believe it might be a performance hit to do it this way (larger memory footprint). Can I improve on this? I suppose I could call through to c code that calls fftw, for example\n",
    "\n",
    "Code now supports a third dimension for the camera images (and object z plane), so that we can implement PIV. At the moment it just iterates - performance should be improved by only calculating FT(H) once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import scipy.ndimage, scipy.optimize, scipy.io\n",
    "from scipy.ndimage.filters import convolve\n",
    "from scipy.signal import convolve2d, fftconvolve\n",
    "import os, sys, time, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tifffile\n",
    "import h5py\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "import cProfile, pstats\n",
    "import glob, csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from numba import jit\n",
    "sys.path.insert(0, 'py_symmetry')\n",
    "import py_symmetry as jps\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "\n",
    "# I don't know if these are necessary, but it has been suggested that low-level threading\n",
    "# does not interact well with the joblib Parallel feature.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_DYNAMIC'] = 'FALSE'\n",
    "\n",
    "try:\n",
    "    os.mkdir('perf_diags')\n",
    "except:\n",
    "    pass  # Probably the directory already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPath = 'PSFmatrix/PSFmatrix_M22.2NA0.5MLPitch125fml3125from-110to110zspacing4Nnum19lambda520n1.33.mat'\n",
    "\n",
    "warnings.warn('WARNING: Switched to faster matrix for testing')\n",
    "matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-26to0zspacing2Nnum15lambda520n1.0.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmapPath = os.path.splitext(matPath)[0]\n",
    "try:\n",
    "    os.mkdir(mmapPath)\n",
    "except:\n",
    "    pass  # Probably the directory already exists\n",
    "\n",
    "_HPathFormat = mmapPath+'/H{z:02d}.array'\n",
    "_HtPathFormat = mmapPath+'/Ht{z:02d}.array'\n",
    "_HReducedShape = []\n",
    "_HtReducedShape = []\n",
    "if True:\n",
    "    # Load the matrices from the .mat file.\n",
    "    # This is slow since they must be decompressed and are rather large! (9.5GB each, in single-precision FP)\n",
    "    with h5py.File(matPath, 'r') as f:\n",
    "        print('Load CAindex')\n",
    "        sys.stdout.flush()\n",
    "        _CAindex = f['CAindex'].value.astype('int')\n",
    "        \n",
    "        print('Load H')\n",
    "        sys.stdout.flush()\n",
    "        _H = f['H'].value.astype('float32')\n",
    "        Nnum = _H.shape[2]\n",
    "        aabbRange = int((Nnum+1)/2)\n",
    "        for cc in tqdm(range(_H.shape[0]), desc='memmap H'):\n",
    "            HCC =  _H[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            _HReducedShape.append(HCC.shape)\n",
    "            a = np.memmap(_HPathFormat.format(z=cc), dtype='float32', mode='w+', shape=HCC.shape)\n",
    "            a[:,:,:,:] = HCC[:,:,:,:]\n",
    "            del a\n",
    "        #del _H        # H is needed for old code\n",
    "        \n",
    "        print('Load Ht')\n",
    "        sys.stdout.flush()\n",
    "        _Ht = f['Ht'].value.astype('float32')\n",
    "        for cc in tqdm(range(_Ht.shape[0]), desc='memmap Ht'):\n",
    "            HtCC =  _Ht[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            _HtReducedShape.append(HtCC.shape)\n",
    "            a = np.memmap(_HtPathFormat.format(z=cc), dtype='float32', mode='w+', shape=HtCC.shape)\n",
    "            a[:,:,:,:] = HtCC[:,:,:,:]\n",
    "            del a\n",
    "        #del _Ht        # Ht is needed for old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMatrix:\n",
    "    def __init__(self, HPathFormat, HtPathFormat, HReducedShape, numZ=None, zStart=0):\n",
    "        self.HPathFormat = HPathFormat\n",
    "        self.HtPathFormat = HtPathFormat\n",
    "        self.HReducedShape = HReducedShape   # Same for Ht\n",
    "        if numZ is not None:\n",
    "            self.numZ = numZ\n",
    "        else:\n",
    "            self.numZ = len(HReducedShape)\n",
    "        self.zStart = zStart\n",
    "        \n",
    "    def Hcc(self, cc, transpose):\n",
    "        if transpose:\n",
    "            pathFormat = self.HtPathFormat\n",
    "        else:\n",
    "            pathFormat = self.HPathFormat\n",
    "        result = np.memmap(pathFormat.format(z=cc+self.zStart), dtype='float32', mode='r', shape=self.HReducedShape[cc+self.zStart])\n",
    "        return result\n",
    "    \n",
    "    def IterableBRange(self, cc):\n",
    "        return range(self.HReducedShape[cc+self.zStart][0])\n",
    "    \n",
    "    def PSFShape(self, cc):\n",
    "        return (self.HReducedShape[cc+self.zStart][2], self.HReducedShape[cc+self.zStart][3])\n",
    "        \n",
    "    def Nnum(self, cc):\n",
    "        return self.HReducedShape[cc+self.zStart][0]*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "LFmovie = tifffile.imread('Data/02_Rectified/exampleData/20131219WORM2_small_full_neg_X1_N15_cropped_uncompressed.tif')\n",
    "LFmovie = LFmovie.transpose()[np.newaxis,:,:]\n",
    "\n",
    "LFIMG = LFmovie[0].astype('float32')\n",
    "if True:\n",
    "    # Actual (cropped) image loaded from disk\n",
    "    inputImage = LFIMG\n",
    "else:\n",
    "    inputImage = np.tile(LFIMG,(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects stored in the .mat file\n",
    "\n",
    "### Optical parameters from GUI: [? means I am not sure if or where it is stored]\n",
    "\n",
    "M<br>\n",
    "NA<br>\n",
    "d    \"fml\" in GUI (stored here in units of m)<br>\n",
    "pixelPitch is \"ML pitch\" / \"Nnum\" (stored here in units of m)<br>\n",
    "? n<br>\n",
    "? wavelength<br>\n",
    "\n",
    "### User parameters from GUI:\n",
    "\n",
    "OSR<br>\n",
    "zspacing<br>\n",
    "? z-min<br>\n",
    "? z-max<br>\n",
    "Nnum<br>\n",
    "\n",
    "\n",
    "### Misc parameter:\n",
    "\n",
    "fobj (can presumably be deduced from mag, NA etc?)<br>\n",
    "\n",
    "### The actual arrays:\n",
    "\n",
    "H:             shape (56, 19, 19, 343, 343), type \"f4\"<br>\n",
    "Ht:            shape (56, 19, 19, 343, 343), type \"f4\"<br>\n",
    "\n",
    "### Information about object space:\n",
    "\n",
    "x1objspace:    x pixel positions in object space (19 elements across one lenslet)<br>\n",
    "x2objspace:    y pixel positions in object space (19 elements across one lenslet)<br>\n",
    "x3objspace:    z pixel positions in object space (56 z planes)<br>\n",
    "x1space:       x pixel positions in lenslet space (19 elements across one lenslet)<br>\n",
    "x2space:       y pixel positions in lenslet space (19 elements across one lenslet)<br>\n",
    "\n",
    "### Not sure what these are exactly:\n",
    "\n",
    "CAindex:       shape (2, 56) - something about the start and end index of the PSF array, for each z plane.<br>\n",
    "CP:            shape (343, 1)<br>\n",
    "MLARRAY:       shape (1141, 1141), type \"|V16\"<br>\n",
    "objspace:      shape (56, 1, 1)<br>\n",
    "settingPSF:    You would think this contains the GUI parameters, but e.g. print(f['settingPSF']['M'].value) gives a strange 3x1 array [50, 50, 46, 50] etc...?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I am a little unsure how to interpret the arrays I have loaded from the .mat.\n",
    "# From looking at how H and CAindex are accessed, it looks as if the shapes I have loaded\n",
    "# are the reversal of the shape ordering as expected in Matlab.\n",
    "# I suppose that makes sense given that matlab is column-major in its array accesses.\n",
    "# The data has been loaded from disk in the order it is *stored*,\n",
    "# and I therefore need to flip around all the matlab array index ordering \n",
    "# (e.g. matlabArray(1,2,3) becomes pythonArray[3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "def noProgressBar(work, **kwargs):\n",
    "    # Dummy function to be used in place of tqdm when we don't want to show a progress bar\n",
    "    return work    \n",
    "\n",
    "def cpuTime(kind):\n",
    "    rus = resource.getrusage(resource.RUSAGE_SELF)    \n",
    "    ruc = resource.getrusage(resource.RUSAGE_CHILDREN)\n",
    "    if (kind == 'self'):\n",
    "        return np.array([rus.ru_utime, rus.ru_stime])\n",
    "    elif (kind == 'children'):\n",
    "        return np.array([ruc.ru_utime, ruc.ru_stime])\n",
    "    else:\n",
    "        return np.array([rus.ru_utime+ruc.ru_utime, rus.ru_stime+ruc.ru_stime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy._lib._version import NumpyVersion\n",
    "from numpy.fft import fft, fftn, rfft, rfftn, irfftn\n",
    "_rfft_mt_safe = (NumpyVersion(np.__version__) >= '1.9.0.dev-e24486e')\n",
    "\n",
    "def _next_regular(target):\n",
    "    \"\"\"\n",
    "    Find the next regular number greater than or equal to target.\n",
    "    Regular numbers are composites of the prime factors 2, 3, and 5.\n",
    "    Also known as 5-smooth numbers or Hamming numbers, these are the optimal\n",
    "    size for inputs to FFTPACK.\n",
    "\n",
    "    Target must be a positive integer.\n",
    "    \"\"\"\n",
    "    if target <= 6:\n",
    "        return target\n",
    "\n",
    "    # Quickly check if it's already a power of 2\n",
    "    if not (target & (target-1)):\n",
    "        return target\n",
    "\n",
    "    match = float('inf')  # Anything found will be smaller\n",
    "    p5 = 1\n",
    "    while p5 < target:\n",
    "        p35 = p5\n",
    "        while p35 < target:\n",
    "            # Ceiling integer division, avoiding conversion to float\n",
    "            # (quotient = ceil(target / p35))\n",
    "            quotient = -(-target // p35)\n",
    "\n",
    "            # Quickly find next power of 2 >= quotient\n",
    "            try:\n",
    "                p2 = 2**((quotient - 1).bit_length())\n",
    "            except AttributeError:\n",
    "                # Fallback for Python <2.7\n",
    "                p2 = 2**(len(bin(quotient - 1)) - 2)\n",
    "\n",
    "            N = p2 * p35\n",
    "            if N == target:\n",
    "                return N\n",
    "            elif N < match:\n",
    "                match = N\n",
    "            p35 *= 3\n",
    "            if p35 == target:\n",
    "                return p35\n",
    "        if p35 < match:\n",
    "            match = p35\n",
    "        p5 *= 5\n",
    "        if p5 == target:\n",
    "            return p5\n",
    "    if p5 < match:\n",
    "        match = p5\n",
    "    return match\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    currsize = np.array(arr.shape)\n",
    "    newsize = np.asarray(newsize)\n",
    "    if (len(currsize) > len(newsize)):\n",
    "        newsize = np.append([currsize[0]], newsize)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "def tempMul(bb,fshape,result):\n",
    "    result *= np.exp(-1j * bb * 2*np.pi / fshape[0] * np.arange(result.shape[0],dtype='complex64'))[:,np.newaxis]\n",
    "    return result\n",
    "\n",
    "def expand2(result, bb, aa, Nnum, fshape):\n",
    "    return np.tile(result, (Nnum,1))\n",
    "\n",
    "def expand(reducedF, bb, aa, Nnum, fshape):\n",
    "    result = np.tile(reducedF, (1,int(Nnum/2+1)))\n",
    "    result = result[:,:int(fshape[1]/2+1)]\n",
    "    result *= np.exp(-1j * aa * 2*np.pi / fshape[1] * np.arange(result.shape[1],dtype='complex64'))\n",
    "    result = expand2(result, bb, aa, Nnum, fshape)\n",
    "    return tempMul(bb,fshape,result)\n",
    "\n",
    "\n",
    "def special_rfftn(in1, bb, aa, Nnum, fshape):\n",
    "    # Compute the fft of elements in1[bb::Nnum,aa::Nnum], after in1 has been zero-padded out to fshape\n",
    "    # We exploit the fact that fft(masked-in1) is fft(arr[::Nnum,::Nnum]) replicated Nnum times.\n",
    "    reducedShape = ()\n",
    "    for d in fshape:\n",
    "        assert((d % Nnum) == 0)\n",
    "        reducedShape = reducedShape + (int(d/Nnum),)\n",
    "        \n",
    "    assert(in1.ndim == 2)\n",
    "    reduced = in1[bb::Nnum,aa::Nnum]\n",
    "\n",
    "    # Compute an array giving rfft(mask(in1))\n",
    "    reducedF = scipy.fftpack.fft2(reduced, reducedShape).astype('complex64')\n",
    "    return expand(reducedF, bb, aa, Nnum, fshape)\n",
    "\n",
    "def convolutionShape(in1, in2, Nnum):\n",
    "    # Logic copied from fftconvolve source code\n",
    "    s1 = np.array(in1.shape)\n",
    "    s2 = np.array(in2.shape)\n",
    "    if (len(s1) == 3):   # Cope with case where we are processing multiple reconstructions in parallel\n",
    "        s1 = s1[1:]\n",
    "    shape = s1 + s2 - 1\n",
    "    if False:\n",
    "        # TODO: I haven't worked out if/how I can do this yet.\n",
    "        # This is the original code in fftconvolve, which says:\n",
    "        # Speed up FFT by padding to optimal size for FFTPACK\n",
    "        fshape = [_next_regular(int(d)) for d in shape]\n",
    "    else:\n",
    "        fshape = [int(np.ceil(d/float(Nnum)))*Nnum for d in shape]\n",
    "    fslice = tuple([slice(0, int(sz)) for sz in shape])\n",
    "    return (fshape, fslice, s1)\n",
    "    \n",
    "def special_fftconvolve_part1(in1, bb, aa, Nnum, in2):\n",
    "    assert(len(in1.shape) == 2)\n",
    "    assert(len(in2.shape) == 2)\n",
    "    (fshape, fslice, s1) = convolutionShape(in1, in2, Nnum)\n",
    "    # Pre-1.9 NumPy FFT routines are not threadsafe - this code requires numpy 1.9 or greater\n",
    "    assert(_rfft_mt_safe)\n",
    "    fa = special_rfftn(in1, bb, aa, Nnum, fshape)\n",
    "    return (fa, fshape, fslice, s1)\n",
    "\n",
    "def special_fftconvolve_part3b(fab, fshape, fslice, s1):\n",
    "    assert(len(fab.shape) == 2)\n",
    "    ret = irfftn(fab, fshape)[fslice].copy()\n",
    "    return _centered(ret, s1)\n",
    "\n",
    "def special_fftconvolve_part3(fab, fshape, fslice, s1):\n",
    "    if (len(fab.shape) == 2):\n",
    "        return special_fftconvolve_part3b(fab, fshape, fslice, s1)\n",
    "    else:\n",
    "        results = []\n",
    "        for n in range(fab.shape[0]):\n",
    "            results.append(special_fftconvolve_part3(fab[n], fshape, fslice, s1))\n",
    "        return np.array(results)\n",
    "\n",
    "def special_fftconvolve(in1, bb, aa, Nnum, in2, accum, fb=None):\n",
    "    '''\n",
    "    in1 consists of subapertures of size Nnum x Nnum pixels.\n",
    "    We are being asked to convolve only pixel (bb,aa) within each subaperture, i.e.\n",
    "        tempSlice = np.zeros(in1.shape, dtype=in1.dtype)\n",
    "        tempSlice[bb::Nnum, aa::Nnum] = in1[bb::Nnum, aa::Nnum]\n",
    "    This allows us to take a significant shortcut in computing the FFT for in1.\n",
    "    '''\n",
    "    (fa, fshape, fslice, s1) = special_fftconvolve_part1(in1, bb, aa, Nnum, in2)\n",
    "    if fb is None:\n",
    "        fb = rfftn(in2, fshape)\n",
    "    if accum is None:\n",
    "        accum = fa*fb\n",
    "    else:\n",
    "        accum += fa*fb\n",
    "    return (accum, fshape, fslice, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProjectForZ_old(HCC, realspaceCC):\n",
    "    singleJob = (len(realspaceCC.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        realspaceCC = realspaceCC[np.newaxis,:,:]\n",
    "    # Iterate over each lenslet pixel\n",
    "    Nnum = HCC.shape[1]\n",
    "    TOTALprojection = np.zeros(realspaceCC.shape, dtype='float32')\n",
    "    for bb in tqdm(range(Nnum), leave=False, desc='Forward-project - y'):\n",
    "        for aa in tqdm(range(Nnum), leave=False, desc='Forward-project - x'):\n",
    "            # Extract the part of H that represents this lenslet pixel\n",
    "            Hs = HCC[bb, aa]\n",
    "            for n in range(realspaceCC.shape[0]):\n",
    "                # Create a workspace representing just the voxels cc,bb,aa behind each lenslet (the rest is 0)\n",
    "                tempspace = np.zeros((realspaceCC[n].shape[0], realspaceCC[n].shape[1]), dtype='float32');\n",
    "                tempspace[bb::Nnum, aa::Nnum] = realspaceCC[n, bb::Nnum, aa::Nnum]  # ???? what to do about index ordering?\n",
    "                # Compute how those voxels project onto the sensor, and accumulate\n",
    "                TOTALprojection[n] += fftconvolve(tempspace, Hs, 'same')\n",
    "    if singleJob:\n",
    "        return TOTALprojection[0]\n",
    "    else:\n",
    "        return TOTALprojection\n",
    "    \n",
    "def backwardProjectForZ_old(HtCC, projection):\n",
    "    singleJob = (len(projection.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        projection = projection[np.newaxis,:,:]\n",
    "    # Iterate over each lenslet pixel\n",
    "    Nnum = HtCC.shape[1]\n",
    "    tempSliceBack = np.zeros(projection.shape, dtype='float32')        \n",
    "    for aa in tqdm(range(Nnum), leave=False, desc='y'):\n",
    "        for bb in range(Nnum):\n",
    "            # Extract the part of Ht that represents this lenslet pixel\n",
    "            Hts = HtCC[bb, aa]\n",
    "            for n in range(projection.shape[0]):\n",
    "                # Create a workspace representing just the voxels cc,bb,aa behind each lenslet (the rest is 0)\n",
    "                tempSlice = np.zeros(projection[n].shape, dtype='float32')\n",
    "                tempSlice[bb::Nnum, aa::Nnum] = projection[n, bb::Nnum, aa::Nnum]\n",
    "                # Compute how those voxels back-project from the sensor\n",
    "                tempSliceBack[n] += fftconvolve(tempSlice, Hts, 'same')\n",
    "    if singleJob:\n",
    "        return tempSliceBack[0]\n",
    "    else:\n",
    "        return tempSliceBack\n",
    "\n",
    "def backwardProjectACC_original(Ht, projection, CAindex, planes=None):\n",
    "    Backprojection = np.zeros((Ht.shape[0], projection.shape[0], projection.shape[1]), dtype='float32')\n",
    "    # Iterate over each z plane\n",
    "    if planes is None:\n",
    "        planes = range(Ht.shape[0])\n",
    "    for cc in tqdm(planes, desc='Back-project - z'):\n",
    "        HtCC =  Ht[cc, :, :, CAindex[0,cc]-1:CAindex[1,cc], CAindex[0,cc]-1:CAindex[1,cc]]\n",
    "        Backprojection[cc] = backwardProjectForZ_old(HtCC, projection)\n",
    "    return Backprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvRL(hMatrix, Htf, maxIter, Xguess, logPrint=True):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC(hMatrix, Xguess, logPrint=logPrint)\n",
    "        HXguessBack = backwardProjectACC(hMatrix, HXguess, logPrint=logPrint)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        ttime = time.time() - t0\n",
    "        print('iter %d | %d, took %.1f secs. Max val %f' % (i+1, maxIter, ttime, np.max(Xguess)))\n",
    "    return Xguess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: H.shape in python is (<num z planes>, Nnum, Nnum, <psf size>, <psf size>),\n",
    "#                       e.g. (56, 19, 19, 343, 343)\n",
    "\n",
    "class Projector(object):\n",
    "    # Note: the variable names in this class mostly imply we are doing the back-projection\n",
    "    # (e.g. Ht, 'projection', etc. However, the same code also does forward-projection!)\n",
    "    def __init__(self, projection, HtCCBB, Nnum):\n",
    "        # Note: H and Hts are not stored as class variables.\n",
    "        # I had a lot of trouble with them and multithreading,\n",
    "        # and eventually settled on having them in shared memory.\n",
    "        # As I encapsulate more stuff in this class, I could bring them back as class variables...\n",
    "\n",
    "        self.cpuTime = np.zeros(2)\n",
    "        \n",
    "        # Nnum: number of pixels across a lenslet array (after rectification)\n",
    "        self.Nnum = Nnum\n",
    "        \n",
    "        # This next chunk of logic copied from fftconvolve source code.\n",
    "        # s1, s2: shapes of the input arrays\n",
    "        # fshape: shape of the (full, possibly padded) result array in Fourier space\n",
    "        # fslice: slicing tuple specifying the actual result size that should be returned\n",
    "        self.s1 = np.array(projection.shape)\n",
    "        self.s2 = np.array(HtCCBB[0].shape)\n",
    "        shape = self.s1 + self.s2 - 1\n",
    "        if False:\n",
    "            # TODO: I haven't worked out if/how I can do this yet.\n",
    "            # This is the original code in fftconvolve, which says:\n",
    "            # Speed up FFT by padding to optimal size for FFTPACK\n",
    "            self.fshape = [_next_regular(int(d)) for d in shape]\n",
    "        else:\n",
    "            self.fshape = [int(np.ceil(d/float(Nnum)))*Nnum for d in shape]\n",
    "        self.fslice = tuple([slice(0, int(sz)) for sz in shape])\n",
    "        \n",
    "        # rfslice: slicing tuple to crop down full fft array to the shape that would be output from rfftn\n",
    "        self.rfslice = (slice(0,self.fshape[0]), slice(0,int(self.fshape[1]/2)+1))\n",
    "        return\n",
    "    \n",
    "    def MirrorXArray(self, Hts, fHtsFull):\n",
    "        padLength = self.fshape[0] - Hts.shape[0]\n",
    "        if False:\n",
    "            fHtsFull = fHtsFull.conj() * np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[0]) * np.arange(self.fshape[0],dtype='complex64')[:,np.newaxis])\n",
    "            fHtsFull[:,1::] = fHtsFull[:,1::][:,::-1]\n",
    "            return fHtsFull\n",
    "        else:\n",
    "            temp = np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[0]) * np.arange(self.fshape[0])).astype('complex64')\n",
    "            if True:\n",
    "                result = jps.mirrorX(fHtsFull, temp)\n",
    "            else:\n",
    "                result = np.empty(fHtsFull.shape, dtype=fHtsFull.dtype)\n",
    "                result[:,0] = fHtsFull[:,0].conj()*temp\n",
    "                for i in range(1,fHtsFull.shape[1]):\n",
    "                    result[:,i] = (fHtsFull[:,fHtsFull.shape[1]-i].conj()*temp)\n",
    "            return result\n",
    "\n",
    "    def MirrorYArray(self, Hts, fHtsFull):\n",
    "        padLength = self.fshape[1] - Hts.shape[1]\n",
    "        if False:\n",
    "            fHtsFull = fHtsFull.conj() * np.exp(1j * (1+padLength) * 2*np.pi / self.fshape[1] * np.arange(self.fshape[1],dtype='complex64'))\n",
    "            fHtsFull[1::] = fHtsFull[1::][::-1]\n",
    "            return fHtsFull\n",
    "        else:\n",
    "            temp = np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[1]) * np.arange(self.fshape[1])).astype('complex64')\n",
    "            if True:\n",
    "                result = jps.mirrorY(fHtsFull, temp)\n",
    "            else:\n",
    "                result = np.empty(fHtsFull.shape, dtype=fHtsFull.dtype)\n",
    "                result[0] = fHtsFull[0].conj()*temp\n",
    "                for i in range(1,fHtsFull.shape[0]):\n",
    "                    result[i] = (fHtsFull[fHtsFull.shape[0]-i].conj()*temp)\n",
    "            return result\n",
    "        \n",
    "    def convolvePart3(self, projection, bb, aa, Hts, fHtsFull, mirrorX, accum):\n",
    "        # TODO: to make this work, I need the full matrix for fHts and then I need to slice it \n",
    "        # to the correct shape when I call through to special_fftconvolve here. Is fshape what I need?\n",
    "        cpu0 = cpuTime('both')\n",
    "        (accum,_,_,_) = special_fftconvolve(projection,bb,aa,self.Nnum,Hts,accum,fb=fHtsFull[self.rfslice])\n",
    "        self.cpuTime += cpuTime('both')-cpu0\n",
    "        if mirrorX:\n",
    "            fHtsFull = self.MirrorXArray(Hts, fHtsFull)\n",
    "            cpu0 = cpuTime('both')\n",
    "            (accum,_,_,_) = special_fftconvolve(projection,self.Nnum-bb-1,aa,self.Nnum,Hts[::-1,:],accum,fb=fHtsFull[self.rfslice]) \n",
    "            self.cpuTime += cpuTime('both')-cpu0\n",
    "        return accum\n",
    "\n",
    "    def convolvePart2(self, projection, bb, aa, Hts, fHtsFull, mirrorY, mirrorX, accum):\n",
    "        accum = self.convolvePart3(projection,bb,aa,Hts,fHtsFull,mirrorX,accum)\n",
    "        if mirrorY:\n",
    "            fHtsFull = self.MirrorYArray(Hts, fHtsFull)\n",
    "            accum = self.convolvePart3(projection,bb,self.Nnum-aa-1,Hts[:,::-1],fHtsFull,mirrorX,accum)\n",
    "        return accum\n",
    "\n",
    "    def convolve(self, projection, bb, aa, Hts, accum):\n",
    "        cent = int(self.Nnum/2)\n",
    "\n",
    "        mirrorX = (bb != cent)\n",
    "        mirrorY = (aa != cent)\n",
    "        transpose = ((aa != bb) and (aa != (self.Nnum-bb-1)))\n",
    "            \n",
    "        # TODO: it would speed things up if I could avoid computing the full fft for Hts.\n",
    "        # However, it's not immediately clear to me how to fill out the full fftn array from rfftn\n",
    "        # in the case of a 2D transform.\n",
    "        # For 1D it's the reversed conjugate, but for 2D it's more complicated than that.\n",
    "        # It's possible that it's actually nontrivial, in spite of the fact that\n",
    "        # you can get away without it when only computing fft/ifft for real arrays)\n",
    "        fHtsFull = scipy.fftpack.fft2(Hts, self.fshape).astype('complex64')\n",
    "        accum = self.convolvePart2(projection,bb,aa,Hts,fHtsFull,mirrorY,mirrorX, accum)\n",
    "        if transpose:\n",
    "            if (self.fshape[0] == self.fshape[1]):\n",
    "                # For a square array, the FFT of the transpose is just the transpose of the FFT.\n",
    "                # The copy() is because my C code currently can't cope with\n",
    "                # a transposed array (non-contiguous strides in x)\n",
    "                fHtsFull = fHtsFull.transpose().copy()    \n",
    "            else:\n",
    "                # For a non-square array, we have to compute the FFT for the transpose.\n",
    "                fHtsFull = scipy.fftpack.fft2(Hts.transpose(), self.fshape).astype('complex64')\n",
    "\n",
    "            # Note that mx,my need to be swapped following the transpose\n",
    "            accum = self.convolvePart2(projection,aa,bb,Hts.transpose(),fHtsFull,mirrorX,mirrorY, accum) \n",
    "        return accum\n",
    "    \n",
    "def _projectForZY(cc, bb, source, hMatrix, backwards, Hccbb=None):\n",
    "    f = open('perf_diags/%d_%d.txt'%(cc,bb), \"w\")\n",
    "    t1 = time.time()\n",
    "    singleJob = (len(source.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        source = source[np.newaxis,:,:]\n",
    "    result = [None] * source.shape[0]\n",
    "    if Hccbb is None:\n",
    "        Hccbb = hMatrix.Hcc(cc, transpose=backwards)[bb]\n",
    "        Nnum = hMatrix.Nnum(cc)\n",
    "    else:\n",
    "        Nnum = Hccbb.shape[0]\n",
    "    projector = Projector(source[0], Hccbb, Nnum)\n",
    "    projector.cpuTime = np.zeros(2)\n",
    "    for aa in range(bb,int((Nnum+1)/2)):\n",
    "        for n in range(source.shape[0]):\n",
    "            result[n] = projector.convolve(source[n], bb, aa, Hccbb[aa], result[n])\n",
    "    t2 = time.time()\n",
    "    f.write('%d\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (os.getpid(), t1, t2, t2-t1, projector.cpuTime[0], projector.cpuTime[1]))\n",
    "    f.close()\n",
    "    if singleJob:\n",
    "        return (result[0], cc, bb, t2-t1)\n",
    "    else:\n",
    "        return (np.array(result), cc, bb, t2-t1)\n",
    "    \n",
    "def projectForZ(Hcc, cc, source):\n",
    "    result = None\n",
    "    Nnum = Hcc.shape[1]\n",
    "    r = range(int((Nnum+1)/2))\n",
    "    for bb in tqdm(r, leave=False, desc='Project - y'):\n",
    "        (thisResult, _, _, _) = _projectForZY(cc, bb, source, None, False, Hcc[bb])\n",
    "        if (result is None):\n",
    "            result = thisResult\n",
    "        else:\n",
    "            result += thisResult\n",
    "    # Actually, for forward projection we don't need to do this separately for every z,\n",
    "    # but it's easier to do it for symmetry (and this function is not used in performance-critical code anyway)\n",
    "    (fshape, fslice, s1) = convolutionShape(source, Hcc[0,0], Nnum)\n",
    "    return special_fftconvolve_part3(result, fshape, fslice, s1)\n",
    "\n",
    "def projectForZ2(hMatrix, backwards, cc, source):\n",
    "    result = None\n",
    "    for bb in tqdm(hMatrix.IterableBRange(cc), leave=False, desc='Project - y'):\n",
    "        (thisResult, _, _, _) = _projectForZY(cc, bb, source, hMatrix, backwards)\n",
    "        if (result is None):\n",
    "            result = thisResult\n",
    "        else:\n",
    "            result += thisResult\n",
    "    # Actually, for forward projection we don't need to do this separately for every z,\n",
    "    # but it's easier to do it for symmetry (and this function is not used in performance-critical code anyway)\n",
    "    (fshape, fslice, s1) = convolutionShape(source, np.empty(hMatrix.PSFShape(cc)), hMatrix.Nnum(cc))\n",
    "    return special_fftconvolve_part3(result, fshape, fslice, s1)\n",
    "    \n",
    "# Test the backprojection code against a slower definitive version\n",
    "# (this code is here for now because this is where I have been working on stuff, but it could move)\n",
    "# TODO: would be a better test if I use the hMatrix form of projectForZ\n",
    "testHtCC = np.random.random((5,5,30,30)).astype(np.float32)\n",
    "testHtCC = _Ht[13,int(_Ht.shape[1]/2)-2:int(_Ht.shape[1]/2)+3,int(_Ht.shape[2]/2)-2:int(_Ht.shape[2]/2)+3,_CAindex[0,13]-1:_CAindex[1,13], _CAindex[0,13]-1:_CAindex[1,13]]\n",
    "for fd in [False, True]:\n",
    "    for shape in [(200,200), (200,300), (300,200)]:\n",
    "        # Test both square and non-square, since they use different code\n",
    "        testProjection = np.random.random(shape).astype(np.float32)\n",
    "        if fd:\n",
    "            testResultOld = forwardProjectForZ_old(testHtCC, testProjection)\n",
    "            testResultNew = projectForZ(testHtCC, 0, testProjection)\n",
    "        else:\n",
    "            testResultOld = backwardProjectForZ_old(testHtCC, testProjection)\n",
    "            testResultNew = projectForZ(testHtCC, 0, testProjection)\n",
    "        comparison = np.max(np.abs(testResultOld - testResultNew))\n",
    "        print('test result (should be <<1): %e' % comparison)\n",
    "        if (comparison > 1e-4):\n",
    "            print(\" -> WARNING: disagreement detected\")\n",
    "        else:\n",
    "            print(\" -> OK\")\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slower test that exercises the projection code with the new HMatrix object\n",
    "if True:\n",
    "    testHCC = _H[13]\n",
    "    testHtCC = _Ht[13]\n",
    "    testHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=13)\n",
    "    for fd in [False, True]:\n",
    "        for shape in [(200,200), (200,300), (300,200)]:\n",
    "            # Test both square and non-square, since they use different code\n",
    "            testProjection = np.random.random(shape).astype(np.float32)\n",
    "            if fd:\n",
    "                testResultOld = forwardProjectForZ_old(testHCC, testProjection)\n",
    "                testResultNew = projectForZ2(testHMatrix, False, 0, testProjection)\n",
    "            else:\n",
    "                testResultOld = backwardProjectForZ_old(testHtCC, testProjection)\n",
    "                testResultNew = projectForZ2(testHMatrix, True, 0, testProjection)\n",
    "            comparison = np.max(np.abs(testResultOld - testResultNew))\n",
    "            print('test result (fd=%d) (should be <<1): %e' % (fd, comparison))\n",
    "            if (comparison > 1e-4):\n",
    "                print(\" -> WARNING: disagreement detected\")\n",
    "            else:\n",
    "                print(\" -> OK\")\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def backwardProjectACC(hMatrix, projection, planes=None, numjobs=multiprocessing.cpu_count(), progress=tqdm, logPrint=True):\n",
    "    singleJob = (len(projection.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        projection = projection[np.newaxis,:,:]\n",
    "    if planes is None:\n",
    "        planes = range(hMatrix.numZ)\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "\n",
    "    ru1 = cpuTime('both')\n",
    "\n",
    "    Backprojection = np.zeros((hMatrix.numZ, projection.shape[0], projection.shape[1], projection.shape[2]), dtype='float32')\n",
    "        \n",
    "    # Set up the work to iterate over each z plane\n",
    "    work = []\n",
    "    for cc in planes:\n",
    "        for bb in hMatrix.IterableBRange(cc):\n",
    "            work.append((cc, bb, projection, hMatrix, True))\n",
    "\n",
    "    # Run the multithreaded work\n",
    "    t0 = time.time()\n",
    "    results = Parallel(n_jobs=numjobs)\\\n",
    "            (delayed(_projectForZY)(*args) for args in progress(work, desc='Back-project - z', leave=False))\n",
    "    ru2 = cpuTime('both')\n",
    "\n",
    "    # Gather together and sum the results for each z plane\n",
    "    t1 = time.time()\n",
    "    fourierZPlanes = [None]*hMatrix.numZ\n",
    "    elapsedTime = 0\n",
    "    for (result, cc, bb, t) in results:\n",
    "        elapsedTime += t\n",
    "        if fourierZPlanes[cc] is None:\n",
    "            fourierZPlanes[cc] = result\n",
    "        else:\n",
    "            fourierZPlanes[cc] += result\n",
    "    \n",
    "    # Compute the FFT for each z plane\n",
    "    for cc in planes:\n",
    "        # A bit complicated here to set up the correct inputs for convolutionShape...\n",
    "        (fshape, fslice, s1) = convolutionShape(projection, np.empty(hMatrix.PSFShape(cc)), hMatrix.Nnum(cc))\n",
    "        Backprojection[cc] = special_fftconvolve_part3(fourierZPlanes[cc], fshape, fslice, s1)        \n",
    "    t2 = time.time()\n",
    "\n",
    "    # Save some diagnostics\n",
    "    if logPrint:\n",
    "        print('work elapsed wallclock time %f'%(t1-t0))\n",
    "        print('work elapsed thread time %f'%elapsedTime)\n",
    "        print('work delta rusage:', ru2-ru1)\n",
    "        print('FFTs took %f'%(t2-t1))\n",
    "    \n",
    "    f = open('overall.txt', 'w')\n",
    "    f.write('%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (t0, t1, t1-t0, t2-t1, (ru2-ru1)[0], (ru2-ru1)[1]))\n",
    "    f.close()\n",
    "\n",
    "    if singleJob:\n",
    "        return Backprojection[:,0]\n",
    "    else:\n",
    "        return Backprojection\n",
    "\n",
    "def forwardProjectACC(hMatrix, realspace, planes=None, numjobs=multiprocessing.cpu_count(), progress=tqdm, logPrint=True):\n",
    "    singleJob = (len(realspace.shape) == 3)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        realspace = realspace[:,np.newaxis,:,:]\n",
    "    if planes is None:\n",
    "        planes = range(hMatrix.numZ)\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "\n",
    "    # Set up the work to iterate over each z plane\n",
    "    work = []\n",
    "    for cc in planes:\n",
    "        for bb in hMatrix.IterableBRange(cc):\n",
    "            work.append((cc, bb, realspace[cc], hMatrix, False))\n",
    "\n",
    "    # Run the multithreaded work\n",
    "    t0 = time.time()\n",
    "    results = Parallel(n_jobs=numjobs)\\\n",
    "                (delayed(_projectForZY)(*args) for args in progress(work, desc='Forward-project - z', leave=False))\n",
    "\n",
    "    # Gather together and sum all the results\n",
    "    t1 = time.time()\n",
    "    fourierProjection = [None]*hMatrix.numZ\n",
    "    elapsedTime = 0\n",
    "    for (result, cc, bb, t) in results:\n",
    "        elapsedTime += t\n",
    "        if fourierProjection[cc] is None:\n",
    "            fourierProjection[cc] = result\n",
    "        else:\n",
    "            fourierProjection[cc] += result\n",
    "\n",
    "    # Compute and accumulate the FFT for each z plane\n",
    "    TOTALprojection = None\n",
    "    for cc in planes:\n",
    "        # A bit complicated here to set up the correct inputs for convolutionShape...\n",
    "        (fshape, fslice, s1) = convolutionShape(realspace[cc], np.empty(hMatrix.PSFShape(cc)), hMatrix.Nnum(cc))\n",
    "        thisProjection = special_fftconvolve_part3(fourierProjection[cc], fshape, fslice, s1)        \n",
    "        if TOTALprojection is None:\n",
    "            TOTALprojection = thisProjection\n",
    "        else:\n",
    "            TOTALprojection += thisProjection\n",
    "    t2 = time.time()\n",
    "            \n",
    "    # Print out some diagnostics\n",
    "    if (logPrint):\n",
    "        print('work elapsed wallclock time %f'%(t1-t0))\n",
    "        print('work elapsed thread time %f'%elapsedTime)\n",
    "        print('FFTs took %f'%(t2-t1))\n",
    "        \n",
    "    if singleJob:\n",
    "        return TOTALprojection[0]\n",
    "    else:\n",
    "        return TOTALprojection\n",
    "\n",
    "if False:\n",
    "    # Temporary call to test parallelization\n",
    "    temp = backwardProjectACC(hMatrix, inputImage, planes=[0], numjobs=3)\n",
    "    \n",
    "if False:\n",
    "    # Temporary code to test running with an image pair\n",
    "    # This is maybe not a comprehensive test, but it run with two different (albeit proportional)\n",
    "    # images and checks that the result matches the result for two totally independent calls on a single array.\n",
    "    hMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape)\n",
    "    candidate = np.tile(inputImage[np.newaxis,0,0], (2,1,1))\n",
    "    candidate[1] *= 1.4\n",
    "    temp = backwardProjectACC(hMatrix, candidate, planes=None, numjobs=1)\n",
    "    dualRoundtrip = forwardProjectACC(hMatrix, temp, planes=None)\n",
    "\n",
    "    temp = backwardProjectACC(hMatrix, candidate[0], planes=None, numjobs=1)\n",
    "    firstRoundtrip = forwardProjectACC(hMatrix, temp, planes=None, numjobs=1)    \n",
    "    comparison = np.max(np.abs(firstRoundtrip - dualRoundtrip[0]))\n",
    "    print('test result (should be <<1): %e' % comparison)\n",
    "    if (comparison > 1e-6):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")\n",
    "    \n",
    "    temp = backwardProjectACC(hMatrix, candidate[1], planes=None, numjobs=1)\n",
    "    secondRoundtrip = forwardProjectACC(hMatrix, temp, planes=None, numjobs=1)    \n",
    "    comparison = np.max(np.abs(secondRoundtrip - dualRoundtrip[1]))\n",
    "    print('test result (should be <<1): %e' % comparison)\n",
    "    if (comparison > 1e-6):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def AnalyzeTestResults():\n",
    "    with open('overall.txt') as f:\n",
    "        csv_reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            pass\n",
    "    startTime = float(row[0])\n",
    "    endTime = float(row[1])\n",
    "    userTime = float(row[4])\n",
    "    sysTime = float(row[5])\n",
    "\n",
    "    rows = []\n",
    "    for fn in glob.glob('perf_diags/*_*.txt'):\n",
    "        with open(fn) as f:\n",
    "            csv_reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in csv_reader:\n",
    "                pass\n",
    "            rows.append(row)\n",
    "    rows = np.array(rows).astype('float').transpose()\n",
    "    firstPid = np.min(rows[0])\n",
    "    rows[0] -= firstPid\n",
    "    rows[1:3] -= startTime\n",
    "    rows = rows[:,np.argsort(rows[1],kind='mergesort')]\n",
    "    rows = rows[:,rows[0].argsort(kind='mergesort')]\n",
    "\n",
    "    deadTimeStart = 0\n",
    "    deadTimeMid = 0\n",
    "    deadTimeEnd = 0\n",
    "    threadWorkTime = 0\n",
    "    thisThreadStartTime = 0\n",
    "    longestThreadRunTime = 0\n",
    "    longestThreadRunPid = -1\n",
    "    latestStartTime = 0\n",
    "    userTimeBreakdown = 0\n",
    "    sysTimeBreakdown = 0\n",
    "    for i in range(rows.shape[1]):\n",
    "        pid = rows[0,i]\n",
    "        t0 = rows[1,i]\n",
    "        t1 = rows[2,i]\n",
    "        userTimeBreakdown += rows[4,i]\n",
    "        sysTimeBreakdown += rows[5,i]\n",
    "        if (i == 0):\n",
    "            deadTimeStart += t0\n",
    "            thisThreadStartTime = t0\n",
    "            latestStartTime = t0\n",
    "        else:\n",
    "            if (pid == rows[0,i-1]):\n",
    "                deadTimeMid += t0 - rows[2,i-1]\n",
    "            else:\n",
    "                latestStartTime = max(latestStartTime, t0)\n",
    "                thisThreadRunTime = rows[2,i-1]-thisThreadStartTime  # For previous pid\n",
    "                if (thisThreadRunTime > longestThreadRunTime):\n",
    "                    longestThreadRunPid = rows[0,i-1]\n",
    "                    longestThreadRunTime = thisThreadRunTime\n",
    "                thisThreadStartTime = t0\n",
    "                deadTimeStart += t0\n",
    "                deadTimeEnd += (endTime-startTime) - rows[2,i-1]\n",
    "        threadWorkTime += t1-t0\n",
    "        plt.plot([t0, t1], [pid, pid])\n",
    "        plt.plot(t0, pid, 'x')\n",
    "    thisThreadRunTime = t1-thisThreadStartTime\n",
    "    if (thisThreadRunTime > longestThreadRunTime):\n",
    "        longestThreadRunPid = pid\n",
    "        longestThreadRunTime = thisThreadRunTime\n",
    "    deadTimeEnd += (endTime-startTime) - rows[2,-1]\n",
    "    print('Elapsed time', endTime-startTime)\n",
    "    print('Longest thread run time', longestThreadRunTime, 'pid', int(longestThreadRunPid))\n",
    "    print('Latest start time', latestStartTime)\n",
    "    print('Thread work time', threadWorkTime)\n",
    "    print('Dead time', deadTimeStart, deadTimeMid, deadTimeEnd)\n",
    "    print(' Total', deadTimeStart + deadTimeMid + deadTimeEnd)\n",
    "    print('User cpu time', userTime)\n",
    "    print('System cpu time', sysTime)\n",
    "    print('User cpu time for subset', userTimeBreakdown)\n",
    "    print('System cpu time for subset', sysTimeBreakdown)\n",
    "\n",
    "    with open('stats.txt', 'a') as f:\n",
    "        f.write('%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (numJobsForTesting, endTime-startTime, threadWorkTime, \\\n",
    "                        longestThreadRunTime, latestStartTime, deadTimeStart, deadTimeMid, deadTimeEnd, userTime, sysTime))\n",
    "\n",
    "    plt.xlim(0, endTime-startTime)\n",
    "    plt.ylim(-0.5,np.max(rows[0])+0.5)\n",
    "    plt.show()\n",
    "    \n",
    "if False:\n",
    "    for numJobsForTesting in range(1,13):\n",
    "        ru1 = cpuTime('both')\n",
    "        temp = backwardProjectACC(Ht, HtPathFormat, HtReducedShape, inputImage, numjobs=numJobsForTesting, planes=None)\n",
    "        ru2 = cpuTime('both')\n",
    "        print('overall delta rusage:', ru2-ru1)\n",
    "        AnalyzeTestResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomment(csvfile):\n",
    "    for row in csvfile:\n",
    "        raw = row.split('#')[0].strip()\n",
    "        if raw: yield raw\n",
    "\n",
    "def AnalyzeTestResults2(fn):\n",
    "    rows = []\n",
    "    with open(fn) as f:\n",
    "        csv_reader = csv.reader(decomment(f), delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "    rows = np.array(rows).astype(np.float).transpose()\n",
    "\n",
    "    plt.plot(rows[0], rows[2]/rows[2,0], label='work time')\n",
    "    plt.plot(rows[0], np.sum(rows[5:8], axis=0)/(rows[0]*rows[1]), label='dead time')\n",
    "    plt.plot(rows[0], rows[5]/(rows[0]*rows[1]), label='dead start')\n",
    "    plt.plot(rows[0], rows[1]/(rows[1,0]/rows[0]), label='runtime excess')\n",
    "    plt.ylim(0,2.5)\n",
    "    plt.legend(loc=2)\n",
    "    plt.show()\n",
    "\n",
    "plt.title('Dummy work on empty arrays')\n",
    "AnalyzeTestResults2('stats-dummy.txt')\n",
    "plt.title('Real work')\n",
    "AnalyzeTestResults2('stats-realwork.txt')\n",
    "plt.title('Smaller memory footprint - no improvement')\n",
    "AnalyzeTestResults2('stats-no-H.txt')\n",
    "plt.title('New code')\n",
    "AnalyzeTestResults2('stats-new-code.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a single backprojection and compare against definitive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "planesToProcess = None#[4]\n",
    "if False:\n",
    "    t0 = time.time()\n",
    "    Htf = backwardProjectACC_original(Ht, inputImage, CAindex, planes=planesToProcess)\n",
    "    print('Original code took %f'%(time.time()-t0))\n",
    "elif True:\n",
    "    # Profile my code (single-threaded) on a cropped version of Prevedel's data\n",
    "    myStats = cProfile.run('Htf = backwardProjectACC(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), inputImage, planes=planesToProcess, numjobs=1)', 'mystats')\n",
    "    p = pstats.Stats('mystats')\n",
    "    p.strip_dirs().sort_stats('cumulative').print_stats(40)\n",
    "else:\n",
    "    # Profile my code (single-threaded) in the sort of scenario I would expect to run it in for my PIV experiments\n",
    "    tempInputImage = np.zeros((2,Nnum*20,Nnum*20))\n",
    "    myStats = cProfile.run('temp = backwardProjectACC(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), tempInputImage, planes=planesToProcess, numjobs=1)', 'mystats')\n",
    "    p = pstats.Stats('mystats')\n",
    "    p.strip_dirs().sort_stats('cumulative').print_stats(40)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against definitive version generated from Matlab\n",
    "if planesToProcess is not None:\n",
    "    print('WARNING: the following test is not valid because not all planes were processed')\n",
    "definitive = tifffile.imread('Data/03_Reconstructed/exampleData/definitive_worm_crop_X15_backproject.tif')\n",
    "definitive = np.transpose(definitive, axes=(0,2,1))\n",
    "comparison = np.max(np.abs(definitive[4] - Htf[4]*10))\n",
    "print('Compare against matlab result (should be <1.0): %f' % comparison)\n",
    "if (comparison > 1.0):\n",
    "    print(\" -> WARNING: disagreement detected\")\n",
    "else:\n",
    "    print(\" -> OK\")\n",
    "\n",
    "#tifffile.imsave('Htf_backproject4.tif', np.transpose(Htf*1e2, axes=(0,2,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a full deconvolution and compare against definitive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xguess = Htf.copy();\n",
    "maxIter = 8\n",
    "deconvolvedResult = deconvRL(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), Htf, maxIter, Xguess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against definitive version generated from Matlab\n",
    "definitive = tifffile.imread('Data/03_Reconstructed/exampleData/definitive_worm_crop_X15_iter8.tif')\n",
    "definitive = np.transpose(definitive, axes=(0,2,1))\n",
    "comparison = np.max(np.abs(definitive - deconvolvedResult*1e3))\n",
    "print('Compare against matlab result (should be <1.0): %f' % comparison)\n",
    "if (comparison > 1.0):\n",
    "    print(\" -> WARNING: disagreement detected\")\n",
    "else:\n",
    "    print(\" -> OK\")\n",
    "\n",
    "#tifffile.imsave('iter8.tif', np.transpose(Xguess*1e3, axes=(0,2,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for flow field (single-plane toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two identical images of the same synthetic object,\n",
    "# which for now consists of 10 random gaussian spots\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "numSpots = 100\n",
    "obj = np.zeros((1, 200, 200))\n",
    "obj[0, (np.random.random(numSpots)*obj.shape[1]).astype('int'), (np.random.random(numSpots)*obj.shape[2]).astype('int')] = 1\n",
    "obj = np.pad(obj, ((0,0),(20,20),(20,20)), 'constant')\n",
    "obj = gaussian_filter(obj, sigma=(0,8,8))\n",
    "plt.imshow(obj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 'piv'\n",
    "\n",
    "def forwardProjectACC_PIV(hMatrix, obj, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return forwardProjectACC(hMatrix, dualObject, logPrint=False, progress=None)\n",
    "\n",
    "def dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    # Compute the reverse transform given the AB images (B image shifted by shiftYX).\n",
    "    # First we do the reverse transformation on both images\n",
    "    dualObject = backwardProjectACC(hMatrix, dualProjection, logPrint=False, progress=None)\n",
    "    # Now we reverse the shift on the B object\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    # Now, ideally the objects would match, but of course in practice there will be discrepancies,\n",
    "    # especially if we are not using the correct shiftDescription.\n",
    "    # To make the operation match the transpose of the forward operation,\n",
    "    # we add the two objects and divide by 2 here\n",
    "    return dualObject\n",
    "\n",
    "def fusedBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def deconvRL_PIV_OLD(hMatrix, imageAB, maxIter, Xguess, shiftDescription):\n",
    "    # I believed this to be the RL algorithm in the way I have written it in the past.\n",
    "    # However, this gives different results to Prevedel's implementation\n",
    "    # (mine seems to converge more slowly).\n",
    "    # TODO: I should look into this and see if I've just made a mistake or if they are actually different.\n",
    "    \n",
    "    # Xguess is our single combined guess of the object\n",
    "    Xguess = Xguess.copy()    # Because we will be updating it, and caller may not always be expecting that\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        relativeBlurDual = imageAB / forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        Xguess *= fusedBackwardProjectACC_PIV(hMatrix, relativeBlurDual, shiftDescription)\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def deconvRL_PIV(hMatrix, imageAB, maxIter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    Htf = fusedBackwardProjectACC_PIV(hMatrix, imageAB, shiftDescription)\n",
    "    Xguess = Htf.copy()\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        HXguessBack = fusedBackwardProjectACC_PIV(hMatrix, HXguess, shiftDescription)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def RollNoninteger(obj, amount, axis=0):\n",
    "    intAmount = int(amount)\n",
    "    frac = amount - intAmount\n",
    "    result1 = np.roll(obj, intAmount, axis=axis)\n",
    "    result2 = np.roll(obj, intAmount+1, axis=axis)\n",
    "    return result1 * (1-frac) + result2 * frac\n",
    "\n",
    "if shift == 'uniform':\n",
    "    def ShiftObject(obj, shiftYX):\n",
    "        # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "        # For now I just consider a uniform translation in xy\n",
    "        # \n",
    "        # TODO: We need to worry about conserving energy during the shift. \n",
    "        # For now I will do a circular shift in order to avoid having to worry about this!\n",
    "        result = RollNoninteger(obj, shiftYX[0], axis=len(obj.shape)-2)\n",
    "        return RollNoninteger(result, shiftYX[1], axis=len(obj.shape)-1)\n",
    "    \n",
    "    # Generate a synthetic shift in the B image\n",
    "    shiftDescription = np.array([-10,20])\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:], (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    plt.imshow(dualObject[0,0])\n",
    "    plt.show()\n",
    "    plt.imshow(dualObject[0,1])\n",
    "    plt.show()    \n",
    "elif shift == 'uniformSK':\n",
    "    # A lot of code duplication here, but it's just an experiment for now\n",
    "    def VelocityShapeForObject(obj):\n",
    "        return (2,)\n",
    "\n",
    "    def ShiftObject(obj, shiftYX):\n",
    "        # Generate control points in the corners of the image\n",
    "        src_cols = np.arange(0, obj.shape[-1]+1, obj.shape[-1])\n",
    "        src_rows = np.arange(0, obj.shape[-2]+1, obj.shape[-2])\n",
    "        src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "        src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "        dst = src + np.array(shiftYX)\n",
    "        tform = PiecewiseAffineTransform()\n",
    "        tform.estimate(src, dst)\n",
    "        # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "        maxVal = np.max(np.abs(obj))\n",
    "        if len(obj.shape) == 3:\n",
    "            result = np.zeros(obj.shape)\n",
    "            for cc in range(obj.shape[0]):\n",
    "                result[cc] = warp(obj[cc]/maxVal, tform) * maxVal\n",
    "            return result\n",
    "        else:\n",
    "            return warp(obj/maxVal, tform) * maxVal\n",
    "else:\n",
    "    # Arbitrary motion described in terms of an array of control points at IWCentresForObject\n",
    "    def IWCentresForObject(obj):\n",
    "        spacing = 60\n",
    "        startPos = 0\n",
    "        # Reusing the code from the skimage example, since that actualy does what we need:\n",
    "        src_cols = np.arange(startPos, obj.shape[-1]+1, spacing)\n",
    "        src_rows = np.arange(startPos, obj.shape[-2]+1, spacing)\n",
    "        src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "        return np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    def VelocityShapeForObject(obj):\n",
    "        return IWCentresForObject(obj).shape\n",
    "    \n",
    "    def ShiftObject(obj, shiftYX):\n",
    "        # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "        # I use a piecewise affine transformation that should approximately correspond to\n",
    "        # what I use for PIV analysis\n",
    "\n",
    "        src = IWCentresForObject(obj)\n",
    "        if (src.shape[0] != shiftYX.shape[0]):\n",
    "            assert(src.shape[0] == shiftYX.shape[0])\n",
    "        dst = src + shiftYX\n",
    "        tform = PiecewiseAffineTransform()\n",
    "        tform.estimate(src, dst)\n",
    "        # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "        maxVal = np.max(np.abs(obj))\n",
    "        if len(obj.shape) == 3:\n",
    "            result = np.zeros(obj.shape)\n",
    "            for cc in range(obj.shape[0]):\n",
    "                result[cc] = warp(obj[cc]/maxVal, tform) * maxVal\n",
    "            return result\n",
    "        else:\n",
    "            assert(len(obj.shape) == 2)\n",
    "            return warp(obj/maxVal, tform) * maxVal\n",
    "        \n",
    "    pivImagePair = tifffile.imread('piv-raw-data/038298.tif')[24:26,:15*20,:15*16]\n",
    "    if True:\n",
    "        plt.imshow(pivImagePair[0])\n",
    "        plt.show()\n",
    "        plt.imshow(pivImagePair[1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zPlaneToModel = _H.shape[0]-1   # Modelling native focal plane\n",
    "zPlaneToModel = 7   # Modelling some way from the native focal plane, which should perform fairly well\n",
    "zPlaneToModel = _H.shape[0]-2   # Modelling close to native focal plane\n",
    "\n",
    "pivHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=zPlaneToModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary experiments: don't use light field deconvolution at all\n",
    "# and just apply the warping directly to the AB images\n",
    "\n",
    "gShiftHistory = []\n",
    "gScoreHistory = []\n",
    "gCounter = 0\n",
    "\n",
    "def ScoreShiftByDirectWarping(candidateShiftYX, imageAB, scaling=1.0, log=True):\n",
    "    # Our input parameters get flattened, so we need to reshape them to Nx2 like my code is expecting\n",
    "    # 'scaling' is useful for optimizers that insist on initial very small step sizes\n",
    "    candidateShiftYX = candidateShiftYX.reshape(int(candidateShiftYX.shape[0]/2),2) * scaling\n",
    "\n",
    "    # Just warp the raw B image manually and look at how the two images compare\n",
    "    if log:\n",
    "        print('======== Score shift ========', candidateShiftYX.T)\n",
    "\n",
    "    candidateImageAB = imageAB.copy()\n",
    "    candidateImageAB[:,1,:,:] = ShiftObject(candidateImageAB[:,0,:,:], candidateShiftYX)\n",
    "    renormHack = np.average(candidateImageAB) / np.average(imageAB)\n",
    "    ssdScore = np.sum((candidateImageAB/renormHack - imageAB)**2)\n",
    "\n",
    "    print('return', ssdScore)\n",
    "\n",
    "    global gCounter\n",
    "    gCounter = gCounter + 1\n",
    "    gShiftHistory.append(candidateShiftYX[6,1])\n",
    "    gScoreHistory.append(ssdScore)\n",
    "    if log and ((gCounter%20) == 0):\n",
    "        plt.plot(gShiftHistory)\n",
    "        plt.show()\n",
    "        improvement = gScoreHistory[0] - np.min(gScoreHistory)\n",
    "        plt.ylim(np.min(gScoreHistory), gScoreHistory[0]+2*improvement)# Limit to avoid stupid guesses distorting the plot!\n",
    "        plt.plot(gScoreHistory)\n",
    "        plt.show()\n",
    "        \n",
    "        ShowObjectsAndFlow(candidateImageAB, candidateShiftYX)\n",
    "\n",
    "        with open('scores.txt', 'a') as f:\n",
    "            f.write('%f\\t' % ssdScore)\n",
    "            for n in candidateShiftYX:\n",
    "                f.write('%f\\t%f\\t' % (n[0], n[1]))\n",
    "            f.write('\\n')\n",
    "\n",
    "    return ssdScore\n",
    "\n",
    "def ShowObjectsAndFlow(dualObject, shiftDescription):\n",
    "    plt.imshow(dualObject[0,0])\n",
    "    plt.show()\n",
    "    plt.imshow(dualObject[0,1])\n",
    "    iwPos = IWCentresForObject(dualObject)\n",
    "    for n in range(iwPos.shape[0]):\n",
    "        plt.plot([iwPos[n,0], iwPos[n,0] - shiftDescription[n,0]], \\\n",
    "                 [iwPos[n,1], iwPos[n,1] - shiftDescription[n,1]], color='red')\n",
    "    plt.xlim(0, dualObject.shape[3])\n",
    "    plt.ylim(dualObject.shape[2], 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1)) *1e3#* 1e7\n",
    "\n",
    "iwPos = IWCentresForObject(dualObject)\n",
    "shiftDescription = np.zeros(VelocityShapeForObject(dualObject))\n",
    "for n in range(iwPos.shape[0]):\n",
    "    shiftDescription[n,1] = ((dualObject.shape[2]/2)**2 - (iwPos[n,0]-dualObject.shape[2]/2)**2) / 400\n",
    "#    shiftDescription[6,1] = 5\n",
    "\n",
    "dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "\n",
    "if True:\n",
    "    # Run the imaging cycle on each of the AB images individually (i.e. introduce artefacts into them)\n",
    "    dualObjectRecovered = dualObject.copy()\n",
    "    for n in [0, 1]:\n",
    "        cameraImage = forwardProjectACC(pivHMatrix, dualObject[:,n,:,:], logPrint=False)\n",
    "        backProjected = backwardProjectACC(pivHMatrix, cameraImage, logPrint=False)\n",
    "        dualObjectRecovered[:,n,:,:] = deconvRL(pivHMatrix, backProjected, maxIter=8, Xguess=backProjected, logPrint=False)\n",
    "\n",
    "if False:\n",
    "    # Temporary experiments to understand how things are behaving\n",
    "    # Remember that deconvRL takes different parameters to deconvRL_PIV\n",
    "\n",
    "    # The conclusion from these comparisons is that:\n",
    "    # - Code doesn't like tall images, and goes crazy. I think even my _original code may do the same...?\n",
    "    #   (on the face of it, wide images seem ok)\n",
    "    # - deconvRL and _PIV actually give slightly different results\n",
    "    #    (deconvRL seems better - is there a bug in deconvRL_PIV?)\n",
    "    # - Note that forwardProjectACC returns float64 - I should track down where that happens and reduce to float32\n",
    "    if True:\n",
    "        res4 = deconvRL(pivHMatrix, initialEstimate, maxIter=8, Xguess=initialEstimate)\n",
    "       \n",
    "print('Original object')\n",
    "ShowObjectsAndFlow(dualObject, shiftDescription)\n",
    "print('Recovered from light field images (plane %d)' % zPlaneToModel)\n",
    "ShowObjectsAndFlow(dualObjectRecovered, shiftDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using the images recovered following light field deconvolution\n",
    "objectToUse = dualObjectRecovered.copy()\n",
    "\n",
    "if True:\n",
    "    # Experimenting with fairly strict bounds for now\n",
    "    print('Applying fairly strict bounds')\n",
    "    lb = []\n",
    "    ub = []\n",
    "    print(shiftDescription)\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-20, shiftDescription[n,1]-20])\n",
    "        ub.extend([shiftDescription[n,0]+20, shiftDescription[n,1]+20])\n",
    "    theBounds = scipy.optimize.Bounds(lb, ub, True)\n",
    "\n",
    "    plt.imshow(objectToUse[0,0,:,:])\n",
    "    plt.show()\n",
    "    plt.imshow(objectToUse[0,1,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "    # Since I am only using a local minimizer, we need to start with a decent guess as to the flow.\n",
    "    # I think that's ok though: we should have that from a PIV estimate on the with-artefacts AB images\n",
    "    #initialShiftGuess = np.zeros(VelocityShapeForObject(dualObject))\n",
    "    initialShiftGuess = shiftDescription + np.random.random(shiftDescription.shape) * 4.0\n",
    "\n",
    "    print('correct', ScoreShiftByDirectWarping(shiftDescription.flatten(), objectToUse))\n",
    "    print('null', ScoreShiftByDirectWarping(initialShiftGuess.flatten(), objectToUse))\n",
    "\n",
    "    # Optimize to obtain the best-matching shift\n",
    "    if False:\n",
    "        shift = scipy.optimize.minimize(ScoreShiftByDirectWarping, initialShiftGuess, args=(objectToUse, 1e4), \\\n",
    "                                        method='Nelder-Mead', options={'eps': 5e-03, 'xatol': 1e-2})\n",
    "    elif False:\n",
    "        shift = scipy.optimize.minimize(ScoreShiftByDirectWarping, initialShiftGuess, args=(objectToUse, 1e4), \\\n",
    "                                        method='Nelder-Mead', options={'eps': 5e-03, 'xatol': 1e-2, 'adaptive': True})\n",
    "    elif False:\n",
    "        shift = scipy.optimize.minimize(ScoreShiftByDirectWarping, initialShiftGuess, args=(objectToUse, 1.0), \\\n",
    "                                        method='Powell', options={'eps': 5e-03, 'xtol': 1e-2})        \n",
    "    elif True:\n",
    "        # Frustrating that this requires the gradient, but it's quick to converge.\n",
    "        shift = scipy.optimize.minimize(ScoreShiftByDirectWarping, initialShiftGuess, args=(objectToUse, 1.0), \\\n",
    "                                        bounds=theBounds, \\\n",
    "                                        method='L-BFGS-B', options={'eps': 5e-03, 'gtol': 1e-6})                \n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gShiftHistory = []\n",
    "gScoreHistory = []\n",
    "\n",
    "def ScoreShift(candidateShiftYX, hMatrix, imageAB, scaling=1.0, log=True):\n",
    "    # Our input parameters get flattened, so we need to reshape them to Nx2 like my code is expecting\n",
    "    candidateShiftYX = candidateShiftYX.reshape(int(candidateShiftYX.shape[0]/2),2)\n",
    "    \n",
    "    # Perform the joint deconvolution to recover a single object\n",
    "    if log:\n",
    "        print('======== Score shift ========', candidateShiftYX)\n",
    "    res = deconvRL_PIV(hMatrix, imageAB, maxIter=8, shiftDescription=candidateShiftYX)\n",
    "\n",
    "    # Evaluate how well the forward-projected result matches the actual camera images, using SSD\n",
    "    candidateImageAB = forwardProjectACC_PIV(hMatrix, res, candidateShiftYX)\n",
    "    renormHack = np.average(candidateImageAB) / np.average(imageAB)\n",
    "    ssdScore = np.sum((candidateImageAB/renormHack - imageAB)**2)\n",
    "\n",
    "    gShiftHistory.append(candidateShiftYX[6,1])\n",
    "    gScoreHistory.append(ssdScore)\n",
    "    if log:\n",
    "        print('return', ssdScore)\n",
    "        plt.plot(gShiftHistory)\n",
    "        plt.show()\n",
    "        plt.plot(gScoreHistory)\n",
    "        plt.show()\n",
    "        with open('scores.txt', 'a') as f:\n",
    "            f.write('%f\\t' % ssdScore)\n",
    "            for n in candidateShiftYX:\n",
    "                f.write('%f\\t%f\\t' % (n[0], n[1]))\n",
    "            f.write('\\n')\n",
    "\n",
    "    return ssdScore\n",
    "\n",
    "if True:\n",
    "    # Run the actual optimizer to find the shift value for an input frame pair\n",
    "    if shift == 'uniform':\n",
    "        actualShifts = [(1,0)]#[(10,4), (0,0), (-4,17), (2,-7)]\n",
    "        for actualShift in actualShifts:\n",
    "            # Generate a camera image pair based on a chosen shift transform\n",
    "            imageAB = forwardProjectACC_PIV(pivHMatrix, obj, actualShift)\n",
    "            # Optimize to obtain the best-matching shift\n",
    "            shift = scipy.optimize.minimize(ScoreShift, (0,0), args=(pivHMatrix, imageAB), options={'eps': 5e-03})\n",
    "            print('shift', shift['x'], 'for actual shift', actualShift)\n",
    "    else:\n",
    "        if True:\n",
    "            # Treat each of pivImagePair as an object (one z plane),\n",
    "            # and forward-project to obtain to camera images        \n",
    "            imageAB = pivImagePair.copy().astype('float32')[np.newaxis,:,:,:]\n",
    "            if False:\n",
    "                print(\"WARNING: making pivImagePair square for now - seems to be a bug with tall images?\")\n",
    "                imageAB = imageAB[:,:,:15*16,:15*16]\n",
    "            imageAB = forwardProjectACC(pivHMatrix, imageAB)\n",
    "        elif False:\n",
    "            print(\"WARNING: overriding imageAB with Prevedel image\")\n",
    "            imageAB = np.tile(inputImage.copy()[np.newaxis,:,:], (2,1,1))\n",
    "        else:\n",
    "            # Generate a camera image pair based on a chosen shift transform\n",
    "            print(\"WARNING: using synthetic image\")\n",
    "            imageAB = forwardProjectACC_PIV(pivHMatrix, obj, np.array([1,0]))\n",
    "\n",
    "        if False:\n",
    "            print(\"WARNING: providing two identical images as a test\")\n",
    "            imageAB[1] = imageAB[0]\n",
    "        \n",
    "        initialShiftGuess = np.zeros(VelocityShapeForObject(imageAB))\n",
    "        # Just see what object I recover, for now.\n",
    "        candidateShiftYX = initialShiftGuess\n",
    "        initialEstimate = fusedBackwardProjectACC_PIV(pivHMatrix, imageAB, candidateShiftYX)\n",
    "\n",
    "        if False:\n",
    "            # Temporary experiments to understand how things are behaving\n",
    "            # Remember that deconvRL takes different parameters to deconvRL_PIV\n",
    "\n",
    "            # The conclusion from these comparisons is that:\n",
    "            # - Code doesn't like tall images, and goes crazy. I think even my _original code may do the same...?\n",
    "            #   (on the face of it, wide images seem ok)\n",
    "            # - deconvRL and _PIV actually give slightly different results\n",
    "            #    (deconvRL seems better - is there a bug in deconvRL_PIV?)\n",
    "            # - Note that forwardProjectACC returns float64 - I should track down where that happens and reduce to float32\n",
    "            if True:\n",
    "                res4 = deconvRL(pivHMatrix, initialEstimate, maxIter=8, Xguess=initialEstimate)\n",
    "            if True:\n",
    "                testResultOld = backwardProjectForZ_old(pivHMatrix.Hcc(0, True), imageAB[0])\n",
    "                testResultNew = projectForZ2(pivHMatrix, True, 0, imageAB[0])\n",
    "\n",
    "                HXguess = forwardProjectACC(pivHMatrix, initialEstimate)\n",
    "                HXguessBack = backwardProjectACC(pivHMatrix, HXguess)\n",
    "                errorBack = initialEstimate / HXguessBack\n",
    "                res2 = initialEstimate * errorBack\n",
    "\n",
    "            res3 = deconvRL_PIV(pivHMatrix, imageAB, maxIter=8, shiftDescription=initialShiftGuess)\n",
    "\n",
    "            if True:\n",
    "                Xguess = initialEstimate.copy()\n",
    "                relativeBlurDual = imageAB / forwardProjectACC_PIV(pivHMatrix, Xguess, initialShiftGuess)\n",
    "                Xguess *= fusedBackwardProjectACC_PIV(pivHMatrix, relativeBlurDual, initialShiftGuess)\n",
    "                Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "                res = Xguess\n",
    "            else:\n",
    "                res = res3\n",
    "\n",
    "            candidateImageAB = forwardProjectACC_PIV(pivHMatrix, res, candidateShiftYX)\n",
    "            # Evaluate the match using SSD\n",
    "            renormHack = np.average(candidateImageAB) / np.average(imageAB)\n",
    "            ssdScore = np.sum((candidateImageAB/renormHack - imageAB)**2)\n",
    "            print('score', ssdScore)\n",
    "        elif True:\n",
    "            # Optimize to obtain the best-matching shift\n",
    "            shift = scipy.optimize.minimize(ScoreShift, initialShiftGuess, args=(pivHMatrix, imageAB), \\\n",
    "                                            method='BFGS', options={'eps': 5e-03, 'gtol': 1e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowDiff(a, b):\n",
    "    difference = np.abs(a-b)\n",
    "    difference[0,0] = np.max(np.abs(a))\n",
    "    plt.imshow(difference)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('imageAB')\n",
    "plt.imshow(imageAB[0])\n",
    "plt.show()\n",
    "plt.imshow(imageAB[1])\n",
    "plt.show()\n",
    "\n",
    "print('candidateImageAB')\n",
    "plt.imshow(candidateImageAB[0])\n",
    "plt.show()\n",
    "plt.imshow(candidateImageAB[1])\n",
    "plt.show()\n",
    "\n",
    "print('pivImagePair[0]')\n",
    "plt.imshow(pivImagePair[0])\n",
    "plt.show()\n",
    "\n",
    "print('initialEstimate', initialEstimate.shape, np.min(initialEstimate), np.max(initialEstimate))\n",
    "# Third dimension of initialEstimate is the z plane (there is only one estimate from fusedBackProject)\n",
    "plt.imshow(initialEstimate[0])\n",
    "plt.show()\n",
    "\n",
    "# res2 represents the object, so again this is 3D (third dimension is z)\n",
    "print('res2 - deconvRL manual 1 iter', res2.shape)\n",
    "plt.imshow(res2[0])\n",
    "plt.show()\n",
    "\n",
    "print('res4 - deconvRL', res4.shape)\n",
    "plt.imshow(res4[0])\n",
    "plt.show()\n",
    "\n",
    "print('res - deconvRL_PIV manual 1 iter', res.shape)\n",
    "plt.imshow(res[0])\n",
    "plt.show()\n",
    "\n",
    "print('res3 - deconvRL_PIV3', res3.shape)\n",
    "plt.imshow(res3[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand how the optimizer is behaving, scan the search space rather than optimizing\n",
    "actualShift = (1,0)\n",
    "# Generate a camera image pair based on a chosen shift transform\n",
    "imageAB = forwardProjectACC_PIV(thisH, obj, actualShift)\n",
    "scores = []\n",
    "for dx in range(-2,4,1):\n",
    "    scores.append([dx, ScoreShift(np.array([dx,0]), imageAB)])\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives a nice clear quadratic minimum, although biased to about 1.5 (true shift 1.0).\n",
    "# I should remember that I don't expect a perfect result in the native focal plane!\n",
    "# That said, the very small numbers being trialled by the optimizer on my mac pro do not bode well!\n",
    "# Needs more investigation (and I should log each trial that is made)\n",
    "# Very clear quadratic minimum at 1.0 when I use z plane index 7. This is good news!\n",
    "\n",
    "# Next steps:\n",
    "# 1. Investigate why the mac pro optimizer did not converge to the correct minimum.\n",
    "# 2. See if there's a way to allow optimizer to stop when converged to 0.1 accuracy(!), and/or investigate which is the best optimizer\n",
    "# 3. Write code to compare against PIV performed on independent reconstructions\n",
    "# 4. Expand the PIV code to more than one z plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores[:,0], scores[:,1], 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
