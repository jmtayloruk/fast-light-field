{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook implementing fast light field deconvolution, and motion-aware deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, time, warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import cProfile, pstats\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage, scipy.optimize, scipy.io\n",
    "from scipy.optimize import Bounds\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "\n",
    "from hmatrix import HMatrix, LoadMatrix\n",
    "import jutils as util\n",
    "import lfdeconv, projector, lfimage\n",
    "\n",
    "# I don't know if these are necessary, but it has been suggested that low-level threading\n",
    "# does not interact well with the joblib Parallel feature.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_DYNAMIC'] = 'FALSE'\n",
    "\n",
    "# My code expects these to start as None, and I want to do this right at the top\n",
    "# to minimize the rish of accidentally resetting them to None after I've spent hours\n",
    "# accumulating valuable data in them!\n",
    "shiftHistoryJoint = None\n",
    "shiftHistoryRaw = None\n",
    "shiftHistoryNaive = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the PSF matrix we will use in this notebook\n",
    "if False:\n",
    "    # This is the definitive, full PSF matrix\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M22.2NA0.5MLPitch125fml3125from-110to110zspacing4Nnum19lambda520n1.33.mat'\n",
    "elif True:\n",
    "    # This is a smaller one (so that things don't take forever to run)\n",
    "    warnings.warn('WARNING: Switched to faster matrix for testing')\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-26to0zspacing2Nnum15lambda520n1.0.mat'\n",
    "elif True:\n",
    "    # This closer-spaced one is useful for focusing on native-focal-plane artefacts in flow analysis\n",
    "    warnings.warn('WARNING: Switched to faster and closer-spaced matrix for testing')\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat'   \n",
    "\n",
    "# Load the matrix information\n",
    "_HPathFormat, _HtPathFormat, _HReducedShape, _HtReducedShape = LoadMatrix(matPath)\n",
    "\n",
    "# Load an input image\n",
    "inputImage = lfimage.LoadLightFieldTiff('Data/02_Rectified/exampleData/20131219WORM2_small_full_neg_X1_N15_cropped_uncompressed.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for flow field (single-plane toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two identical images of the same synthetic object,\n",
    "# which for now consists of a cloud of random gaussian spots\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "if False:\n",
    "    numSpots = 100\n",
    "    imageSize = 240\n",
    "    sigma = 8\n",
    "    controlPointSpacing = 30    \n",
    "elif False:\n",
    "    numSpots = 400\n",
    "    imageSize = 120\n",
    "    sigma = 2\n",
    "    controlPointSpacing = 30\n",
    "else:\n",
    "    numSpots = 1000\n",
    "    imageSize = 180\n",
    "    sigma = 2\n",
    "    controlPointSpacing = 30\n",
    "syntheticImageExtendSize = 30\n",
    "\n",
    "syntheticObjectExt = np.zeros((1, imageSize+syntheticImageExtendSize, imageSize))\n",
    "syntheticObjectExt[0, (np.random.random(numSpots)*syntheticObjectExt.shape[1]).astype('int'), \\\n",
    "                      (np.random.random(numSpots)*syntheticObjectExt.shape[2]).astype('int')] = 1\n",
    "syntheticObjectExt = gaussian_filter(syntheticObjectExt, sigma=(0,sigma,sigma))\n",
    "plt.imshow(syntheticObjectExt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PSF that we will use\n",
    "\n",
    "# First check we're using the expected PSF - the plane choices used here are intended to work with this PSF.\n",
    "assert(matPath == 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat')\n",
    "\n",
    "zPlaneToModel = _H.shape[0]-1   # Modelling native focal plane\n",
    "zPlaneToModel = 7   # Modelling some way from the native focal plane, which should perform fairly well\n",
    "zPlaneToModel = _H.shape[0]-3   # Modelling close to native focal plane. This has artefacts - prev one is fairly artefact-free\n",
    "zPlaneToModel = _H.shape[0]-2\n",
    "\n",
    "\n",
    "pivHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=zPlaneToModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    shiftType = 'piv'\n",
    "    source = 'synthetic'\n",
    "    actualImageExtendSize = syntheticImageExtendSize\n",
    "    # Allowing an x search range is fairer, but it makes little difference for vertical flow\n",
    "    xMotionPermitted = False\n",
    "    xSearchRange = 0\n",
    "    ySearchRange = 10\n",
    "else:\n",
    "    shiftType = 'piv-zeroedge'\n",
    "    source = 'piv'\n",
    "    actualImageExtendSize = 0\n",
    "    xMotionPermitted = True\n",
    "    xSearchRange = 8\n",
    "    ySearchRange = 8\n",
    "\n",
    "\n",
    "def forwardProjectACC_PIV(hMatrix, obj, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return forwardProjectACC(hMatrix, dualObject, logPrint=False, progress=None)\n",
    "\n",
    "def dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    # Compute the reverse transform given the AB images (B image shifted by shiftYX).\n",
    "    # First we do the reverse transformation on both images\n",
    "    dualObject = backwardProjectACC(hMatrix, dualProjection, logPrint=False, progress=None)\n",
    "    # Now we reverse the shift on the B object\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    # Now, ideally the objects would match, but of course in practice there will be discrepancies,\n",
    "    # especially if we are not using the correct shiftDescription.\n",
    "    # To make the operation match the transpose of the forward operation,\n",
    "    # we add the two objects and divide by 2 here\n",
    "    return dualObject\n",
    "\n",
    "def fusedBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def deconvRL_PIV_OLD(hMatrix, imageAB, maxIter, Xguess, shiftDescription):\n",
    "    # I believed this to be the RL algorithm in the way I have written it in the past.\n",
    "    # However, this gives different results to Prevedel's implementation\n",
    "    # (mine seems to converge more slowly).\n",
    "    # TODO: I should look into this and see if I've just made a mistake or if they are actually different.\n",
    "    \n",
    "    # Xguess is our single combined guess of the object\n",
    "    Xguess = Xguess.copy()    # Because we will be updating it, and caller may not always be expecting that\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        relativeBlurDual = imageAB / forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        Xguess *= fusedBackwardProjectACC_PIV(hMatrix, relativeBlurDual, shiftDescription)\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def deconvRL_PIV(hMatrix, imageAB, maxIter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    Htf = fusedBackwardProjectACC_PIV(hMatrix, imageAB, shiftDescription)\n",
    "    Xguess = Htf.copy()\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        HXguessBack = fusedBackwardProjectACC_PIV(hMatrix, HXguess, shiftDescription)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def RollNoninteger(obj, amount, axis=0):\n",
    "    intAmount = math.floor(amount)\n",
    "    frac = amount - intAmount\n",
    "    result1 = np.roll(obj, intAmount, axis=axis)\n",
    "    result2 = np.roll(obj, intAmount+1, axis=axis)\n",
    "    return result1 * (1-frac) + result2 * frac\n",
    "\n",
    "\n",
    "# Some replacement functions to use for testing (effective PSF is a delta function, 1:1 mapping from image to object)\n",
    "def forwardProjectTrivial(hMatrix, obj, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return dualObject[0]\n",
    "\n",
    "def dualBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualProjection[np.newaxis].copy()\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    return dualObject\n",
    "\n",
    "def fusedBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def deconvRLTrivial(hMatrix, imageAB, maxIter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    return fusedBackwardProjectTrivial(hMatrix, imageAB, shiftDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (shiftType == 'uniform') or (shiftType == 'uniformSK'):\n",
    "    if shiftType == 'uniform':\n",
    "        def ShiftObject(obj, shiftYX):\n",
    "            # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "            # For now I just consider a uniform translation in xy\n",
    "            # \n",
    "            # TODO: We need to worry about conserving energy during the shift. \n",
    "            # For now I will do a circular shift in order to avoid having to worry about this!\n",
    "            result = RollNoninteger(obj, shiftYX[0,0], axis=len(obj.shape)-2)\n",
    "            return RollNoninteger(result, shiftYX[0,1], axis=len(obj.shape)-1)\n",
    "    else:\n",
    "        # A lot of code duplication here, but it's just an experiment for now\n",
    "        def ShiftObject(obj, shiftYX):\n",
    "            # Generate control points in the corners of the image\n",
    "            src_cols = np.arange(0, obj.shape[-1]+1, obj.shape[-1])\n",
    "            src_rows = np.arange(0, obj.shape[-2]+1, obj.shape[-2])\n",
    "            src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "            src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "            dst = src + shiftYX[0]\n",
    "            tform = PiecewiseAffineTransform()\n",
    "            tform.estimate(src, dst)\n",
    "            # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "            maxVal = np.max(np.abs(obj))\n",
    "            if len(obj.shape) == 3:\n",
    "                result = np.zeros(obj.shape)\n",
    "                for cc in range(obj.shape[0]):\n",
    "                    result[cc] = warp(obj[cc]/maxVal, tform, mode='edge') * maxVal\n",
    "                return result\n",
    "            else:\n",
    "                return warp(obj/maxVal, tform, mode='edge') * maxVal\n",
    "    \n",
    "    def ExampleShiftDescriptionForObject(obj):\n",
    "        return np.array([[-10, 20]])\n",
    "    \n",
    "    def VelocityShapeForObject(obj):\n",
    "        return (2,)\n",
    "\n",
    "    def IWCentresForObject(obj):\n",
    "        return np.array([[int(obj.shape[-2]/2), int(obj.shape[-1]/2)]])\n",
    "\n",
    "else:\n",
    "    # Arbitrary motion described in terms of an array of control points at IWCentresForObject\n",
    "    assert((shiftType == 'piv') or (shiftType == 'piv-zeroedge'))\n",
    "    def IWCentresForObject(obj, st=shiftType):\n",
    "        startPos = 0\n",
    "        # Reusing the code from the skimage example, since that actualy does what we need:\n",
    "        if st == 'piv-zeroedge':\n",
    "            src_cols = np.arange(controlPointSpacing, obj.shape[-1], controlPointSpacing)\n",
    "            src_rows = np.arange(controlPointSpacing, obj.shape[-2]-actualImageExtendSize, controlPointSpacing)\n",
    "        else:\n",
    "            src_cols = np.arange(startPos, obj.shape[-1]+1, controlPointSpacing)\n",
    "            src_rows = np.arange(startPos, obj.shape[-2]+1-actualImageExtendSize, controlPointSpacing)\n",
    "        src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "        return np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    def VelocityShapeForObject(obj):\n",
    "        return IWCentresForObject(obj).shape\n",
    "    \n",
    "    def ExampleShiftDescriptionForObject(obj):\n",
    "        peakVelocity = 7\n",
    "        iwPos = IWCentresForObject(obj)\n",
    "        shiftDescription = np.zeros(VelocityShapeForObject(obj))\n",
    "        width = obj.shape[-1]\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            quadraticProfile = ((width/2)**2 - (iwPos[n,0]-width/2)**2)\n",
    "            quadraticProfile = quadraticProfile / ((width/2)**2) * peakVelocity\n",
    "            shiftDescription[n,1] = quadraticProfile\n",
    "        if xMotionPermitted:\n",
    "            return shiftDescription\n",
    "        else:\n",
    "            return shiftDescription[:,1:2]\n",
    "\n",
    "    def ExtraDuplicateRow(shifts, add=None):\n",
    "        assert(len(shifts.shape) == 2)\n",
    "        rowLength = int(np.sqrt(shifts.shape[0]))\n",
    "        shifts = np.reshape(shifts, (rowLength, rowLength, shifts.shape[1]))\n",
    "        toAppend = shifts[:,-1:,:].copy()\n",
    "        if add is not None:\n",
    "            toAppend += add\n",
    "        result = np.append(shifts, toAppend, axis=1)\n",
    "        return result.reshape(result.shape[0]*result.shape[1], result.shape[2])\n",
    "\n",
    "    def AddZeroEdgePadding(obj, src, shiftYX):\n",
    "        paddedSrc = IWCentresForObject(obj, st='piv')\n",
    "        paddedShifts = np.zeros(paddedSrc.shape)\n",
    "        for i in range(src.shape[0]):\n",
    "            match = False\n",
    "            for j in range(paddedSrc.shape[0]):\n",
    "                if (src[i] == paddedSrc[j]).all():\n",
    "                    match = True\n",
    "                    paddedShifts[j] = shiftYX[i]\n",
    "            assert(match)\n",
    "        return paddedSrc, paddedShifts\n",
    "        \n",
    "    def ShiftObject(obj, shiftYX):\n",
    "        # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "        # I use a piecewise affine transformation that should approximately correspond to\n",
    "        # what I use for PIV analysis\n",
    "        src = IWCentresForObject(obj)\n",
    "        if (src.shape[0] != shiftYX.shape[0]):\n",
    "            print(src.shape, shiftYX.shape, obj.shape)\n",
    "            assert(src.shape[0] == shiftYX.shape[0])\n",
    "            \n",
    "        if (shiftType == 'piv-zeroedge'):\n",
    "            (src, shiftYX) = AddZeroEdgePadding(obj, src, shiftYX)\n",
    "        \n",
    "        if (actualImageExtendSize > 0):\n",
    "            src = ExtraDuplicateRow(src, add=np.array([0, actualImageExtendSize]))\n",
    "            if xMotionPermitted:\n",
    "                dst = src + ExtraDuplicateRow(shiftYX)\n",
    "            else:\n",
    "                dst = src.copy().astype(shiftYX.dtype)\n",
    "                dst[:,1] = dst[:,1] + ExtraDuplicateRow(shiftYX)[:,0]\n",
    "        else:\n",
    "            dst = src.copy().astype(shiftYX.dtype) + shiftYX\n",
    "            \n",
    "        tform = PiecewiseAffineTransform()\n",
    "        tform.estimate(src, dst)\n",
    "        # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "        maxVal = np.max(np.abs(obj))\n",
    "        if len(obj.shape) == 3:\n",
    "            result = np.zeros(obj.shape)\n",
    "            for cc in range(obj.shape[0]):\n",
    "                result[cc] = warp(obj[cc]/maxVal, tform, mode='edge') * maxVal\n",
    "            return result\n",
    "        else:\n",
    "            assert(len(obj.shape) == 2)\n",
    "            return warp(obj/maxVal, tform, mode='edge') * maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if source == 'synthetic':\n",
    "    # Generate a synthetic shift in the B image\n",
    "    dualObject = np.tile(syntheticObjectExt[:,np.newaxis,:,:], (1,2,1,1)) *1e3#* 1e7\n",
    "    if False:\n",
    "        warnings.warn('Loading previously-saved dualObject')\n",
    "        dualObject = np.load('dualObject5.npy')\n",
    "    \n",
    "    shiftDescription = ExampleShiftDescriptionForObject(dualObject)\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "\n",
    "    # Since I am only using a local minimizer, we need to start with a decent guess as to the flow.\n",
    "    # I think that's ok though: we should have that from a PIV estimate on the with-artefacts AB images\n",
    "    #initialShiftGuess = np.zeros(VelocityShapeForObject(dualObject))\n",
    "    initialShiftGuess = shiftDescription + np.random.random(shiftDescription.shape) * 4.0\n",
    "else:\n",
    "    assert(source == 'piv')\n",
    "    pivImagePair = tifffile.imread('piv-raw-data/038298.tif')[24:26,:15*20,:15*16].astype('float64')\n",
    "    # Note: frames 57-58 (wrong pair) would be an option to investigate bigger motion (~16px) with imperfect AB matches\n",
    "    #              64-65 (correct pair) are another example of small movement (0-3px)\n",
    "    dualObject = pivImagePair[np.newaxis]\n",
    "    # For now, I just guess an initial shift of zero\n",
    "    shiftDescription = np.zeros(VelocityShapeForObject(dualObject)).astype('float64')\n",
    "    initialShiftGuess = shiftDescription.copy()\n",
    "    \n",
    "    \n",
    "lb = []\n",
    "ub = []\n",
    "if xMotionPermitted:\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-xSearchRange, shiftDescription[n,1]-ySearchRange])\n",
    "        ub.extend([shiftDescription[n,0]+xSearchRange, shiftDescription[n,1]+ySearchRange])\n",
    "else:\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-ySearchRange])\n",
    "        ub.extend([shiftDescription[n,0]+ySearchRange])\n",
    "shiftSearchBounds = scipy.optimize.Bounds(lb, ub, True)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dualObject[0,0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dualObject[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used for investigations in which I directly warp the input object/images,\n",
    "# without any use of light field PSFs and deconvolution\n",
    "\n",
    "def ScoreShift2(candidateShiftYX, method, imageAB, hMatrix=None, shiftHistory=None, scaling=1.0, log=True, comparator=None, maxIter=8):\n",
    "    return ScoreShift3(candidateShiftYX, method, imageAB, hMatrix, shiftHistory, scaling, log, comparator, maxIter=maxIter)[0]\n",
    "\n",
    "def ScoreShift3(candidateShiftYX, method, imageAB, hMatrix=None, shiftHistory=None, scaling=1.0, log=True, comparator=None, maxIter=8):\n",
    "    # Our input parameters get flattened, so we need to reshape them to Nx2 like my code is expecting\n",
    "    # 'scaling' is useful for optimizers that insist on initial very small step sizes\n",
    "    if xMotionPermitted:\n",
    "        candidateShiftYX = candidateShiftYX.reshape(int(candidateShiftYX.shape[0]/2),2) * scaling\n",
    "    else:\n",
    "        candidateShiftYX = candidateShiftYX.reshape(candidateShiftYX.shape[0],1) * scaling\n",
    "    # Sanity check and reminder that we have a 2xMxN AB image pair\n",
    "    assert(len(imageAB.shape) == 3)  \n",
    "    assert(imageAB.shape[0] == 2)\n",
    "        \n",
    "    if log:\n",
    "#        print('======== Score shift ========', candidateShiftYX.T)\n",
    "        print('======== Score shift ========')\n",
    "\n",
    "    if method == 'joint':\n",
    "        # Perform the joint deconvolution to recover a single object\n",
    "        res = deconvRL_PIV(hMatrix, imageAB, maxIter=maxIter, shiftDescription=candidateShiftYX)\n",
    "        # Evaluate how well the forward-projected result matches the actual camera images, using SSD\n",
    "        candidateImageAB = forwardProjectACC_PIV(hMatrix, res, candidateShiftYX)\n",
    "    elif method == 'joint-test-trivial':\n",
    "        # Debugging method in which I use trivial projectors that behave like a delta function PSF\n",
    "        res = deconvRLTrivial(hMatrix, imageAB, maxIter=maxIter, shiftDescription=candidateShiftYX)\n",
    "        candidateImageAB = forwardProjectTrivial(hMatrix, res, candidateShiftYX)\n",
    "    else:\n",
    "        # Just warp the raw B image manually and look at how the two images compare\n",
    "        assert(method == 'naive')\n",
    "        candidateImageAB = imageAB.copy()\n",
    "        # A bit of dimensional gymnastics here, because ShiftObject expects an *object*,\n",
    "        # i.e. a 3D volume, whereas in this case we just have a 2D image\n",
    "        candidateImageAB[1,:,:] = ShiftObject(candidateImageAB[np.newaxis,0,:,:], candidateShiftYX)[0]  \n",
    "        res = None  # So that we have something to return\n",
    "    # Sanity check and reminder that we have a 2xMxN AB image pair\n",
    "    assert(len(candidateImageAB.shape) == 3)  \n",
    "    assert(candidateImageAB.shape[0] == 2)\n",
    "\n",
    "    imageToScore = candidateImageAB[:, 1:-1-actualImageExtendSize, 1:-1-actualImageExtendSize]\n",
    "    referenceImage = imageAB[:, 1:-1-actualImageExtendSize, 1:-1-actualImageExtendSize]\n",
    "    # Score by comparing the A and B images to the ones we are optimizing on.\n",
    "    # Note: in some simulated or naive cases, the A camera images will always be a perfect match,\n",
    "    # but for the real case the joint solution will be a compromise for both the A and B camera images.\n",
    "    #\n",
    "    # I have tried to renormalize to aid comparison between the images - based on the relative intensity\n",
    "    # of the candidate and observed A images. I chose the A images because they will be identical in the case\n",
    "    # of the 'naive' method (direct warping). However, for the 'joint' method they won't be.\n",
    "    # TODO: I need to think more about whether this normalization is necessary and appropriate.\n",
    "    # (I think I introduced it in the hope of fixing a problem,\n",
    "    # but lack of normalization wasn't the fundamental issue in the end)\n",
    "    renormHack = np.average(candidateImageAB[0]) / np.average(imageAB[0])\n",
    "    ssdScore = np.sum((imageToScore/renormHack - referenceImage)**2)\n",
    "\n",
    "    if comparator is not None:\n",
    "        maxLoc = np.argmax(np.abs(imageToScore - comparator)[1:-1,1:-1])\n",
    "        maxVal =    np.max(np.abs(imageToScore - comparator)[1:-1,1:-1])\n",
    "        print('showing B image diffs')\n",
    "        plt.imshow((imageToScore[1] - comparator)[170:,150:])\n",
    "        plt.colorbar()\n",
    "        plt.title('BRel (max %e)'%maxVal)\n",
    "        print('Max val %f at %d (image scale %d)' % (maxVal, maxLoc, np.max(comparator)))\n",
    "        plt.show()\n",
    "\n",
    "    if shiftHistory is not None:\n",
    "        shiftHistory.Update(candidateShiftYX, ssdScore)\n",
    "        if log:\n",
    "            if shiftHistory.PlotHistory(onlyPlotEvery=20):\n",
    "                if method == 'joint':\n",
    "                    dualObject = np.tile(res[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "                    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "                    ShowDualObjectAndFlow(dualObject, candidateShiftYX)\n",
    "                else:\n",
    "                    ShowDualObjectAndFlow(candidateImageAB, candidateShiftYX)\n",
    "                print('Last trial shift: ', candidateShiftYX.T)\n",
    "\n",
    "    if log:\n",
    "        print('return %e' % ssdScore)\n",
    "    return (ssdScore, renormHack, np.average(candidateImageAB[0]), np.average(imageAB), candidateImageAB, res)\n",
    "\n",
    "def ShowDualObjectAndFlow(dualObject, shiftDescription, otherObject=None, otherObject2=None):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if (len(dualObject.shape) == 4):\n",
    "        assert(dualObject.shape[1] == 2)\n",
    "        plt.imshow(dualObject[0,0])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(dualObject[0,1])\n",
    "    else:\n",
    "        assert(len(dualObject.shape) == 3)  # It's actually a dual image not an object\n",
    "        assert(dualObject.shape[0] == 2)\n",
    "        plt.imshow(dualObject[1])\n",
    "    iwPos = IWCentresForObject(dualObject)\n",
    "    if xMotionPermitted == False:\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            plt.plot([iwPos[n,0], iwPos[n,0]], \\\n",
    "                     [iwPos[n,1], iwPos[n,1] - shiftDescription[n,0]/2], color='red')\n",
    "    else:\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            plt.plot([iwPos[n,0], iwPos[n,0] - shiftDescription[n,0]/2], \\\n",
    "                     [iwPos[n,1], iwPos[n,1] - shiftDescription[n,1]/2], color='red')\n",
    "    plt.xlim(0, dualObject.shape[-1])\n",
    "    plt.ylim(dualObject.shape[-2], 0)\n",
    "    plt.show()\n",
    "    if otherObject is not None:\n",
    "        plt.imshow(otherObject[0])\n",
    "        plt.show()        \n",
    "    if otherObject2 is not None:\n",
    "        plt.imshow(otherObject2[0])\n",
    "        plt.show()   \n",
    "        \n",
    "def CheckConvergence(funcToCall, convergedShift, args):\n",
    "    initialScore = funcToCall(convergedShift.flatten(), *args)\n",
    "    print('initial score', initialScore)\n",
    "    for du in [0.5, -0.5, 1.5, -1.5]:\n",
    "        for n in [7, 8, 12, 13]:\n",
    "            temp = convergedShift.copy()\n",
    "            temp[n] += du\n",
    "            score = funcToCall(temp, *args)\n",
    "            print('offset score', score)\n",
    "            if (score < initialScore):\n",
    "                print(n, du, 'BETTER! (by %f%%)' % ((initialScore-score)/score*100))\n",
    "\n",
    "def ReportOnOptimizerConvergence(shiftHistory, method, obj, hMatrix=None):\n",
    "    if shiftHistory is None:\n",
    "        print('ReportOnOptimizerConvergence returning - called with shiftHistory=None')\n",
    "        return\n",
    "    bestShift = shiftHistory.BestShift()\n",
    "    print('Best score:', shiftHistory.BestScore())\n",
    "    print('Best shift: np.array([', end='')\n",
    "    for n in bestShift.flatten():\n",
    "        print('%f, '%n, end='')\n",
    "    print('])')\n",
    "    CheckConvergence(ScoreShift2, bestShift.flatten(), (method, obj, hMatrix, None, 1.0, False))\n",
    "    return bestShift\n",
    "                \n",
    "class ShiftHistory:\n",
    "    def __init__(self):\n",
    "        self.Reset()\n",
    "\n",
    "    def __copy__(self):\n",
    "        result = ShiftHistory()\n",
    "        result.shiftHistory = self.shiftHistory\n",
    "        result.scoreHistory = self.scoreHistory\n",
    "        result.counter = self.counter\n",
    "        return result\n",
    "\n",
    "    def Reset(self):\n",
    "        self.scoreHistory = []\n",
    "        self.shiftHistory = []\n",
    "        self.counter = 0\n",
    "    \n",
    "    def Update(self, shift, score):\n",
    "        self.shiftHistory.append(shift)\n",
    "        self.scoreHistory.append(score)\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "    def BestScore(self):\n",
    "        return np.min(self.scoreHistory)\n",
    "\n",
    "    def BestShift(self):\n",
    "        return self.shiftHistory[np.argmin(self.scoreHistory)]\n",
    "\n",
    "    def PlotHistory(self, onlyPlotEvery=1):\n",
    "        if ((self.counter%onlyPlotEvery) == 0) and (len(self.shiftHistory) > 0):\n",
    "            print('best score so far: %e' % np.min(self.scoreHistory))\n",
    "            # Plot one of the shifts\n",
    "            shiftShape = self.shiftHistory[0].shape\n",
    "            selectedItem = np.minimum(int(np.sqrt(shiftShape[0])/2), shiftShape[0]-1)\n",
    "            selectedShift = np.array(self.shiftHistory)[:, selectedItem, -1]\n",
    "            plt.plot(selectedShift)\n",
    "            plt.show()\n",
    "            # Plot scores, with a suitable y axis scaling to see the interesting parts.\n",
    "            # We limit the y axis to avoid stupid guesses distorting the plot.\n",
    "            improvement = self.scoreHistory[0] - np.min(self.scoreHistory)\n",
    "            plt.ylim(np.min(self.scoreHistory), self.scoreHistory[0]+2*improvement)\n",
    "            plt.plot(self.scoreHistory)\n",
    "            plt.show()\n",
    "            # Plot an indication of which values are being updated on which iteration\n",
    "            for n in range(1, len(self.scoreHistory)):\n",
    "                changes = np.array(np.where((self.shiftHistory[n] == self.shiftHistory[n-1]).flatten() == False))\n",
    "                if (changes.size > 0):\n",
    "                    plt.plot(n, changes, 'x', color='red')\n",
    "            plt.show()\n",
    "\n",
    "            with open('scores.txt', 'a') as f:\n",
    "                f.write('%f\\t' % self.scoreHistory[-1])\n",
    "                for n in self.shiftHistory[-1]:\n",
    "                    if xMotionPermitted:\n",
    "                        f.write('%f\\t%f\\t' % (n[0], n[1]))\n",
    "                    else:\n",
    "                        f.write('%f\\t' % (n[0]))\n",
    "                f.write('\\n')\n",
    "            return True\n",
    "        else:\n",
    "            return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate synthetic light-field-recovered AB images (doing it the naive way, not using my new joint deconvolution)\n",
    "# Run the imaging cycle on each of the AB images individually (i.e. introduce artefacts into them)\n",
    "dualObjectRecovered = dualObject.copy()\n",
    "for n in [0, 1]:\n",
    "    cameraImage = forwardProjectACC(pivHMatrix, dualObject[:,n,:,:], logPrint=False)\n",
    "    backProjected = backwardProjectACC(pivHMatrix, cameraImage, logPrint=False)\n",
    "    \n",
    "    # With the shifted images, we have problems with true zeroes in regions that have no features remaining.\n",
    "    # To avoid this, I apply a very small nonzero background so that the deconvolution doesn't fail.\n",
    "    backProjected = np.maximum(backProjected, 1e-5*np.max(backProjected))\n",
    "    \n",
    "    dualObjectRecovered[:,n,:,:] = deconvRL(pivHMatrix, backProjected, maxIter=8, Xguess=backProjected, logPrint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original object')\n",
    "iwPos = IWCentresForObject(dualObject)\n",
    "ShowDualObjectAndFlow(dualObject, shiftDescription)\n",
    "print('Recovered from light field images (plane %d)' % zPlaneToModel)\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, shiftDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # If I want to give the algorithm the best possible starting point,\n",
    "    # I can give it the actual true shift values as its starting point\n",
    "    # (but it still may iterate away from that...)\n",
    "    warnings.warn(\"WARNING: starting guess is actually the correct flow description\")\n",
    "    startShiftForOptimizer = shiftDescription.copy()\n",
    "else:\n",
    "    startShiftForOptimizer = initialShiftGuess.copy()\n",
    "\n",
    "    \n",
    "def OptimizeToRecoverFlowField(method, imageAB, hMatrix, shiftDescription, initialShiftGuess, shiftHistory=None):\n",
    "    imageAB = imageAB.copy()    # This is just paranoia - I don't think it should get manipulated\n",
    "    print('True shift:', shiftDescription.T)\n",
    "\n",
    "    if False:\n",
    "        plt.imshow(imageAB[0,:,:])\n",
    "        plt.show()\n",
    "        plt.imshow(imageAB[1,:,:])\n",
    "        plt.show()\n",
    "\n",
    "    if False:\n",
    "        print('Score for correct shift:', ScoreShift2(shiftDescription.flatten(), method, imageAB, hMatrix))\n",
    "        print('Score for initial guess:', ScoreShift2(initialShiftGuess.flatten(), method, imageAB, hMatrix))\n",
    "\n",
    "    if True:\n",
    "        optimizationAlgorithm = 'Powell'\n",
    "        options = {'xtol': 1e-2}\n",
    "    elif True:\n",
    "        optimizationAlgorithm = 'L-BFGS-B'\n",
    "        options = {'eps': 5e-03, 'gtol': 1e-6}\n",
    "    else:\n",
    "        optimizationAlgorithm = 'Nelder-Mead'\n",
    "        options = {'eps': 5e-03, 'xatol': 1e-2, 'adaptive': True}\n",
    "\n",
    "    if shiftHistory is None:\n",
    "        shiftHistory = ShiftHistory()\n",
    "\n",
    "    # Optimize to obtain the best-matching shift\n",
    "    try:\n",
    "        shift = scipy.optimize.minimize(ScoreShift2, initialShiftGuess, bounds=shiftSearchBounds, args=(method, imageAB, hMatrix, shiftHistory), method=optimizationAlgorithm, options=options)\n",
    "        print('Optimizer finished:', str(shift.message), 'Final shift:', shift.x.T)\n",
    "    except KeyboardInterrupt:\n",
    "        # Catch keyboard interrupts so that we still return whatever shiftHistory we have built up so far.\n",
    "        print('KEYBOARD INTERRUPT DURING OPTIMIZATION')\n",
    "    return shiftHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using direct shift-matching of the raw input images (real experimental SPIM images)\n",
    "if False:\n",
    "    shiftHistoryRaw = OptimizeToRecoverFlowField('naive', dualObject[0], None, shiftDescription, startShiftForOptimizer)\n",
    "\n",
    "# Note: if continuing a previously-interrupted run then we can do this to pick up roughly where we left off.\n",
    "# i.e. provide BestShift() for the two shift-related input parameters, and pass the existing shift history as the final (optional) parameter\n",
    "#    shiftHistoryRaw = OptimizeToRecoverFlowField('naive', dualObject[0], None, shiftHistoryRaw.BestShift(), shiftHistoryRaw.BestShift(), shiftHistoryRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bestShift = ReportOnOptimizerConvergence(shiftHistoryRaw, 'naive', dualObject[0])\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using direct shift-matching of the light-field-deconvolved images\n",
    "if False:\n",
    "    shiftHistoryNaive = OptimizeToRecoverFlowField('naive', dualObjectRecovered[0], None, shiftDescription, startShiftForOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ReportOnOptimizerConvergence(shiftHistoryNaive, 'naive', dualObjectRecovered[0])\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using my new joint algorithm\n",
    "if True:\n",
    "    # Generate a camera image pair from the object.\n",
    "    if source == 'piv':\n",
    "        # The camera AB images are determined by separate forward projection of the AB spim images\n",
    "        imageAB = forwardProjectACC(pivHMatrix, dualObject)\n",
    "    else:\n",
    "        # The synthetic B image is determined with the help of the chosen shift transform.\n",
    "        imageAB = forwardProjectACC(pivHMatrix, dualObject[:,0,:,:])\n",
    "\n",
    "    if False:\n",
    "        # Try starting using the solution obtained by direct warping of AB image pair,\n",
    "        # to see if that yields a better minimum than the one I had found so far\n",
    "        startShiftForOptimizer = np.array([4.179692, 2.422054, 2.277945, -3.442326, 2.588265, -1.628299, -0.701406, -0.351879, 1.371176, -0.887983, -0.329903, -1.814173, -0.039174, -1.546245, 4.530734, 6.433376, -3.923658, 0.765194, -3.139235, 11.998391, 0.159123, 4.712269, 0.000467, 1.881291, -1.076288, 2.571115, -0.752311, 6.346806, 0.705785, 1.599266, 0.526477, 0.520794, 1.613503, -0.944800, -4.052433, 0.938896, -9.285762, 9.058932, -1.427279, 3.465706, -2.667963, 6.611281, -2.711337, 6.691590, 1.149587, 6.157966, 5.232333, 7.419857, 3.860831, 0.035423, 1.096535, -0.919879, 1.315764, 0.783761, -1.649745, 1.829128, -1.506330, 2.903395, -2.640247, 6.333610, -2.974801, 5.116153, -1.640844, 6.727836, 6.771447, 5.497423, 7.318270, 3.963571, -1.879130, 0.376258, -2.545277, 3.033343, -1.405359, 2.988077, -3.664550, 3.713645, -2.404847, 3.906314, -0.068660, 0.731329, 3.443943, 1.132651, 8.621877, 2.114740, 4.915054, 3.548191, 3.346262, 5.315995, -2.250714, 3.869669, -3.046189, 2.948226, -1.592374, 0.569959, -0.875566, 0.699708, -0.309011, -0.220754, 2.785740, 4.885732, 1.892708, 2.223612, 5.977712, 3.248553, 1.007629, 3.325284, -0.803304, 5.829418, -2.376718, 0.837404, 0.982720, 0.897666, -1.992212, 4.365900, -0.497122, 3.024971, -0.809540, 2.668115, 3.179223, -4.673659, 3.866968, 0.850031, 2.411868, 0.370574, 3.250005, 2.128673])\n",
    "\n",
    "    # Run the joint optimizer optimizer to find the shift value for an input frame pair\n",
    "    shiftHistoryJoint = OptimizeToRecoverFlowField('joint', imageAB, pivHMatrix, shiftDescription, startShiftForOptimizer, shiftHistoryJoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    np.save('shiftHistoryJoint.npy', shiftHistoryJoint.shiftHistory)\n",
    "    np.save('scoreHistoryJoint.npy', shiftHistoryJoint.scoreHistory)\n",
    "    np.save('dualObjectJoint.npy', dualObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ReportOnOptimizerConvergence(shiftHistoryJoint, 'joint', imageAB, pivHMatrix)\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at how the scores are evolving during the powell iterations\n",
    "\n",
    "if True:\n",
    "    vals = np.array(shiftHistoryJoint.shiftHistory)\n",
    "    scores = np.array(shiftHistoryJoint.scoreHistory)\n",
    "else:\n",
    "    # Load from files previously saving using:\n",
    "    #   np.save('scoreHistory.npy', np.array(shiftHistoryJoint.scoreHistory))\n",
    "    #   np.save('shiftHistory.npy', np.array(shiftHistoryJoint.shiftHistory))\n",
    "    vals = np.load('/Users/jonny/Desktop/shiftHistory.npy')\n",
    "    scores = np.load('/Users/jonny/Desktop/scoreHistory.npy')\n",
    "iwOfInterest = 5*7+3\n",
    "iwOfInterest = 5*7+6# Looking at border control point for shiftHistoryNaive\n",
    "x = []\n",
    "y = []\n",
    "y2 = []\n",
    "\n",
    "if False:\n",
    "    # Compare the results from different control points\n",
    "    sh = vals[3020].flatten()\n",
    "    sh[iwOfInterest] = 5.011\n",
    "    (_,_,_,_,comp) = ScoreShift3(sh, 'naive', objectToUse, log=False)    \n",
    "    for d in [5.012, 5.0135, 5.0145]:\n",
    "        sh[iwOfInterest] = d\n",
    "        sc = ScoreShift2(sh, 'naive', objectToUse[0], log=False, comparator=comp)\n",
    "        print('score', sc)\n",
    "\n",
    "if True:\n",
    "    for iw in [iwOfInterest]:\n",
    "#    for iw in range(49):\n",
    "        for n in range(0,vals.shape[0]-1):\n",
    "            if (vals[n,iw,0] != vals[n+1,iw,0]):\n",
    "                x.append(vals[n,iw,0])\n",
    "                y.append(scores[n])\n",
    "            else:\n",
    "                if (len(x) > 0):\n",
    "                    if (len(x) > 2):\n",
    "                        plt.plot(x, y, 'x')\n",
    "                        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "                        plt.show()\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    y2 = []\n",
    "                nStart = n\n",
    "    if (len(x) > 2):\n",
    "        plt.plot(x, y, 'x')\n",
    "        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code useful for understanding how two images differ, since I have been having\n",
    "# a lot of problems related to warp(), where tiny changes in shifts make a difference to the result\n",
    "# (these are largely due to edge effects of one type or another)\n",
    "def ShowDifferences(im1, im2, fullIm1, sh):\n",
    "    diff = im1-im2\n",
    "    print(diff.shape)\n",
    "    print('Largest difference', np.max(np.abs(diff)), 'loc', np.argmax(np.abs(diff)), \\\n",
    "          np.argmax(np.abs(diff))%diff.shape[1], int(np.argmax(np.abs(diff))/diff.shape[1]))\n",
    "    plt.imshow(diff)\n",
    "    iwPos = IWCentresForObject(dualObject, st='piv')\n",
    "    if False:\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            plt.plot(iwPos[n,0], iwPos[n,1], 'x', color='red')\n",
    "    elif True:\n",
    "        src = IWCentresForObject(fullIm1[np.newaxis])\n",
    "        if (src.shape[0] != sh.shape[0]):\n",
    "            assert(src.shape[0] == sh.shape[0])\n",
    "        if (shiftType == 'piv-zeroedge'):\n",
    "            (src, sh) = AddZeroEdgePadding(fullIm1[np.newaxis], src, sh)\n",
    "            print('padded')\n",
    "        for n in range(sh.shape[0]):\n",
    "            plt.plot([iwPos[n,0], iwPos[n,0]+sh[n,0]*1e9], \\\n",
    "                     [iwPos[n,1], iwPos[n,1]+sh[n,1]*1e9], color='red')\n",
    "            if not sh[n,0] == 0:\n",
    "                print('x', [iwPos[n,0], iwPos[n,0]+sh[n,0]*1e9])\n",
    "                print('y', [iwPos[n,1], iwPos[n,1]+sh[n,1]*1e9])\n",
    "    plt.xlim(-10,60)\n",
    "    plt.ylim(80,-10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand how the optimizer is behaving, scan the search space rather than optimizing\n",
    "\n",
    "# Generate a camera image pair from the object.\n",
    "# The B image is determined with the help of the chosen shift transform.\n",
    "imageAB = forwardProjectACC_PIV(pivHMatrix, dualObject[:,0,:,:], shiftDescription)\n",
    "# Run the joint optimizer optimizer to find the shift value for an input frame pair\n",
    "shiftHistorySearch = ShiftHistory()\n",
    "candidateShiftYX = startShiftForOptimizer.copy()\n",
    "for dx in range(-4,5,1):\n",
    "#    candidateShiftYX[4*11+3] = dx\n",
    "#    [5147746000.0, 4475782000.0, 3882488600.0, 3441547500.0, 3223274800.0, 3499643600.0, 4056565800.0, 4845896000.0, 5856099300.0]\n",
    "    candidateShiftYX[3*11+5] = dx\n",
    "    ScoreShift2(candidateShiftYX.flatten(), 'joint', imageAB, pivHMatrix, shiftHistorySearch, log=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shiftHistorySearch.scoreHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
