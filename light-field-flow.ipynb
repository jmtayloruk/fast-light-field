{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook implementing fast light field deconvolution, and motion-aware deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, time, datetime, warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import cProfile, pstats\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import psfmatrix\n",
    "import jutils as util\n",
    "import lfdeconv, lfdeconv_piv, projector, lfimage\n",
    "import motion_recovery as recovery\n",
    "import flow\n",
    "\n",
    "# My code expects these to start as None, and I want to do this right at the top\n",
    "# to minimize the risk of accidentally resetting them to None after I've spent hours\n",
    "# accumulating valuable data in them!\n",
    "shiftHistoryJoint = None\n",
    "shiftHistoryRaw = None\n",
    "shiftHistoryNaive = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the PSF matrix we will use in this notebook.\n",
    "# This closer-spaced one is useful for focusing on native-focal-plane artefacts in flow analysis.\n",
    "matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat'   \n",
    "\n",
    "# For now I am only actually simulating flow in a single plane (imaged with light field microscopy),\n",
    "# so we set up a single-plane PSF to work from.\n",
    "fullHMatrix = psfmatrix.LoadMatrix(matPath)\n",
    "zPlaneToModel = fullHMatrix.numZ-1   # Modelling native focal plane\n",
    "zPlaneToModel = 7   # Modelling some way from the native focal plane, which should perform fairly well\n",
    "zPlaneToModel = fullHMatrix.numZ-3   # Modelling close to native focal plane. This has artefacts - prev one is fairly artefact-free\n",
    "zPlaneToModel = fullHMatrix.numZ-2\n",
    "pivHMatrix = psfmatrix.LoadMatrix(matPath, numZ=1, zStart=zPlaneToModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two identical images of the same synthetic object,\n",
    "# which for now consists of a cloud of random gaussian spots\n",
    "numSpots = 1000\n",
    "imageSize = 180\n",
    "sigma = 2\n",
    "controlPointSpacing = 30\n",
    "previouslySavedSynthetic = '2019-06-23 18.10.19 syntheticInput.npy'\n",
    "\n",
    "syntheticImageExtendSize = 30       # TODO: document the purpose of this\n",
    "syntheticObjectExt = np.zeros((1, imageSize+syntheticImageExtendSize, imageSize), dtype='float32')\n",
    "if previouslySavedSynthetic is not None:\n",
    "    # Load a synthetic object that we saved from a previous run\n",
    "    # (This is useful for reproducible behaviour)\n",
    "    syntheticObjectExt[0] = np.load(previouslySavedSynthetic)\n",
    "else:\n",
    "    # Generate a synthetic object, and save it to disk for reference\n",
    "    syntheticObjectExt[0, (np.random.random(numSpots)*syntheticObjectExt.shape[1]).astype('int'), \\\n",
    "                          (np.random.random(numSpots)*syntheticObjectExt.shape[2]).astype('int')] = 1\n",
    "    syntheticObjectExt = gaussian_filter(syntheticObjectExt, sigma=(0,sigma,sigma)).astype('float32')\n",
    "    fn = datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S syntheticInput.npy\")\n",
    "    np.save(fn, syntheticObjectExt[0])\n",
    "    \n",
    "plt.imshow(syntheticObjectExt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Model a flow that can be different at different xy locations:\n",
    "    # Note: allowing an x search range is more open-minded,\n",
    "    # but it makes little difference to the outcome, in the case of vertical flow\n",
    "    shifter = flow.PIVShifter(controlPointSpacing, syntheticImageExtendSize, xMotionPermitted=False)\n",
    "    source = 'synthetic'\n",
    "    searchRangeXY = (0,10)\n",
    "elif False:\n",
    "    # Slightly simplified model in which we assume flow will be zero at all boundaries of the image\n",
    "    shifter = flow.PIVZeroEdgeShifter(controlPointSpacing, 0, xMotionPermitted=True)\n",
    "    source = 'piv'\n",
    "    searchRangeXY = (8,8)\n",
    "else:\n",
    "    # Very simple model in which there is a uniform shift across the whole field of view\n",
    "    shifter = flow.UniformSKShifter(0, 0, True)\n",
    "    source = 'synthetic'\n",
    "    searchRangeXY = (0,10)\n",
    "print(\"** We will use a model for the shifts defined by class {0} **\".format(type(shifter).__name__))\n",
    "if source == 'synthetic':\n",
    "    print(\"** The synthetic data will move in a way that is compatible with that model **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source == 'synthetic':\n",
    "    # Generate a synthetic shift in the B image.\n",
    "    # It is the shifter class that provides the motion profile we will use.\n",
    "    # Thus, if we chose a simpler shifter (above), we will use an appropriately simple flow profile\n",
    "    dualObject = np.tile(syntheticObjectExt[:,np.newaxis,:,:], (1,2,1,1)) *1e3#* 1e7\n",
    "    if False:\n",
    "        warnings.warn('Loading previously-saved dualObject')\n",
    "        dualObject = np.load('dualObject5.npy')\n",
    "    \n",
    "    trueShiftDescription = shifter.ExampleShiftDescriptionForObject(dualObject)\n",
    "    dualObject[:,1,:,:] = shifter.ShiftObject(dualObject[:,1,:,:], trueShiftDescription)\n",
    "\n",
    "    # Since I am only using a local minimizer, we need to start with a decent guess as to the flow.\n",
    "    # I think that's ok though: we should have that from a PIV estimate on the with-artefacts AB images\n",
    "    #initialShiftGuess = np.zeros(VelocityShapeForObject(dualObject))\n",
    "    initialShiftGuess = trueShiftDescription + np.random.random(trueShiftDescription.shape) * 4.0\n",
    "else:\n",
    "    assert(source == 'piv')\n",
    "    pivImagePair = tifffile.imread('piv-raw-data/038298.tif')[24:26,:15*20,:15*16].astype('float32')\n",
    "    # Note: frames 57-58 (wrong pair) would be an option to investigate bigger motion (~16px) with imperfect AB matches\n",
    "    #              64-65 (correct pair) are another example of small movement (0-3px)\n",
    "    dualObject = pivImagePair[np.newaxis]\n",
    "    # For now, I just guess an initial shift of zero\n",
    "    trueShiftDescription = np.zeros(VelocityShapeForObject(dualObject)).astype('float32')\n",
    "    initialShiftGuess = trueShiftDescription.copy()\n",
    "    \n",
    "    \n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dualObject[0,0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dualObject[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # If I want to give the algorithm the best possible starting point,\n",
    "    # I can give it the actual true shift values as its starting point\n",
    "    # (but it still may iterate away from that...)\n",
    "    warnings.warn(\"WARNING: starting guess is actually the correct flow description\")\n",
    "    startShiftForOptimizer = trueShiftDescription.copy()\n",
    "else:\n",
    "    startShiftForOptimizer = initialShiftGuess.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeconvRL_PIV_OLD(hMatrix, imageAB, maxIter, Xguess, shifter, shiftDescription):\n",
    "    # I believed this to be the RL algorithm in the way I have written it in the past.\n",
    "    # However, this gives different results to Prevedel's implementation\n",
    "    # (mine seems to converge more slowly).\n",
    "    # TODO: I should look into this and see if I've just made a mistake or if they are actually different.\n",
    "    \n",
    "    # Xguess is our single combined guess of the object\n",
    "    Xguess = Xguess.copy()    # Because we will be updating it, and caller may not always be expecting that\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        relativeBlurDual = imageAB / ForwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        Xguess *= FusedBackwardProjectACC_PIV(hMatrix, relativeBlurDual, shiftDescription)\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "# Some replacement functions to use for testing (effective PSF is a delta function, 1:1 mapping from image to object)\n",
    "def ForwardProjectTrivial(hMatrix, obj, shifter, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = shifter.ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return dualObject[0]\n",
    "\n",
    "def DualBackwardProjectTrivial(hMatrix, dualProjection, shifter, shiftDescription):\n",
    "    dualObject = dualProjection[np.newaxis].copy()\n",
    "    dualObject[:,1,:,:] = shifter.ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    return dualObject\n",
    "\n",
    "def FusedBackwardProjectTrivial(hMatrix, dualProjection, shifter, shiftDescription):\n",
    "    dualObject = DualBackwardProjectTrivial(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def DeconvRLTrivial(hMatrix, imageAB, maxIter, shifter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    return FusedBackwardProjectTrivial(hMatrix, imageAB, shifter, shiftDescription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate flow by using direct shift-matching of the raw input images\n",
    "*Since there is no light field involved at all in this approach, it is of course expected to work very well!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    shiftHistoryRaw = recovery.OptimizeToRecoverFlowField('naive', dualObject[0], None, \\\n",
    "                                        shifter, trueShiftDescription, startShiftForOptimizer, searchRangeXY)\n",
    "\n",
    "# Note: if continuing a previously-interrupted run then we can do this to pick up roughly where we left off.\n",
    "# i.e. provide BestShift() for the two shift-related input parameters, and pass the existing shift history as the final (optional) parameter\n",
    "#    shiftHistoryRaw = recovery.OptimizeToRecoverFlowField('naive', dualObject[0], None, shiftHistoryRaw.BestShift(), shiftHistoryRaw.BestShift(), shiftHistoryRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bestShift = recovery.ReportOnOptimizerConvergence(shiftHistoryRaw, shifter, 'naive', dualObject[0])\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate flow by using direct shift-matching of the light-field-deconvolved images\n",
    "*This is not expected to work particularly well, due to the presence of the artefacts in the recovered A and B images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic light-field-recovered A and B images,\n",
    "# by running the imaging cycle on each of the AB images individually (i.e. introduce artefacts into them)\n",
    "# These recovered volumes represent the inputs for the 'naive' method of recovering the flow profile,\n",
    "# but are not used as inputs for my new algorithm.\n",
    "dualObjectRecovered = dualObject.copy()\n",
    "for n in [0, 1]:\n",
    "    cameraImage = lfdeconv.ForwardProjectACC(pivHMatrix, dualObject[:,n,:,:], logPrint=False)\n",
    "    backProjected = lfdeconv.BackwardProjectACC(pivHMatrix, cameraImage, logPrint=False)\n",
    "    \n",
    "    # With the shifted images, we have problems with true zeroes in regions that have no features remaining.\n",
    "    # To avoid this, I apply a very small nonzero background so that the deconvolution doesn't fail.\n",
    "    backProjected = np.maximum(backProjected, 1e-5*np.max(backProjected))\n",
    "    \n",
    "    dualObjectRecovered[:,n,:,:] = lfdeconv.DeconvRL(pivHMatrix, backProjected, maxIter=8, Xguess=backProjected, logPrint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original object (and true flow)')\n",
    "iwPos = shifter.IWCentresForObject(dualObject)\n",
    "flow.ShowDualObjectAndFlow(dualObject, shifter, trueShiftDescription)\n",
    "print('Recovered from light field images (plane %d) - showing true flow' % zPlaneToModel)\n",
    "flow.ShowDualObjectAndFlow(dualObjectRecovered, shifter, trueShiftDescription)\n",
    "plt.imsave('syntheticInput.tif', dualObject[0,0])\n",
    "plt.imsave('syntheticInputB.tif', dualObject[0,1])\n",
    "\n",
    "plt.imsave('syntheticA.tif', dualObjectRecovered[0,0])\n",
    "plt.imsave('syntheticB.tif', dualObjectRecovered[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    shiftHistoryNaive = recovery.OptimizeToRecoverFlowField('naive', dualObjectRecovered[0], None, \\\n",
    "                                        shifter, trueShiftDescription, startShiftForOptimizer, searchRangeXY, shiftHistoryNaive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    recovery.ReportOnOptimizerConvergence(shiftHistoryNaive, shifter, 'naive', dualObjectRecovered[0])\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate flow by using my new algorithm on the light-field-deconvolved images\n",
    "*Hopefully this should work better!*\n",
    "\n",
    "Note that this cell will take a *very* long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Generate a camera image pair from the object.\n",
    "    if source == 'piv':\n",
    "        # The camera AB images are determined by separate forward projection of the AB spim images in dualObject\n",
    "        imageAB = lfdeconv.ForwardProjectACC(pivHMatrix, dualObject)\n",
    "    else:\n",
    "        # The synthetic B image is determined with the help of the chosen shift transform.\n",
    "        imageAB = lfdeconv_piv.ForwardProjectACC_PIV(pivHMatrix, dualObject[:,0], shifter, trueShiftDescription)\n",
    "\n",
    "    # Run the joint optimizer optimizer to find the shift value for an input frame pair\n",
    "    shiftHistoryJoint = recovery.OptimizeToRecoverFlowField('joint', imageAB, pivHMatrix, \\\n",
    "                                        shifter, trueShiftDescription, startShiftForOptimizer, searchRangeXY, shiftHistoryJoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    recovery.ReportOnOptimizerConvergence(shiftHistoryJoint, shifter, 'joint', imageAB, pivHMatrix)\n",
    "except NameError:\n",
    "    warnings.warn('History probably not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Optional code snippet to save the optimizer histories\n",
    "    np.save('shiftHistoryJoint.npy', shiftHistoryJoint.shiftHistory)\n",
    "    np.save('scoreHistoryJoint.npy', shiftHistoryJoint.scoreHistory)\n",
    "    np.save('dualObjectJoint.npy', dualObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optional code to look at how the scores are evolving during the powell iterations\n",
    "\n",
    "if True:\n",
    "    vals = np.array(shiftHistoryJoint.shiftHistory)\n",
    "    scores = np.array(shiftHistoryJoint.scoreHistory)\n",
    "else:\n",
    "    # Load from files previously saving using:\n",
    "    #   np.save('scoreHistory.npy', np.array(shiftHistoryJoint.scoreHistory))\n",
    "    #   np.save('shiftHistory.npy', np.array(shiftHistoryJoint.shiftHistory))\n",
    "    vals = np.load('/Users/jonny/Desktop/shiftHistory.npy')\n",
    "    scores = np.load('/Users/jonny/Desktop/scoreHistory.npy')\n",
    "iwOfInterest = 5*7+3\n",
    "iwOfInterest = 5*7+6# Looking at border control point for shiftHistoryNaive\n",
    "x = []\n",
    "y = []\n",
    "y2 = []\n",
    "\n",
    "if False:\n",
    "    # Compare the results from different control points\n",
    "    sh = vals[3020].flatten()\n",
    "    sh[iwOfInterest] = 5.011\n",
    "    (_,_,_,_,comp) = recovery.ScoreShiftDetailed(sh, shifter, 'naive', objectToUse, log=False)    \n",
    "    for d in [5.012, 5.0135, 5.0145]:\n",
    "        sh[iwOfInterest] = d\n",
    "        sc = recovery.ScoreShift(sh, shifter, 'naive', objectToUse[0], log=False, comparator=comp)\n",
    "        print('score', sc)\n",
    "\n",
    "if True:\n",
    "    for iw in [iwOfInterest]:\n",
    "#    for iw in range(49):\n",
    "        for n in range(0,vals.shape[0]-1):\n",
    "            if (vals[n,iw,0] != vals[n+1,iw,0]):\n",
    "                x.append(vals[n,iw,0])\n",
    "                y.append(scores[n])\n",
    "            else:\n",
    "                if (len(x) > 0):\n",
    "                    if (len(x) > 2):\n",
    "                        plt.plot(x, y, 'x')\n",
    "                        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "                        plt.show()\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    y2 = []\n",
    "                nStart = n\n",
    "    if (len(x) > 2):\n",
    "        plt.plot(x, y, 'x')\n",
    "        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
