{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status: my new code (which eliminates some of the FFTs) takes 16 seconds instead of 63, on my laptop - for a 2x2 tiled-up input [I did this to give more reproducible timings with a larger work size].\n",
    "\n",
    "Without exploiting symmetries it takes 23 seconds. I had to write C code to speed up the generation of the reflected/transposed FFT matrices - without that it was barely any faster than just computing the rfftn for all aa,bb.\n",
    "\n",
    "Now, 2/3rds of the time is spent in fft2, so that is the bottleneck. If I insist on a square array then I could halve that, but that would be a limitation. I could, I suppose, make it a *recommendation* that allows the code to run faster. I could certainly take advantage of that for my own work.\n",
    "\n",
    "For the original dataset size, on my mac pro, my code takes 6.5s (single-threaded) to back-project plane 4, compared to Matlab's 2.2s (multithreaded). \n",
    "\n",
    "On my mac pro, full backprojection takes 96s single-threaded or 13s parallel(!), of which 1s is on the merging at the end (which I should be able to speed up too). Matlab with multithreading took 28s, so I have achieved a >2x speedup. More would have been nice, but it's still fairly respectable.\n",
    "\n",
    "\n",
    "NOTE: my c code can't cope with an array that has been transposed (Probably because it assumes adjacent strides in x?). I should probably fix that, though I doubt it's a performance issue to just .copy() the transposed array, which is what I do at the moment. I should really be swapping the transpose to be the final operation (in the case of square inputs) anyway. However, it looks as if a decent chunk of the fft time is actually being spent in the other ffts (for the reduced arrays) anyway!\n",
    "\n",
    "### Performance investigation\n",
    "\n",
    "Actual thread execution time seems to grow considerably with the number of threads, i.e. efficiency falls. I am not sure how to try and work out what the cause of that is. I could go back to working on dummy data (no transfers between processes) and see if that makes a difference to *that* in particular. (I think I may have looked only at the dead time overheads - which are also an issue).\n",
    "I looked at user and system cpu time, and with Instruments. Looks like 20% of time is spent in madvise (macbook, 2 threads). I am not sure exactly why or where that is happening. It seems to be related to python memory management in some way. I should check if that grows with number of threads on mac pro, and if it is the same when I use dummy work blocks rather than passing to subprocesses\n",
    "\n",
    "-> revisit this now I am using mmap rather than pickle - hopefully much of this is now fixed.\n",
    "\n",
    "### Performance improvements to make\n",
    "\n",
    "Move transpose to final operation (since it's probably faster than reversing an array - although it may impact subsequent fft performance?), in the case of square arrays\n",
    "\n",
    "fft2 returns a double array (on macbook, at least) for float input. I would much prefer it to return complex64. I could well believe it might be a performance hit to do it this way (larger memory footprint). Can I improve on this? I suppose I could call through to c code that calls fftw, for example\n",
    "\n",
    "Code now supports a third dimension for the camera images (and object z plane), so that we can implement PIV. At the moment it just iterates - performance should be improved by only calculating FT(H) once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import scipy.ndimage, scipy.optimize, scipy.io\n",
    "from scipy.ndimage.filters import convolve\n",
    "from scipy.signal import convolve2d, fftconvolve\n",
    "from scipy.optimize import Bounds\n",
    "import os, sys, time, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tifffile\n",
    "import h5py\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "import cProfile, pstats\n",
    "import glob, csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from numba import jit\n",
    "sys.path.insert(0, 'py_symmetry')\n",
    "import py_symmetry as jps\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# I don't know if these are necessary, but it has been suggested that low-level threading\n",
    "# does not interact well with the joblib Parallel feature.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_DYNAMIC'] = 'FALSE'\n",
    "\n",
    "try:\n",
    "    os.mkdir('perf_diags')\n",
    "except:\n",
    "    pass  # Probably the directory already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPath = 'PSFmatrix/PSFmatrix_M22.2NA0.5MLPitch125fml3125from-110to110zspacing4Nnum19lambda520n1.33.mat'\n",
    "\n",
    "if False:\n",
    "    warnings.warn('WARNING: Switched to faster matrix for testing')\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-26to0zspacing2Nnum15lambda520n1.0.mat'\n",
    "elif True:\n",
    "    warnings.warn('WARNING: Switched to faster and closer-spaced matrix for testing')\n",
    "    matPath = 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmapPath = os.path.splitext(matPath)[0]\n",
    "try:\n",
    "    os.mkdir(mmapPath)\n",
    "except:\n",
    "    pass  # Probably the directory already exists\n",
    "\n",
    "_HPathFormat = mmapPath+'/H{z:02d}.array'\n",
    "_HtPathFormat = mmapPath+'/Ht{z:02d}.array'\n",
    "_HReducedShape = []\n",
    "_HtReducedShape = []\n",
    "if True:\n",
    "    # Load the matrices from the .mat file.\n",
    "    # This is slow since they must be decompressed and are rather large! (9.5GB each, in single-precision FP)\n",
    "    with h5py.File(matPath, 'r') as f:\n",
    "        print('Load CAindex')\n",
    "        sys.stdout.flush()\n",
    "        _CAindex = f['CAindex'].value.astype('int')\n",
    "        \n",
    "        print('Load H')\n",
    "        sys.stdout.flush()\n",
    "        _H = f['H'].value.astype('float32')\n",
    "        Nnum = _H.shape[2]\n",
    "        aabbRange = int((Nnum+1)/2)\n",
    "        for cc in tqdm(range(_H.shape[0]), desc='memmap H'):\n",
    "            HCC =  _H[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            _HReducedShape.append(HCC.shape)\n",
    "            a = np.memmap(_HPathFormat.format(z=cc), dtype='float32', mode='w+', shape=HCC.shape)\n",
    "            a[:,:,:,:] = HCC[:,:,:,:]\n",
    "            del a\n",
    "        #del _H        # H is needed for old code\n",
    "        \n",
    "        print('Load Ht')\n",
    "        sys.stdout.flush()\n",
    "        _Ht = f['Ht'].value.astype('float32')\n",
    "        for cc in tqdm(range(_Ht.shape[0]), desc='memmap Ht'):\n",
    "            HtCC =  _Ht[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            _HtReducedShape.append(HtCC.shape)\n",
    "            a = np.memmap(_HtPathFormat.format(z=cc), dtype='float32', mode='w+', shape=HtCC.shape)\n",
    "            a[:,:,:,:] = HtCC[:,:,:,:]\n",
    "            del a\n",
    "        #del _Ht        # Ht is needed for old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMatrix:\n",
    "    def __init__(self, HPathFormat, HtPathFormat, HReducedShape, numZ=None, zStart=0):\n",
    "        self.HPathFormat = HPathFormat\n",
    "        self.HtPathFormat = HtPathFormat\n",
    "        self.HReducedShape = HReducedShape   # Same for Ht\n",
    "        if numZ is not None:\n",
    "            self.numZ = numZ\n",
    "        else:\n",
    "            self.numZ = len(HReducedShape)\n",
    "        self.zStart = zStart\n",
    "        \n",
    "    def Hcc(self, cc, transpose):\n",
    "        if transpose:\n",
    "            pathFormat = self.HtPathFormat\n",
    "        else:\n",
    "            pathFormat = self.HPathFormat\n",
    "        result = np.memmap(pathFormat.format(z=cc+self.zStart), dtype='float32', mode='r', shape=self.HReducedShape[cc+self.zStart])\n",
    "        return result\n",
    "    \n",
    "    def IterableBRange(self, cc):\n",
    "        return range(self.HReducedShape[cc+self.zStart][0])\n",
    "    \n",
    "    def PSFShape(self, cc):\n",
    "        return (self.HReducedShape[cc+self.zStart][2], self.HReducedShape[cc+self.zStart][3])\n",
    "        \n",
    "    def Nnum(self, cc):\n",
    "        return self.HReducedShape[cc+self.zStart][0]*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "LFmovie = tifffile.imread('Data/02_Rectified/exampleData/20131219WORM2_small_full_neg_X1_N15_cropped_uncompressed.tif')\n",
    "LFmovie = LFmovie.transpose()[np.newaxis,:,:]\n",
    "\n",
    "LFIMG = LFmovie[0].astype('float32')\n",
    "if True:\n",
    "    # Actual (cropped) image loaded from disk\n",
    "    inputImage = LFIMG\n",
    "else:\n",
    "    inputImage = np.tile(LFIMG,(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects stored in the .mat file\n",
    "\n",
    "### Optical parameters from GUI: [? means I am not sure if or where it is stored]\n",
    "\n",
    "M<br>\n",
    "NA<br>\n",
    "d    \"fml\" in GUI (stored here in units of m)<br>\n",
    "pixelPitch is \"ML pitch\" / \"Nnum\" (stored here in units of m)<br>\n",
    "? n<br>\n",
    "? wavelength<br>\n",
    "\n",
    "### User parameters from GUI:\n",
    "\n",
    "OSR<br>\n",
    "zspacing<br>\n",
    "? z-min<br>\n",
    "? z-max<br>\n",
    "Nnum<br>\n",
    "\n",
    "\n",
    "### Misc parameter:\n",
    "\n",
    "fobj (can presumably be deduced from mag, NA etc?)<br>\n",
    "\n",
    "### The actual arrays:\n",
    "\n",
    "H:             shape (56, 19, 19, 343, 343), type \"f4\"<br>\n",
    "Ht:            shape (56, 19, 19, 343, 343), type \"f4\"<br>\n",
    "\n",
    "### Information about object space:\n",
    "\n",
    "x1objspace:    x pixel positions in object space (19 elements across one lenslet)<br>\n",
    "x2objspace:    y pixel positions in object space (19 elements across one lenslet)<br>\n",
    "x3objspace:    z pixel positions in object space (56 z planes)<br>\n",
    "x1space:       x pixel positions in lenslet space (19 elements across one lenslet)<br>\n",
    "x2space:       y pixel positions in lenslet space (19 elements across one lenslet)<br>\n",
    "\n",
    "### Not sure what these are exactly:\n",
    "\n",
    "CAindex:       shape (2, 56) - something about the start and end index of the PSF array, for each z plane.<br>\n",
    "CP:            shape (343, 1)<br>\n",
    "MLARRAY:       shape (1141, 1141), type \"|V16\"<br>\n",
    "objspace:      shape (56, 1, 1)<br>\n",
    "settingPSF:    You would think this contains the GUI parameters, but e.g. print(f['settingPSF']['M'].value) gives a strange 3x1 array [50, 50, 46, 50] etc...?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I am a little unsure how to interpret the arrays I have loaded from the .mat.\n",
    "# From looking at how H and CAindex are accessed, it looks as if the shapes I have loaded\n",
    "# are the reversal of the shape ordering as expected in Matlab.\n",
    "# I suppose that makes sense given that matlab is column-major in its array accesses.\n",
    "# The data has been loaded from disk in the order it is *stored*,\n",
    "# and I therefore need to flip around all the matlab array index ordering \n",
    "# (e.g. matlabArray(1,2,3) becomes pythonArray[3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "def noProgressBar(work, **kwargs):\n",
    "    # Dummy function to be used in place of tqdm when we don't want to show a progress bar\n",
    "    return work    \n",
    "\n",
    "def cpuTime(kind):\n",
    "    rus = resource.getrusage(resource.RUSAGE_SELF)    \n",
    "    ruc = resource.getrusage(resource.RUSAGE_CHILDREN)\n",
    "    if (kind == 'self'):\n",
    "        return np.array([rus.ru_utime, rus.ru_stime])\n",
    "    elif (kind == 'children'):\n",
    "        return np.array([ruc.ru_utime, ruc.ru_stime])\n",
    "    else:\n",
    "        return np.array([rus.ru_utime+ruc.ru_utime, rus.ru_stime+ruc.ru_stime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy._lib._version import NumpyVersion\n",
    "from numpy.fft import fft, fftn, rfft, rfftn, irfftn\n",
    "_rfft_mt_safe = (NumpyVersion(np.__version__) >= '1.9.0.dev-e24486e')\n",
    "\n",
    "def _next_regular(target):\n",
    "    \"\"\"\n",
    "    Find the next regular number greater than or equal to target.\n",
    "    Regular numbers are composites of the prime factors 2, 3, and 5.\n",
    "    Also known as 5-smooth numbers or Hamming numbers, these are the optimal\n",
    "    size for inputs to FFTPACK.\n",
    "\n",
    "    Target must be a positive integer.\n",
    "    \"\"\"\n",
    "    if target <= 6:\n",
    "        return target\n",
    "\n",
    "    # Quickly check if it's already a power of 2\n",
    "    if not (target & (target-1)):\n",
    "        return target\n",
    "\n",
    "    match = float('inf')  # Anything found will be smaller\n",
    "    p5 = 1\n",
    "    while p5 < target:\n",
    "        p35 = p5\n",
    "        while p35 < target:\n",
    "            # Ceiling integer division, avoiding conversion to float\n",
    "            # (quotient = ceil(target / p35))\n",
    "            quotient = -(-target // p35)\n",
    "\n",
    "            # Quickly find next power of 2 >= quotient\n",
    "            try:\n",
    "                p2 = 2**((quotient - 1).bit_length())\n",
    "            except AttributeError:\n",
    "                # Fallback for Python <2.7\n",
    "                p2 = 2**(len(bin(quotient - 1)) - 2)\n",
    "\n",
    "            N = p2 * p35\n",
    "            if N == target:\n",
    "                return N\n",
    "            elif N < match:\n",
    "                match = N\n",
    "            p35 *= 3\n",
    "            if p35 == target:\n",
    "                return p35\n",
    "        if p35 < match:\n",
    "            match = p35\n",
    "        p5 *= 5\n",
    "        if p5 == target:\n",
    "            return p5\n",
    "    if p5 < match:\n",
    "        match = p5\n",
    "    return match\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    currsize = np.array(arr.shape)\n",
    "    newsize = np.asarray(newsize)\n",
    "    if (len(currsize) > len(newsize)):\n",
    "        newsize = np.append([currsize[0]], newsize)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "def tempMul(bb,fshape,result):\n",
    "    result *= np.exp(-1j * bb * 2*np.pi / fshape[0] * np.arange(result.shape[0],dtype='complex64'))[:,np.newaxis]\n",
    "    return result\n",
    "\n",
    "def expand2(result, bb, aa, Nnum, fshape):\n",
    "    return np.tile(result, (Nnum,1))\n",
    "\n",
    "def expand(reducedF, bb, aa, Nnum, fshape):\n",
    "    result = np.tile(reducedF, (1,int(Nnum/2+1)))\n",
    "    result = result[:,:int(fshape[1]/2+1)]\n",
    "    result *= np.exp(-1j * aa * 2*np.pi / fshape[1] * np.arange(result.shape[1],dtype='complex64'))\n",
    "    result = expand2(result, bb, aa, Nnum, fshape)\n",
    "    return tempMul(bb,fshape,result)\n",
    "\n",
    "\n",
    "def special_rfftn(in1, bb, aa, Nnum, fshape):\n",
    "    # Compute the fft of elements in1[bb::Nnum,aa::Nnum], after in1 has been zero-padded out to fshape\n",
    "    # We exploit the fact that fft(masked-in1) is fft(arr[::Nnum,::Nnum]) replicated Nnum times.\n",
    "    reducedShape = ()\n",
    "    for d in fshape:\n",
    "        assert((d % Nnum) == 0)\n",
    "        reducedShape = reducedShape + (int(d/Nnum),)\n",
    "        \n",
    "    assert(in1.ndim == 2)\n",
    "    reduced = in1[bb::Nnum,aa::Nnum]\n",
    "\n",
    "    # Compute an array giving rfft(mask(in1))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        reducedF = scipy.fftpack.fft2(reduced, reducedShape).astype('complex64')\n",
    "    return expand(reducedF, bb, aa, Nnum, fshape)\n",
    "\n",
    "def convolutionShape(in1, in2, Nnum):\n",
    "    # Logic copied from fftconvolve source code\n",
    "    s1 = np.array(in1.shape)\n",
    "    s2 = np.array(in2.shape)\n",
    "    if (len(s1) == 3):   # Cope with case where we are processing multiple reconstructions in parallel\n",
    "        s1 = s1[1:]\n",
    "    shape = s1 + s2 - 1\n",
    "    if False:\n",
    "        # TODO: I haven't worked out if/how I can do this yet.\n",
    "        # This is the original code in fftconvolve, which says:\n",
    "        # Speed up FFT by padding to optimal size for FFTPACK\n",
    "        fshape = [_next_regular(int(d)) for d in shape]\n",
    "    else:\n",
    "        fshape = [int(np.ceil(d/float(Nnum)))*Nnum for d in shape]\n",
    "    fslice = tuple([slice(0, int(sz)) for sz in shape])\n",
    "    return (fshape, fslice, s1)\n",
    "    \n",
    "def special_fftconvolve_part1(in1, bb, aa, Nnum, in2):\n",
    "    assert(len(in1.shape) == 2)\n",
    "    assert(len(in2.shape) == 2)\n",
    "    (fshape, fslice, s1) = convolutionShape(in1, in2, Nnum)\n",
    "    # Pre-1.9 NumPy FFT routines are not threadsafe - this code requires numpy 1.9 or greater\n",
    "    assert(_rfft_mt_safe)\n",
    "    fa = special_rfftn(in1, bb, aa, Nnum, fshape)\n",
    "    return (fa, fshape, fslice, s1)\n",
    "\n",
    "def special_fftconvolve_part3b(fab, fshape, fslice, s1):\n",
    "    assert(len(fab.shape) == 2)\n",
    "    ret = irfftn(fab, fshape)[fslice].copy()\n",
    "    return _centered(ret, s1)\n",
    "\n",
    "def special_fftconvolve_part3(fab, fshape, fslice, s1):\n",
    "    if (len(fab.shape) == 2):\n",
    "        return special_fftconvolve_part3b(fab, fshape, fslice, s1)\n",
    "    else:\n",
    "        results = []\n",
    "        for n in range(fab.shape[0]):\n",
    "            results.append(special_fftconvolve_part3(fab[n], fshape, fslice, s1))\n",
    "        return np.array(results)\n",
    "\n",
    "def special_fftconvolve(in1, bb, aa, Nnum, in2, accum, fb=None):\n",
    "    '''\n",
    "    in1 consists of subapertures of size Nnum x Nnum pixels.\n",
    "    We are being asked to convolve only pixel (bb,aa) within each subaperture, i.e.\n",
    "        tempSlice = np.zeros(in1.shape, dtype=in1.dtype)\n",
    "        tempSlice[bb::Nnum, aa::Nnum] = in1[bb::Nnum, aa::Nnum]\n",
    "    This allows us to take a significant shortcut in computing the FFT for in1.\n",
    "    '''\n",
    "    (fa, fshape, fslice, s1) = special_fftconvolve_part1(in1, bb, aa, Nnum, in2)\n",
    "    if fb is None:\n",
    "        fb = rfftn(in2, fshape)\n",
    "    if accum is None:\n",
    "        accum = fa*fb\n",
    "    else:\n",
    "        accum += fa*fb\n",
    "    return (accum, fshape, fslice, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProjectForZ_old(HCC, realspaceCC):\n",
    "    singleJob = (len(realspaceCC.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        realspaceCC = realspaceCC[np.newaxis,:,:]\n",
    "    # Iterate over each lenslet pixel\n",
    "    Nnum = HCC.shape[1]\n",
    "    TOTALprojection = np.zeros(realspaceCC.shape, dtype='float32')\n",
    "    for bb in tqdm(range(Nnum), leave=False, desc='Forward-project - y'):\n",
    "        for aa in tqdm(range(Nnum), leave=False, desc='Forward-project - x'):\n",
    "            # Extract the part of H that represents this lenslet pixel\n",
    "            Hs = HCC[bb, aa]\n",
    "            for n in range(realspaceCC.shape[0]):\n",
    "                # Create a workspace representing just the voxels cc,bb,aa behind each lenslet (the rest is 0)\n",
    "                tempspace = np.zeros((realspaceCC[n].shape[0], realspaceCC[n].shape[1]), dtype='float32');\n",
    "                tempspace[bb::Nnum, aa::Nnum] = realspaceCC[n, bb::Nnum, aa::Nnum]  # ???? what to do about index ordering?\n",
    "                # Compute how those voxels project onto the sensor, and accumulate\n",
    "                TOTALprojection[n] += fftconvolve(tempspace, Hs, 'same')\n",
    "    if singleJob:\n",
    "        return TOTALprojection[0]\n",
    "    else:\n",
    "        return TOTALprojection\n",
    "    \n",
    "def backwardProjectForZ_old(HtCC, projection):\n",
    "    singleJob = (len(projection.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        projection = projection[np.newaxis,:,:]\n",
    "    # Iterate over each lenslet pixel\n",
    "    Nnum = HtCC.shape[1]\n",
    "    tempSliceBack = np.zeros(projection.shape, dtype='float32')        \n",
    "    for aa in tqdm(range(Nnum), leave=False, desc='y'):\n",
    "        for bb in range(Nnum):\n",
    "            # Extract the part of Ht that represents this lenslet pixel\n",
    "            Hts = HtCC[bb, aa]\n",
    "            for n in range(projection.shape[0]):\n",
    "                # Create a workspace representing just the voxels cc,bb,aa behind each lenslet (the rest is 0)\n",
    "                tempSlice = np.zeros(projection[n].shape, dtype='float32')\n",
    "                tempSlice[bb::Nnum, aa::Nnum] = projection[n, bb::Nnum, aa::Nnum]\n",
    "                # Compute how those voxels back-project from the sensor\n",
    "                tempSliceBack[n] += fftconvolve(tempSlice, Hts, 'same')\n",
    "    if singleJob:\n",
    "        return tempSliceBack[0]\n",
    "    else:\n",
    "        return tempSliceBack\n",
    "\n",
    "def backwardProjectACC_original(Ht, projection, CAindex, planes=None):\n",
    "    Backprojection = np.zeros((Ht.shape[0], projection.shape[0], projection.shape[1]), dtype='float32')\n",
    "    # Iterate over each z plane\n",
    "    if planes is None:\n",
    "        planes = range(Ht.shape[0])\n",
    "    for cc in tqdm(planes, desc='Back-project - z'):\n",
    "        HtCC =  Ht[cc, :, :, CAindex[0,cc]-1:CAindex[1,cc], CAindex[0,cc]-1:CAindex[1,cc]]\n",
    "        Backprojection[cc] = backwardProjectForZ_old(HtCC, projection)\n",
    "    return Backprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvRL(hMatrix, Htf, maxIter, Xguess, logPrint=True):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC(hMatrix, Xguess, logPrint=logPrint)\n",
    "        HXguessBack = backwardProjectACC(hMatrix, HXguess, logPrint=logPrint)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        ttime = time.time() - t0\n",
    "        print('iter %d | %d, took %.1f secs. Max val %f' % (i+1, maxIter, ttime, np.max(Xguess)))\n",
    "    return Xguess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: H.shape in python is (<num z planes>, Nnum, Nnum, <psf size>, <psf size>),\n",
    "#                       e.g. (56, 19, 19, 343, 343)\n",
    "\n",
    "class Projector(object):\n",
    "    # Note: the variable names in this class mostly imply we are doing the back-projection\n",
    "    # (e.g. Ht, 'projection', etc. However, the same code also does forward-projection!)\n",
    "    def __init__(self, projection, HtCCBB, Nnum):\n",
    "        # Note: H and Hts are not stored as class variables.\n",
    "        # I had a lot of trouble with them and multithreading,\n",
    "        # and eventually settled on having them in shared memory.\n",
    "        # As I encapsulate more stuff in this class, I could bring them back as class variables...\n",
    "\n",
    "        self.cpuTime = np.zeros(2)\n",
    "        \n",
    "        # Nnum: number of pixels across a lenslet array (after rectification)\n",
    "        self.Nnum = Nnum\n",
    "        \n",
    "        # This next chunk of logic copied from fftconvolve source code.\n",
    "        # s1, s2: shapes of the input arrays\n",
    "        # fshape: shape of the (full, possibly padded) result array in Fourier space\n",
    "        # fslice: slicing tuple specifying the actual result size that should be returned\n",
    "        self.s1 = np.array(projection.shape)\n",
    "        self.s2 = np.array(HtCCBB[0].shape)\n",
    "        shape = self.s1 + self.s2 - 1\n",
    "        if False:\n",
    "            # TODO: I haven't worked out if/how I can do this yet.\n",
    "            # This is the original code in fftconvolve, which says:\n",
    "            # Speed up FFT by padding to optimal size for FFTPACK\n",
    "            self.fshape = [_next_regular(int(d)) for d in shape]\n",
    "        else:\n",
    "            self.fshape = [int(np.ceil(d/float(Nnum)))*Nnum for d in shape]\n",
    "        self.fslice = tuple([slice(0, int(sz)) for sz in shape])\n",
    "        \n",
    "        # rfslice: slicing tuple to crop down full fft array to the shape that would be output from rfftn\n",
    "        self.rfslice = (slice(0,self.fshape[0]), slice(0,int(self.fshape[1]/2)+1))\n",
    "        return\n",
    "    \n",
    "    def MirrorXArray(self, Hts, fHtsFull):\n",
    "        padLength = self.fshape[0] - Hts.shape[0]\n",
    "        if False:\n",
    "            fHtsFull = fHtsFull.conj() * np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[0]) * np.arange(self.fshape[0],dtype='complex64')[:,np.newaxis])\n",
    "            fHtsFull[:,1::] = fHtsFull[:,1::][:,::-1]\n",
    "            return fHtsFull\n",
    "        else:\n",
    "            temp = np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[0]) * np.arange(self.fshape[0])).astype('complex64')\n",
    "            if True:\n",
    "                result = jps.mirrorX(fHtsFull, temp)\n",
    "            else:\n",
    "                result = np.empty(fHtsFull.shape, dtype=fHtsFull.dtype)\n",
    "                result[:,0] = fHtsFull[:,0].conj()*temp\n",
    "                for i in range(1,fHtsFull.shape[1]):\n",
    "                    result[:,i] = (fHtsFull[:,fHtsFull.shape[1]-i].conj()*temp)\n",
    "            return result\n",
    "\n",
    "    def MirrorYArray(self, Hts, fHtsFull):\n",
    "        padLength = self.fshape[1] - Hts.shape[1]\n",
    "        if False:\n",
    "            fHtsFull = fHtsFull.conj() * np.exp(1j * (1+padLength) * 2*np.pi / self.fshape[1] * np.arange(self.fshape[1],dtype='complex64'))\n",
    "            fHtsFull[1::] = fHtsFull[1::][::-1]\n",
    "            return fHtsFull\n",
    "        else:\n",
    "            temp = np.exp((1j * (1+padLength) * 2*np.pi / self.fshape[1]) * np.arange(self.fshape[1])).astype('complex64')\n",
    "            if True:\n",
    "                result = jps.mirrorY(fHtsFull, temp)\n",
    "            else:\n",
    "                result = np.empty(fHtsFull.shape, dtype=fHtsFull.dtype)\n",
    "                result[0] = fHtsFull[0].conj()*temp\n",
    "                for i in range(1,fHtsFull.shape[0]):\n",
    "                    result[i] = (fHtsFull[fHtsFull.shape[0]-i].conj()*temp)\n",
    "            return result\n",
    "        \n",
    "    def convolvePart3(self, projection, bb, aa, Hts, fHtsFull, mirrorX, accum):\n",
    "        # TODO: to make this work, I need the full matrix for fHts and then I need to slice it \n",
    "        # to the correct shape when I call through to special_fftconvolve here. Is fshape what I need?\n",
    "        cpu0 = cpuTime('both')\n",
    "        (accum,_,_,_) = special_fftconvolve(projection,bb,aa,self.Nnum,Hts,accum,fb=fHtsFull[self.rfslice])\n",
    "        self.cpuTime += cpuTime('both')-cpu0\n",
    "        if mirrorX:\n",
    "            fHtsFull = self.MirrorXArray(Hts, fHtsFull)\n",
    "            cpu0 = cpuTime('both')\n",
    "            (accum,_,_,_) = special_fftconvolve(projection,self.Nnum-bb-1,aa,self.Nnum,Hts[::-1,:],accum,fb=fHtsFull[self.rfslice]) \n",
    "            self.cpuTime += cpuTime('both')-cpu0\n",
    "        return accum\n",
    "\n",
    "    def convolvePart2(self, projection, bb, aa, Hts, fHtsFull, mirrorY, mirrorX, accum):\n",
    "        accum = self.convolvePart3(projection,bb,aa,Hts,fHtsFull,mirrorX,accum)\n",
    "        if mirrorY:\n",
    "            fHtsFull = self.MirrorYArray(Hts, fHtsFull)\n",
    "            accum = self.convolvePart3(projection,bb,self.Nnum-aa-1,Hts[:,::-1],fHtsFull,mirrorX,accum)\n",
    "        return accum\n",
    "\n",
    "    def fft2(self, mat, shape):\n",
    "        # Perform a 'float' FFT on the matrix we are passed.\n",
    "        # It would probably be faster if there was a way to perform the FFT natively on the 'float' type,\n",
    "        # but scipy does not seem to support that option\n",
    "        #\n",
    "        # With my Mac Pro install, we hit a FutureWarning within scipy.\n",
    "        # This wrapper just suppresses that warning.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return scipy.fftpack.fft2(mat, shape).astype('complex64')       \n",
    "        \n",
    "    def convolve(self, projection, bb, aa, Hts, accum):\n",
    "        cent = int(self.Nnum/2)\n",
    "\n",
    "        mirrorX = (bb != cent)\n",
    "        mirrorY = (aa != cent)\n",
    "        transpose = ((aa != bb) and (aa != (self.Nnum-bb-1)))\n",
    "            \n",
    "        # TODO: it would speed things up if I could avoid computing the full fft for Hts.\n",
    "        # However, it's not immediately clear to me how to fill out the full fftn array from rfftn\n",
    "        # in the case of a 2D transform.\n",
    "        # For 1D it's the reversed conjugate, but for 2D it's more complicated than that.\n",
    "        # It's possible that it's actually nontrivial, in spite of the fact that\n",
    "        # you can get away without it when only computing fft/ifft for real arrays)\n",
    "        fHtsFull = self.fft2(Hts, self.fshape)\n",
    "        accum = self.convolvePart2(projection,bb,aa,Hts,fHtsFull,mirrorY,mirrorX, accum)\n",
    "        if transpose:\n",
    "            if (self.fshape[0] == self.fshape[1]):\n",
    "                # For a square array, the FFT of the transpose is just the transpose of the FFT.\n",
    "                # The copy() is because my C code currently can't cope with\n",
    "                # a transposed array (non-contiguous strides in x)\n",
    "                fHtsFull = fHtsFull.transpose().copy()    \n",
    "            else:\n",
    "                # For a non-square array, we have to compute the FFT for the transpose.\n",
    "                fHtsFull = self.fft2(Hts.transpose(), self.fshape)\n",
    "\n",
    "            # Note that mx,my need to be swapped following the transpose\n",
    "            accum = self.convolvePart2(projection,aa,bb,Hts.transpose(),fHtsFull,mirrorX,mirrorY, accum) \n",
    "        return accum\n",
    "    \n",
    "def _projectForZY(cc, bb, source, hMatrix, backwards, Hccbb=None):\n",
    "    f = open('perf_diags/%d_%d.txt'%(cc,bb), \"w\")\n",
    "    t1 = time.time()\n",
    "    singleJob = (len(source.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        source = source[np.newaxis,:,:]\n",
    "    result = [None] * source.shape[0]\n",
    "    if Hccbb is None:\n",
    "        Hccbb = hMatrix.Hcc(cc, transpose=backwards)[bb]\n",
    "        Nnum = hMatrix.Nnum(cc)\n",
    "    else:\n",
    "        Nnum = Hccbb.shape[0]\n",
    "    projector = Projector(source[0], Hccbb, Nnum)\n",
    "    projector.cpuTime = np.zeros(2)\n",
    "    for aa in range(bb,int((Nnum+1)/2)):\n",
    "        for n in range(source.shape[0]):\n",
    "            result[n] = projector.convolve(source[n], bb, aa, Hccbb[aa], result[n])\n",
    "    t2 = time.time()\n",
    "    f.write('%d\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (os.getpid(), t1, t2, t2-t1, projector.cpuTime[0], projector.cpuTime[1]))\n",
    "    f.close()\n",
    "    if singleJob:\n",
    "        return (result[0], cc, bb, t2-t1)\n",
    "    else:\n",
    "        return (np.array(result), cc, bb, t2-t1)\n",
    "    \n",
    "def projectForZ(Hcc, cc, source):\n",
    "    result = None\n",
    "    Nnum = Hcc.shape[1]\n",
    "    r = range(int((Nnum+1)/2))\n",
    "    for bb in tqdm(r, leave=False, desc='Project - y'):\n",
    "        (thisResult, _, _, _) = _projectForZY(cc, bb, source, None, False, Hcc[bb])\n",
    "        if (result is None):\n",
    "            result = thisResult\n",
    "        else:\n",
    "            result += thisResult\n",
    "    # Actually, for forward projection we don't need to do this separately for every z,\n",
    "    # but it's easier to do it for symmetry (and this function is not used in performance-critical code anyway)\n",
    "    (fshape, fslice, s1) = convolutionShape(source, Hcc[0,0], Nnum)\n",
    "    return special_fftconvolve_part3(result, fshape, fslice, s1)\n",
    "\n",
    "def projectForZ2(hMatrix, backwards, cc, source):\n",
    "    result = None\n",
    "    for bb in tqdm(hMatrix.IterableBRange(cc), leave=False, desc='Project - y'):\n",
    "        (thisResult, _, _, _) = _projectForZY(cc, bb, source, hMatrix, backwards)\n",
    "        if (result is None):\n",
    "            result = thisResult\n",
    "        else:\n",
    "            result += thisResult\n",
    "    # Actually, for forward projection we don't need to do this separately for every z,\n",
    "    # but it's easier to do it for symmetry (and this function is not used in performance-critical code anyway)\n",
    "    (fshape, fslice, s1) = convolutionShape(source, np.empty(hMatrix.PSFShape(cc)), hMatrix.Nnum(cc))\n",
    "    return special_fftconvolve_part3(result, fshape, fslice, s1)\n",
    "    \n",
    "# Test the backprojection code against a slower definitive version\n",
    "# (this code is here for now because this is where I have been working on stuff, but it could move)\n",
    "# TODO: would be a better test if I use the hMatrix form of projectForZ\n",
    "testHtCC = np.random.random((5,5,30,30)).astype(np.float32)\n",
    "testHtCC = _Ht[13,int(_Ht.shape[1]/2)-2:int(_Ht.shape[1]/2)+3,int(_Ht.shape[2]/2)-2:int(_Ht.shape[2]/2)+3,_CAindex[0,13]-1:_CAindex[1,13], _CAindex[0,13]-1:_CAindex[1,13]]\n",
    "for fd in [False, True]:\n",
    "    for shape in [(200,200), (200,300), (300,200)]:\n",
    "        # Test both square and non-square, since they use different code\n",
    "        testProjection = np.random.random(shape).astype(np.float32)\n",
    "        if fd:\n",
    "            testResultOld = forwardProjectForZ_old(testHtCC, testProjection)\n",
    "            testResultNew = projectForZ(testHtCC, 0, testProjection)\n",
    "        else:\n",
    "            testResultOld = backwardProjectForZ_old(testHtCC, testProjection)\n",
    "            testResultNew = projectForZ(testHtCC, 0, testProjection)\n",
    "        comparison = np.max(np.abs(testResultOld - testResultNew))\n",
    "        print('test result (should be <<1): %e' % comparison)\n",
    "        if (comparison > 1e-4):\n",
    "            print(\" -> WARNING: disagreement detected\")\n",
    "        else:\n",
    "            print(\" -> OK\")\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slower test that exercises the projection code with the new HMatrix object\n",
    "if False:\n",
    "    testHCC = _H[13]\n",
    "    testHtCC = _Ht[13]\n",
    "    testHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=13)\n",
    "    for fd in [False, True]:\n",
    "        for shape in [(200,200), (200,300), (300,200)]:\n",
    "            # Test both square and non-square, since they use different code\n",
    "            testProjection = np.random.random(shape).astype(np.float32)\n",
    "            if fd:\n",
    "                testResultOld = forwardProjectForZ_old(testHCC, testProjection)\n",
    "                testResultNew = projectForZ2(testHMatrix, False, 0, testProjection)\n",
    "            else:\n",
    "                testResultOld = backwardProjectForZ_old(testHtCC, testProjection)\n",
    "                testResultNew = projectForZ2(testHMatrix, True, 0, testProjection)\n",
    "            comparison = np.max(np.abs(testResultOld - testResultNew))\n",
    "            print('test result (fd=%d) (should be <<1): %e' % (fd, comparison))\n",
    "            if (comparison > 1e-4):\n",
    "                print(\" -> WARNING: disagreement detected\")\n",
    "            else:\n",
    "                print(\" -> OK\")\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def backwardProjectACC(hMatrix, projection, planes=None, numjobs=multiprocessing.cpu_count(), progress=tqdm, logPrint=True):\n",
    "    singleJob = (len(projection.shape) == 2)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        projection = projection[np.newaxis,:,:]\n",
    "    if planes is None:\n",
    "        planes = range(hMatrix.numZ)\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "\n",
    "    ru1 = cpuTime('both')\n",
    "\n",
    "    Backprojection = np.zeros((hMatrix.numZ, projection.shape[0], projection.shape[1], projection.shape[2]), dtype='float32')\n",
    "        \n",
    "    # Set up the work to iterate over each z plane\n",
    "    work = []\n",
    "    for cc in planes:\n",
    "        for bb in hMatrix.IterableBRange(cc):\n",
    "            work.append((cc, bb, projection, hMatrix, True))\n",
    "\n",
    "    # Run the multithreaded work\n",
    "    t0 = time.time()\n",
    "    results = Parallel(n_jobs=numjobs)\\\n",
    "            (delayed(_projectForZY)(*args) for args in progress(work, desc='Back-project - z', leave=False))\n",
    "    ru2 = cpuTime('both')\n",
    "\n",
    "    # Gather together and sum the results for each z plane\n",
    "    t1 = time.time()\n",
    "    fourierZPlanes = [None]*hMatrix.numZ\n",
    "    elapsedTime = 0\n",
    "    for (result, cc, bb, t) in results:\n",
    "        elapsedTime += t\n",
    "        if fourierZPlanes[cc] is None:\n",
    "            fourierZPlanes[cc] = result\n",
    "        else:\n",
    "            fourierZPlanes[cc] += result\n",
    "    \n",
    "    # Compute the FFT for each z plane\n",
    "    for cc in planes:\n",
    "        # A bit complicated here to set up the correct inputs for convolutionShape...\n",
    "        (fshape, fslice, s1) = convolutionShape(projection, np.empty(hMatrix.PSFShape(cc)), hMatrix.Nnum(cc))\n",
    "        Backprojection[cc] = special_fftconvolve_part3(fourierZPlanes[cc], fshape, fslice, s1)        \n",
    "    t2 = time.time()\n",
    "\n",
    "    # Save some diagnostics\n",
    "    if logPrint:\n",
    "        print('work elapsed wallclock time %f'%(t1-t0))\n",
    "        print('work elapsed thread time %f'%elapsedTime)\n",
    "        print('work delta rusage:', ru2-ru1)\n",
    "        print('FFTs took %f'%(t2-t1))\n",
    "    \n",
    "    f = open('overall.txt', 'w')\n",
    "    f.write('%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (t0, t1, t1-t0, t2-t1, (ru2-ru1)[0], (ru2-ru1)[1]))\n",
    "    f.close()\n",
    "\n",
    "    if singleJob:\n",
    "        return Backprojection[:,0]\n",
    "    else:\n",
    "        return Backprojection\n",
    "\n",
    "def forwardProjectACC(hMatrix, realspace, planes=None, numjobs=multiprocessing.cpu_count(), progress=tqdm, logPrint=True):\n",
    "    singleJob = (len(realspace.shape) == 3)\n",
    "    if singleJob:   # Cope with both a single 2D plane and an array of multiple 2D planes to process independently\n",
    "        realspace = realspace[:,np.newaxis,:,:]\n",
    "    if planes is None:\n",
    "        planes = range(hMatrix.numZ)\n",
    "    if progress is None:\n",
    "        progress = noProgressBar        \n",
    "\n",
    "    # Set up the work to iterate over each z plane\n",
    "    work = []\n",
    "    for cc in planes:\n",
    "        for bb in hMatrix.IterableBRange(cc):\n",
    "            work.append((cc, bb, realspace[cc], hMatrix, False))\n",
    "\n",
    "    # Run the multithreaded work\n",
    "    t0 = time.time()\n",
    "    results = Parallel(n_jobs=numjobs)\\\n",
    "                (delayed(_projectForZY)(*args) for args in progress(work, desc='Forward-project - z', leave=False))\n",
    "\n",
    "    # Gather together and sum all the results\n",
    "    t1 = time.time()\n",
    "    fourierProjection = [None]*hMatrix.numZ\n",
    "    elapsedTime = 0\n",
    "    for (result, cc, bb, t) in results:\n",
    "        elapsedTime += t\n",
    "        if fourierProjection[cc] is None:\n",
    "            fourierProjection[cc] = result\n",
    "        else:\n",
    "            fourierProjection[cc] += result\n",
    "\n",
    "    # Compute and accumulate the FFT for each z plane\n",
    "    TOTALprojection = None\n",
    "    for cc in planes:\n",
    "        # A bit complicated here to set up the correct inputs for convolutionShape...\n",
    "        (fshape, fslice, s1) = convolutionShape(realspace[cc], np.empty(hMatrix.PSFShape(cc)), hMatrix.Nnum(cc))\n",
    "        thisProjection = special_fftconvolve_part3(fourierProjection[cc], fshape, fslice, s1)        \n",
    "        if TOTALprojection is None:\n",
    "            TOTALprojection = thisProjection\n",
    "        else:\n",
    "            TOTALprojection += thisProjection\n",
    "    t2 = time.time()\n",
    "            \n",
    "    # Print out some diagnostics\n",
    "    if (logPrint):\n",
    "        print('work elapsed wallclock time %f'%(t1-t0))\n",
    "        print('work elapsed thread time %f'%elapsedTime)\n",
    "        print('FFTs took %f'%(t2-t1))\n",
    "        \n",
    "    if singleJob:\n",
    "        return TOTALprojection[0]\n",
    "    else:\n",
    "        return TOTALprojection\n",
    "\n",
    "if False:\n",
    "    # Temporary call to test parallelization\n",
    "    temp = backwardProjectACC(hMatrix, inputImage, planes=[0], numjobs=3)\n",
    "    \n",
    "if False:\n",
    "    # Temporary code to test running with an image pair\n",
    "    # This is maybe not a comprehensive test, but it run with two different (albeit proportional)\n",
    "    # images and checks that the result matches the result for two totally independent calls on a single array.\n",
    "    hMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape)\n",
    "    candidate = np.tile(inputImage[np.newaxis,0,0], (2,1,1))\n",
    "    candidate[1] *= 1.4\n",
    "    temp = backwardProjectACC(hMatrix, candidate, planes=None, numjobs=1)\n",
    "    dualRoundtrip = forwardProjectACC(hMatrix, temp, planes=None)\n",
    "\n",
    "    temp = backwardProjectACC(hMatrix, candidate[0], planes=None, numjobs=1)\n",
    "    firstRoundtrip = forwardProjectACC(hMatrix, temp, planes=None, numjobs=1)    \n",
    "    comparison = np.max(np.abs(firstRoundtrip - dualRoundtrip[0]))\n",
    "    print('test result (should be <<1): %e' % comparison)\n",
    "    if (comparison > 1e-6):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")\n",
    "    \n",
    "    temp = backwardProjectACC(hMatrix, candidate[1], planes=None, numjobs=1)\n",
    "    secondRoundtrip = forwardProjectACC(hMatrix, temp, planes=None, numjobs=1)    \n",
    "    comparison = np.max(np.abs(secondRoundtrip - dualRoundtrip[1]))\n",
    "    print('test result (should be <<1): %e' % comparison)\n",
    "    if (comparison > 1e-6):\n",
    "        print(\" -> WARNING: disagreement detected\")\n",
    "    else:\n",
    "        print(\" -> OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def AnalyzeTestResults():\n",
    "    with open('overall.txt') as f:\n",
    "        csv_reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            pass\n",
    "    startTime = float(row[0])\n",
    "    endTime = float(row[1])\n",
    "    userTime = float(row[4])\n",
    "    sysTime = float(row[5])\n",
    "\n",
    "    rows = []\n",
    "    for fn in glob.glob('perf_diags/*_*.txt'):\n",
    "        with open(fn) as f:\n",
    "            csv_reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in csv_reader:\n",
    "                pass\n",
    "            rows.append(row)\n",
    "    rows = np.array(rows).astype('float').transpose()\n",
    "    firstPid = np.min(rows[0])\n",
    "    rows[0] -= firstPid\n",
    "    rows[1:3] -= startTime\n",
    "    rows = rows[:,np.argsort(rows[1],kind='mergesort')]\n",
    "    rows = rows[:,rows[0].argsort(kind='mergesort')]\n",
    "\n",
    "    deadTimeStart = 0\n",
    "    deadTimeMid = 0\n",
    "    deadTimeEnd = 0\n",
    "    threadWorkTime = 0\n",
    "    thisThreadStartTime = 0\n",
    "    longestThreadRunTime = 0\n",
    "    longestThreadRunPid = -1\n",
    "    latestStartTime = 0\n",
    "    userTimeBreakdown = 0\n",
    "    sysTimeBreakdown = 0\n",
    "    for i in range(rows.shape[1]):\n",
    "        pid = rows[0,i]\n",
    "        t0 = rows[1,i]\n",
    "        t1 = rows[2,i]\n",
    "        userTimeBreakdown += rows[4,i]\n",
    "        sysTimeBreakdown += rows[5,i]\n",
    "        if (i == 0):\n",
    "            deadTimeStart += t0\n",
    "            thisThreadStartTime = t0\n",
    "            latestStartTime = t0\n",
    "        else:\n",
    "            if (pid == rows[0,i-1]):\n",
    "                deadTimeMid += t0 - rows[2,i-1]\n",
    "            else:\n",
    "                latestStartTime = max(latestStartTime, t0)\n",
    "                thisThreadRunTime = rows[2,i-1]-thisThreadStartTime  # For previous pid\n",
    "                if (thisThreadRunTime > longestThreadRunTime):\n",
    "                    longestThreadRunPid = rows[0,i-1]\n",
    "                    longestThreadRunTime = thisThreadRunTime\n",
    "                thisThreadStartTime = t0\n",
    "                deadTimeStart += t0\n",
    "                deadTimeEnd += (endTime-startTime) - rows[2,i-1]\n",
    "        threadWorkTime += t1-t0\n",
    "        plt.plot([t0, t1], [pid, pid])\n",
    "        plt.plot(t0, pid, 'x')\n",
    "    thisThreadRunTime = t1-thisThreadStartTime\n",
    "    if (thisThreadRunTime > longestThreadRunTime):\n",
    "        longestThreadRunPid = pid\n",
    "        longestThreadRunTime = thisThreadRunTime\n",
    "    deadTimeEnd += (endTime-startTime) - rows[2,-1]\n",
    "    print('Elapsed time', endTime-startTime)\n",
    "    print('Longest thread run time', longestThreadRunTime, 'pid', int(longestThreadRunPid))\n",
    "    print('Latest start time', latestStartTime)\n",
    "    print('Thread work time', threadWorkTime)\n",
    "    print('Dead time', deadTimeStart, deadTimeMid, deadTimeEnd)\n",
    "    print(' Total', deadTimeStart + deadTimeMid + deadTimeEnd)\n",
    "    print('User cpu time', userTime)\n",
    "    print('System cpu time', sysTime)\n",
    "    print('User cpu time for subset', userTimeBreakdown)\n",
    "    print('System cpu time for subset', sysTimeBreakdown)\n",
    "\n",
    "    with open('stats.txt', 'a') as f:\n",
    "        f.write('%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n' % (numJobsForTesting, endTime-startTime, threadWorkTime, \\\n",
    "                        longestThreadRunTime, latestStartTime, deadTimeStart, deadTimeMid, deadTimeEnd, userTime, sysTime))\n",
    "\n",
    "    plt.xlim(0, endTime-startTime)\n",
    "    plt.ylim(-0.5,np.max(rows[0])+0.5)\n",
    "    plt.show()\n",
    "    \n",
    "if False:\n",
    "    for numJobsForTesting in range(1,13):\n",
    "        ru1 = cpuTime('both')\n",
    "        temp = backwardProjectACC(Ht, HtPathFormat, HtReducedShape, inputImage, numjobs=numJobsForTesting, planes=None)\n",
    "        ru2 = cpuTime('both')\n",
    "        print('overall delta rusage:', ru2-ru1)\n",
    "        AnalyzeTestResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomment(csvfile):\n",
    "    for row in csvfile:\n",
    "        raw = row.split('#')[0].strip()\n",
    "        if raw: yield raw\n",
    "\n",
    "def AnalyzeTestResults2(fn):\n",
    "    rows = []\n",
    "    with open(fn) as f:\n",
    "        csv_reader = csv.reader(decomment(f), delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "    rows = np.array(rows).astype(np.float).transpose()\n",
    "\n",
    "    plt.plot(rows[0], rows[2]/rows[2,0], label='work time')\n",
    "    plt.plot(rows[0], np.sum(rows[5:8], axis=0)/(rows[0]*rows[1]), label='dead time')\n",
    "    plt.plot(rows[0], rows[5]/(rows[0]*rows[1]), label='dead start')\n",
    "    plt.plot(rows[0], rows[1]/(rows[1,0]/rows[0]), label='runtime excess')\n",
    "    plt.ylim(0,2.5)\n",
    "    plt.legend(loc=2)\n",
    "    plt.show()\n",
    "\n",
    "plt.title('Dummy work on empty arrays')\n",
    "AnalyzeTestResults2('stats-dummy.txt')\n",
    "plt.title('Real work')\n",
    "AnalyzeTestResults2('stats-realwork.txt')\n",
    "plt.title('Smaller memory footprint - no improvement')\n",
    "AnalyzeTestResults2('stats-no-H.txt')\n",
    "plt.title('New code')\n",
    "AnalyzeTestResults2('stats-new-code.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a single backprojection and compare against definitive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "planesToProcess = None\n",
    "if False:\n",
    "    t0 = time.time()\n",
    "    Htf = backwardProjectACC_original(Ht, inputImage, CAindex, planes=planesToProcess)\n",
    "    print('Original code took %f'%(time.time()-t0))\n",
    "elif True:\n",
    "    # Profile my code (single-threaded) on a cropped version of Prevedel's data\n",
    "    myStats = cProfile.run('Htf = backwardProjectACC(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), inputImage, planes=planesToProcess, numjobs=1)', 'mystats')\n",
    "    p = pstats.Stats('mystats')\n",
    "    p.strip_dirs().sort_stats('cumulative').print_stats(40)\n",
    "else:\n",
    "    # Profile my code (single-threaded) in the sort of scenario I would expect to run it in for my PIV experiments\n",
    "    tempInputImage = np.zeros((2,Nnum*20,Nnum*20))\n",
    "    myStats = cProfile.run('temp = backwardProjectACC(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), tempInputImage, planes=planesToProcess, numjobs=1)', 'mystats')\n",
    "    p = pstats.Stats('mystats')\n",
    "    p.strip_dirs().sort_stats('cumulative').print_stats(40)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against definitive version generated from Matlab\n",
    "if planesToProcess is not None:\n",
    "    print('WARNING: the following test is not valid because not all planes were processed')\n",
    "definitive = tifffile.imread('Data/03_Reconstructed/exampleData/definitive_worm_crop_X15_backproject.tif')\n",
    "definitive = np.transpose(definitive, axes=(0,2,1))\n",
    "comparison = np.max(np.abs(definitive[4] - Htf[4]*10))\n",
    "print('Compare against matlab result (should be <1.0): %f' % comparison)\n",
    "if (comparison > 1.0):\n",
    "    print(\" -> WARNING: disagreement detected\")\n",
    "else:\n",
    "    print(\" -> OK\")\n",
    "\n",
    "#tifffile.imsave('Htf_backproject4.tif', np.transpose(Htf*1e2, axes=(0,2,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a full deconvolution and compare against definitive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xguess = Htf.copy();\n",
    "maxIter = 8\n",
    "deconvolvedResult = deconvRL(HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape), Htf, maxIter, Xguess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against definitive version generated from Matlab\n",
    "definitive = tifffile.imread('Data/03_Reconstructed/exampleData/definitive_worm_crop_X15_iter8.tif')\n",
    "definitive = np.transpose(definitive, axes=(0,2,1))\n",
    "comparison = np.max(np.abs(definitive - deconvolvedResult*1e3))\n",
    "print('Compare against matlab result (should be <1.0): %f' % comparison)\n",
    "if (comparison > 1.0):\n",
    "    print(\" -> WARNING: disagreement detected\")\n",
    "else:\n",
    "    print(\" -> OK\")\n",
    "\n",
    "#tifffile.imsave('iter8.tif', np.transpose(Xguess*1e3, axes=(0,2,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for flow field (single-plane toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two identical images of the same synthetic object,\n",
    "# which for now consists of a cloud of random gaussian spots\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "if False:\n",
    "    numSpots = 100\n",
    "    imageSize = 240\n",
    "    sigma = 8\n",
    "    controlPointSpacing = 30    \n",
    "elif False:\n",
    "    numSpots = 400\n",
    "    imageSize = 120\n",
    "    sigma = 2\n",
    "    controlPointSpacing = 30\n",
    "else:\n",
    "    numSpots = 1000\n",
    "    imageSize = 180\n",
    "    sigma = 2\n",
    "    controlPointSpacing = 30\n",
    "syntheticImageExtendSize = 30\n",
    "\n",
    "syntheticObjectExt = np.zeros((1, imageSize+syntheticImageExtendSize, imageSize))\n",
    "syntheticObjectExt[0, (np.random.random(numSpots)*syntheticObjectExt.shape[1]).astype('int'), \\\n",
    "                      (np.random.random(numSpots)*syntheticObjectExt.shape[2]).astype('int')] = 1\n",
    "syntheticObjectExt = gaussian_filter(syntheticObjectExt, sigma=(0,sigma,sigma))\n",
    "plt.imshow(syntheticObjectExt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PSF that we will use\n",
    "\n",
    "# First check we're using the expected PSF - the plane choices used here are intended to work with this PSF.\n",
    "assert(matPath == 'PSFmatrix/PSFmatrix_M40NA0.95MLPitch150fml3000from-13to0zspacing0.5Nnum15lambda520n1.0.mat')\n",
    "\n",
    "zPlaneToModel = _H.shape[0]-1   # Modelling native focal plane\n",
    "zPlaneToModel = 7   # Modelling some way from the native focal plane, which should perform fairly well\n",
    "zPlaneToModel = _H.shape[0]-3   # Modelling close to native focal plane. This has artefacts - prev one is fairly artefact-free\n",
    "zPlaneToModel = _H.shape[0]-2\n",
    "\n",
    "\n",
    "pivHMatrix = HMatrix(_HPathFormat, _HtPathFormat, _HReducedShape, numZ=1, zStart=zPlaneToModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    shiftType = 'piv'\n",
    "    source = 'synthetic'\n",
    "    actualImageExtendSize = syntheticImageExtendSize\n",
    "    # Allowing an x search range is fairer, but it makes little difference for vertical flow\n",
    "    xMotionPermitted = False\n",
    "    xSearchRange = 0\n",
    "    ySearchRange = 10\n",
    "else:\n",
    "    shiftType = 'piv'\n",
    "    source = 'piv'\n",
    "    actualImageExtendSize = 0\n",
    "    xMotionPermitted = True\n",
    "    xSearchRange = 8\n",
    "    ySearchRange = 8\n",
    "\n",
    "\n",
    "def forwardProjectACC_PIV(hMatrix, obj, shiftDescription):\n",
    "    # Compute the AB images obtained from the single object we are provided with\n",
    "    # (with the B image being of the object shifted by shiftYX).\n",
    "    # We give each image half the intensity in order to conserve energy.\n",
    "    dualObject = np.tile(obj[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "    return forwardProjectACC(hMatrix, dualObject, logPrint=False, progress=None)\n",
    "\n",
    "def dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    # Compute the reverse transform given the AB images (B image shifted by shiftYX).\n",
    "    # First we do the reverse transformation on both images\n",
    "    dualObject = backwardProjectACC(hMatrix, dualProjection, logPrint=False, progress=None)\n",
    "    # Now we reverse the shift on the B object\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], -shiftDescription)\n",
    "    # Now, ideally the objects would match, but of course in practice there will be discrepancies,\n",
    "    # especially if we are not using the correct shiftDescription.\n",
    "    # To make the operation match the transpose of the forward operation,\n",
    "    # we add the two objects and divide by 2 here\n",
    "    return dualObject\n",
    "\n",
    "def fusedBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription):\n",
    "    dualObject = dualBackwardProjectACC_PIV(hMatrix, dualProjection, shiftDescription)\n",
    "    result = np.sum(dualObject, axis=1) / 2.0     # Merge the two backprojection\n",
    "    return result\n",
    "\n",
    "def deconvRL_PIV_OLD(hMatrix, imageAB, maxIter, Xguess, shiftDescription):\n",
    "    # I believed this to be the RL algorithm in the way I have written it in the past.\n",
    "    # However, this gives different results to Prevedel's implementation\n",
    "    # (mine seems to converge more slowly).\n",
    "    # TODO: I should look into this and see if I've just made a mistake or if they are actually different.\n",
    "    \n",
    "    # Xguess is our single combined guess of the object\n",
    "    Xguess = Xguess.copy()    # Because we will be updating it, and caller may not always be expecting that\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        relativeBlurDual = imageAB / forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        Xguess *= fusedBackwardProjectACC_PIV(hMatrix, relativeBlurDual, shiftDescription)\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def deconvRL_PIV(hMatrix, imageAB, maxIter, shiftDescription):\n",
    "    # Note:\n",
    "    #  Htf is the *initial* backprojection of the camera image\n",
    "    #  Xguess is the initial guess for the object\n",
    "    Htf = fusedBackwardProjectACC_PIV(hMatrix, imageAB, shiftDescription)\n",
    "    Xguess = Htf.copy()\n",
    "    for i in tqdm(range(maxIter), desc='RL deconv'):\n",
    "        t0 = time.time()\n",
    "        HXguess = forwardProjectACC_PIV(hMatrix, Xguess, shiftDescription)\n",
    "        HXguessBack = fusedBackwardProjectACC_PIV(hMatrix, HXguess, shiftDescription)\n",
    "        errorBack = Htf / HXguessBack\n",
    "        Xguess = Xguess * errorBack\n",
    "        Xguess[np.where(np.isnan(Xguess))] = 0\n",
    "        t1 = time.time() - t0\n",
    "    return Xguess\n",
    "\n",
    "def RollNoninteger(obj, amount, axis=0):\n",
    "    intAmount = int(amount)\n",
    "    frac = amount - intAmount\n",
    "    result1 = np.roll(obj, intAmount, axis=axis)\n",
    "    result2 = np.roll(obj, intAmount+1, axis=axis)\n",
    "    return result1 * (1-frac) + result2 * frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (shiftType == 'uniform') or (shiftType == 'uniformSK'):\n",
    "    if shiftType == 'uniform':\n",
    "        def ShiftObject(obj, shiftYX):\n",
    "            # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "            # For now I just consider a uniform translation in xy\n",
    "            # \n",
    "            # TODO: We need to worry about conserving energy during the shift. \n",
    "            # For now I will do a circular shift in order to avoid having to worry about this!\n",
    "            result = RollNoninteger(obj, shiftYX[0,0], axis=len(obj.shape)-2)\n",
    "            return RollNoninteger(result, shiftYX[0,1], axis=len(obj.shape)-1)\n",
    "    else:\n",
    "        # A lot of code duplication here, but it's just an experiment for now\n",
    "        def ShiftObject(obj, shiftYX):\n",
    "            # Generate control points in the corners of the image\n",
    "            src_cols = np.arange(0, obj.shape[-1]+1, obj.shape[-1])\n",
    "            src_rows = np.arange(0, obj.shape[-2]+1, obj.shape[-2])\n",
    "            src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "            src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "            dst = src + shiftYX[0]\n",
    "            tform = PiecewiseAffineTransform()\n",
    "            tform.estimate(src, dst)\n",
    "            # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "            maxVal = np.max(np.abs(obj))\n",
    "            if len(obj.shape) == 3:\n",
    "                result = np.zeros(obj.shape)\n",
    "                for cc in range(obj.shape[0]):\n",
    "                    result[cc] = warp(obj[cc]/maxVal, tform) * maxVal\n",
    "                return result\n",
    "            else:\n",
    "                return warp(obj/maxVal, tform) * maxVal\n",
    "    \n",
    "    def ExampleShiftDescriptionForObject(obj):\n",
    "        return np.array([[-10, 20]])\n",
    "    \n",
    "    def VelocityShapeForObject(obj):\n",
    "        return (2,)\n",
    "\n",
    "    def IWCentresForObject(obj):\n",
    "        return np.array([[int(obj.shape[-2]/2), int(obj.shape[-1]/2)]])\n",
    "\n",
    "else:\n",
    "    # Arbitrary motion described in terms of an array of control points at IWCentresForObject\n",
    "    assert(shiftType == 'piv')\n",
    "    def IWCentresForObject(obj):\n",
    "        startPos = 0\n",
    "        # Reusing the code from the skimage example, since that actualy does what we need:\n",
    "        src_cols = np.arange(startPos, obj.shape[-1]+1, controlPointSpacing)\n",
    "        src_rows = np.arange(startPos, obj.shape[-2]+1-actualImageExtendSize, controlPointSpacing)\n",
    "        src_rows, src_cols = np.meshgrid(src_rows, src_cols)\n",
    "        return np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    def VelocityShapeForObject(obj):\n",
    "        return IWCentresForObject(obj).shape\n",
    "    \n",
    "    def ExampleShiftDescriptionForObject(obj):\n",
    "        peakVelocity = 7\n",
    "        iwPos = IWCentresForObject(obj)\n",
    "        shiftDescription = np.zeros(VelocityShapeForObject(obj))\n",
    "        width = obj.shape[-1]\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            quadraticProfile = ((width/2)**2 - (iwPos[n,0]-width/2)**2)\n",
    "            quadraticProfile = quadraticProfile / ((width/2)**2) * peakVelocity\n",
    "            shiftDescription[n,1] = quadraticProfile\n",
    "        if xMotionPermitted:\n",
    "            return shiftDescription\n",
    "        else:\n",
    "            return shiftDescription[:,1:2]\n",
    "\n",
    "    def ExtraDuplicateRow(shifts, add=None):\n",
    "        assert(len(shifts.shape) == 2)\n",
    "        rowLength = int(np.sqrt(shifts.shape[0]))\n",
    "        shifts = np.reshape(shifts, (rowLength, rowLength, shifts.shape[1]))\n",
    "        toAppend = shifts[:,-1:,:].copy()\n",
    "        if add is not None:\n",
    "            toAppend += add\n",
    "        result = np.append(shifts, toAppend, axis=1)\n",
    "        return result.reshape(result.shape[0]*result.shape[1], result.shape[2])\n",
    "\n",
    "    def ShiftObject(obj, shiftYX):\n",
    "        # Transform a 3D object according to the flow information provided in shiftDescription\n",
    "        # I use a piecewise affine transformation that should approximately correspond to\n",
    "        # what I use for PIV analysis\n",
    "        src = IWCentresForObject(obj)\n",
    "        if (src.shape[0] != shiftYX.shape[0]):\n",
    "            print(src.shape, shiftYX.shape, obj.shape)\n",
    "            assert(src.shape[0] == shiftYX.shape[0])\n",
    "        \n",
    "        if (actualImageExtendSize > 0):\n",
    "            src = ExtraDuplicateRow(src, add=np.array([0, actualImageExtendSize]))\n",
    "            if xMotionPermitted:\n",
    "                dst = src + ExtraDuplicateRow(shiftYX)\n",
    "            else:\n",
    "                dst = src.copy().astype(shiftYX.dtype)\n",
    "                dst[:,1] = dst[:,1] + ExtraDuplicateRow(shiftYX)[:,0]\n",
    "        else:\n",
    "            dst = src.copy().astype(shiftYX.dtype) + shiftYX\n",
    "            \n",
    "        tform = PiecewiseAffineTransform()\n",
    "        tform.estimate(src, dst)\n",
    "        # Annoyingly, skimage insists that a float input is scaled between 0 and 1, so I must rescale here\n",
    "        maxVal = np.max(np.abs(obj))\n",
    "        if len(obj.shape) == 3:\n",
    "            result = np.zeros(obj.shape)\n",
    "            for cc in range(obj.shape[0]):\n",
    "                result[cc] = warp(obj[cc]/maxVal, tform) * maxVal\n",
    "            return result\n",
    "        else:\n",
    "            assert(len(obj.shape) == 2)\n",
    "            return warp(obj/maxVal, tform) * maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if source == 'synthetic':\n",
    "    # Generate a synthetic shift in the B image\n",
    "    dualObject = np.tile(syntheticObjectExt[:,np.newaxis,:,:], (1,2,1,1)) *1e3#* 1e7\n",
    "    if False:\n",
    "        warnings.warn('Loading previously-saved dualObject')\n",
    "        dualObject = np.load('dualObject5.npy')\n",
    "    \n",
    "    shiftDescription = ExampleShiftDescriptionForObject(dualObject)\n",
    "    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "\n",
    "    # Since I am only using a local minimizer, we need to start with a decent guess as to the flow.\n",
    "    # I think that's ok though: we should have that from a PIV estimate on the with-artefacts AB images\n",
    "    #initialShiftGuess = np.zeros(VelocityShapeForObject(dualObject))\n",
    "    initialShiftGuess = shiftDescription + np.random.random(shiftDescription.shape) * 4.0\n",
    "else:\n",
    "    assert(source == 'piv')\n",
    "    pivImagePair = tifffile.imread('piv-raw-data/038298.tif')[24:26,:15*20,:15*16].astype('float64')\n",
    "    # Note: frames 57-58 (wrong pair) would be an option to investigate bigger motion (~16px) with imperfect AB matches\n",
    "    #              64-65 (correct pair) are another example of small movement (0-3px)\n",
    "    dualObject = pivImagePair[np.newaxis]\n",
    "    # For now, I just guess an initial shift of zero\n",
    "    shiftDescription = np.zeros(VelocityShapeForObject(dualObject)).astype('float64')\n",
    "    initialShiftGuess = shiftDescription.copy()\n",
    "    \n",
    "    \n",
    "lb = []\n",
    "ub = []\n",
    "if xMotionPermitted:\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-xSearchRange, shiftDescription[n,1]-ySearchRange])\n",
    "        ub.extend([shiftDescription[n,0]+xSearchRange, shiftDescription[n,1]+ySearchRange])\n",
    "else:\n",
    "    for n in range(shiftDescription.shape[0]):\n",
    "        lb.extend([shiftDescription[n,0]-ySearchRange])\n",
    "        ub.extend([shiftDescription[n,0]+ySearchRange])\n",
    "shiftSearchBounds = scipy.optimize.Bounds(lb, ub, True)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dualObject[0,0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dualObject[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used for investigations in which I directly warp the input object/images,\n",
    "# without any use of light field PSFs and deconvolution\n",
    "\n",
    "def ScoreShift2(candidateShiftYX, method, imageAB, hMatrix=None, shiftHistory=None, scaling=1.0, log=True, comparator=None):\n",
    "    return ScoreShift3(candidateShiftYX, method, imageAB, hMatrix, shiftHistory, scaling, log, comparator)[0]\n",
    "\n",
    "def ScoreShift3(candidateShiftYX, method, imageAB, hMatrix=None, shiftHistory=None, scaling=1.0, log=True, comparator=None):\n",
    "    # Our input parameters get flattened, so we need to reshape them to Nx2 like my code is expecting\n",
    "    # 'scaling' is useful for optimizers that insist on initial very small step sizes\n",
    "    if xMotionPermitted:\n",
    "        candidateShiftYX = candidateShiftYX.reshape(int(candidateShiftYX.shape[0]/2),2) * scaling\n",
    "    else:\n",
    "        candidateShiftYX = candidateShiftYX.reshape(candidateShiftYX.shape[0],1) * scaling\n",
    "    # Sanity check and reminder that we have a 2xMxN AB image pair\n",
    "    assert(len(imageAB.shape) == 3)  \n",
    "    assert(imageAB.shape[0] == 2)\n",
    "        \n",
    "    if log:\n",
    "        print('======== Score shift ========', candidateShiftYX.T)\n",
    "\n",
    "    if method == 'joint':\n",
    "        # Perform the joint deconvolution to recover a single object\n",
    "        res = deconvRL_PIV(hMatrix, imageAB, maxIter=8, shiftDescription=candidateShiftYX)\n",
    "        # Evaluate how well the forward-projected result matches the actual camera images, using SSD\n",
    "        candidateImageAB = forwardProjectACC_PIV(hMatrix, res, candidateShiftYX)\n",
    "        assert(len(candidateImageAB.shape) == 3)  # Temp test: surely this must be the case, but I am doubting myself now (after merging naive and joint code together...)\n",
    "    else:\n",
    "        # Just warp the raw B image manually and look at how the two images compare\n",
    "        assert(method == 'naive')\n",
    "        candidateImageAB = imageAB.copy()\n",
    "        # A bit of dimensional gymnastics here, because ShiftObject expects an *object*,\n",
    "        # i.e. a 3D volume, whereas in this case we just have a 2D image\n",
    "        candidateImageAB[1,:,:] = ShiftObject(candidateImageAB[np.newaxis,0,:,:], candidateShiftYX)[0]  \n",
    "    # Sanity check and reminder that we have a 2xMxN AB image pair\n",
    "    assert(len(candidateImageAB.shape) == 3)  \n",
    "    assert(candidateImageAB.shape[0] == 2)\n",
    "\n",
    "    imageToScore = candidateImageAB[1, 1:-1-actualImageExtendSize, 1:-1-actualImageExtendSize]\n",
    "    referenceImage = imageAB[1, 1:-1-actualImageExtendSize, 1:-1-actualImageExtendSize]\n",
    "    # TODO: I should think about whether this is the correct thing to do.\n",
    "    # The A images will be identical in the case of the 'naive' method (direct warping),\n",
    "    # but for the 'joint' method my intention is that this should be a useful normalization.\n",
    "    # I need to think more about that though (and comment an explanation, if nothing else!)\n",
    "    renormHack = np.average(candidateImageAB[0]) / np.average(imageAB[0])\n",
    "    ssdScore = np.sum((imageToScore/renormHack - referenceImage)**2)\n",
    "\n",
    "    if comparator is not None:\n",
    "        maxLoc = np.argmax(np.abs(imageToScore - comparator)[1:-1,1:-1])\n",
    "        maxVal =    np.max(np.abs(imageToScore - comparator)[1:-1,1:-1])\n",
    "        plt.imshow((imageToScore - comparator)[170:,150:])\n",
    "        plt.colorbar()\n",
    "        plt.title('BRel (max %e)'%maxVal)\n",
    "        print('Max val %f at %d (image scale %d)' % (maxVal, maxLoc, np.max(comparator)))\n",
    "        plt.show()\n",
    "\n",
    "    if shiftHistory is not None:\n",
    "        shiftHistory.Update(candidateShiftYX, ssdScore)\n",
    "        if log:\n",
    "            if shiftHistory.PlotHistory(onlyPlotEvery=20):\n",
    "                if method == 'joint':\n",
    "                    print(res.shape)\n",
    "                    dualObject = np.tile(res[:,np.newaxis,:,:] / 2.0, (1,2,1,1))\n",
    "                    dualObject[:,1,:,:] = ShiftObject(dualObject[:,1,:,:], shiftDescription)\n",
    "                    print(dualObject.shape)\n",
    "                    ShowDualObjectAndFlow(dualObject, candidateShiftYX)\n",
    "                else:\n",
    "                    ShowDualObjectAndFlow(candidateImageAB, candidateShiftYX)\n",
    "    if log:\n",
    "        print('return', ssdScore)\n",
    "    return (ssdScore, renormHack, np.average(candidateImageAB[0]), np.average(imageAB), candidateImageAB[1])\n",
    "\n",
    "def ShowDualObjectAndFlow(dualObject, shiftDescription, otherObject=None, otherObject2=None):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if (len(dualObject.shape) == 4):\n",
    "        assert(dualObject.shape[1] == 2)\n",
    "        plt.imshow(dualObject[0,0])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(dualObject[0,1])\n",
    "    else:\n",
    "        assert(len(dualObject.shape) == 3)  # It's actually a dual image not an object\n",
    "        assert(dualObject.shape[0] == 2)\n",
    "        plt.imshow(dualObject[1])\n",
    "    iwPos = IWCentresForObject(dualObject)\n",
    "    if xMotionPermitted == False:\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            plt.plot([iwPos[n,0], iwPos[n,0]], \\\n",
    "                     [iwPos[n,1], iwPos[n,1] - shiftDescription[n,0]/2], color='red')\n",
    "    else:\n",
    "        for n in range(iwPos.shape[0]):\n",
    "            plt.plot([iwPos[n,0], iwPos[n,0] - shiftDescription[n,0]/2], \\\n",
    "                     [iwPos[n,1], iwPos[n,1] - shiftDescription[n,1]/2], color='red')\n",
    "    plt.xlim(0, dualObject.shape[-1])\n",
    "    plt.ylim(dualObject.shape[-2], 0)\n",
    "    plt.show()\n",
    "    if otherObject is not None:\n",
    "        plt.imshow(otherObject[0])\n",
    "        plt.show()        \n",
    "    if otherObject2 is not None:\n",
    "        plt.imshow(otherObject2[0])\n",
    "        plt.show()   \n",
    "        \n",
    "def CheckConvergence(funcToCall, convergedShift, args):\n",
    "    initialScore = funcToCall(convergedShift.flatten(), *args)\n",
    "    print('initial score', initialScore)\n",
    "    for du in [0.5, -0.5, 1.5, -1.5]:\n",
    "        for n in [7, 8, 12, 13]:\n",
    "            temp = convergedShift.copy()\n",
    "            temp[n] += du\n",
    "            score = funcToCall(temp, *args)\n",
    "            print('offset score', score)\n",
    "            if (score < initialScore):\n",
    "                print(n, du, 'BETTER!')\n",
    "\n",
    "def ReportOnOptimizerConvergence(shiftHistory, obj):\n",
    "    bestShift = shiftHistory.BestShift()\n",
    "    print(shiftHistory.BestScore())\n",
    "    print('np.array([', end='')\n",
    "    for n in bestShift.flatten():\n",
    "        print('%f, '%n, end='')\n",
    "    print('])')\n",
    "    CheckConvergence(ScoreShift2, bestShift.flatten(), ('naive', obj, None, None, 1.0, False))                \n",
    "                \n",
    "class ShiftHistory:\n",
    "    def __init__(self):\n",
    "        self.Reset()\n",
    "\n",
    "    def __copy__(self):\n",
    "        result = ShiftHistory()\n",
    "        result.shiftHistory = self.shiftHistory\n",
    "        result.scoreHistory = self.scoreHistory\n",
    "        result.counter = self.counter\n",
    "        return result\n",
    "\n",
    "    def Reset(self):\n",
    "        self.scoreHistory = []\n",
    "        self.shiftHistory = []\n",
    "        self.counter = 0\n",
    "    \n",
    "    def Update(self, shift, score):\n",
    "        self.shiftHistory.append(shift)\n",
    "        self.scoreHistory.append(score)\n",
    "        self.counter = self.counter + 1\n",
    "        \n",
    "    def BestScore(self):\n",
    "        return np.min(self.scoreHistory)\n",
    "\n",
    "    def BestShift(self):\n",
    "        return self.shiftHistory[np.argmin(self.scoreHistory)]\n",
    "\n",
    "    def PlotHistory(self, onlyPlotEvery=1):\n",
    "        if ((self.counter%onlyPlotEvery) == 0) and (len(self.shiftHistory) > 0):\n",
    "            print('best score so far:', np.min(self.scoreHistory))\n",
    "            # Plot one of the shifts\n",
    "            shiftShape = self.shiftHistory[0].shape\n",
    "            selectedItem = np.minimum(int(np.sqrt(shiftShape[0])/2), shiftShape[0]-1)\n",
    "            selectedShift = np.array(self.shiftHistory)[:, selectedItem, -1]\n",
    "            plt.plot(selectedShift)\n",
    "            plt.show()\n",
    "            # Plot scores, with a suitable y axis scaling to see the interesting parts.\n",
    "            # We limit the y axis to avoid stupid guesses distorting the plot.\n",
    "            improvement = self.scoreHistory[0] - np.min(self.scoreHistory)\n",
    "            plt.ylim(np.min(self.scoreHistory), self.scoreHistory[0]+2*improvement)\n",
    "            plt.plot(self.scoreHistory)\n",
    "            plt.show()\n",
    "\n",
    "            with open('scores.txt', 'a') as f:\n",
    "                f.write('%f\\t' % self.scoreHistory[-1])\n",
    "                for n in self.shiftHistory[-1]:\n",
    "                    if xMotionPermitted:\n",
    "                        f.write('%f\\t%f\\t' % (n[0], n[1]))\n",
    "                    else:\n",
    "                        f.write('%f\\t' % (n[0]))\n",
    "                f.write('\\n')\n",
    "            return True\n",
    "        else:\n",
    "            return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate synthetic light-field-recovered AB images (doing it the naive way, not using my new joint deconvolution)\n",
    "# Run the imaging cycle on each of the AB images individually (i.e. introduce artefacts into them)\n",
    "dualObjectRecovered = dualObject.copy()\n",
    "for n in [0, 1]:\n",
    "    cameraImage = forwardProjectACC(pivHMatrix, dualObject[:,n,:,:], logPrint=False)\n",
    "    backProjected = backwardProjectACC(pivHMatrix, cameraImage, logPrint=False)\n",
    "    \n",
    "    # With the shifted images, we have problems with true zeroes in regions that have no features remaining.\n",
    "    # To avoid this, I apply a very small nonzero background so that the deconvolution doesn't fail.\n",
    "    backProjected = np.maximum(backProjected, 1e-5*np.max(backProjected))\n",
    "    \n",
    "    dualObjectRecovered[:,n,:,:] = deconvRL(pivHMatrix, backProjected, maxIter=8, Xguess=backProjected, logPrint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original object')\n",
    "iwPos = IWCentresForObject(dualObject)\n",
    "ShowDualObjectAndFlow(dualObject, shiftDescription)\n",
    "print('Recovered from light field images (plane %d)' % zPlaneToModel)\n",
    "ShowDualObjectAndFlow(dualObjectRecovered, shiftDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # If I want to give the algorithm the best possible starting point,\n",
    "    # I can give it the actual true shift values as its starting point\n",
    "    # (but it still may iterate away from that...)\n",
    "    warnings.warn(\"WARNING: starting guess is actually the correct flow description\")\n",
    "    startShiftForOptimizer = shiftDescription.copy()\n",
    "else:\n",
    "    startShiftForOptimizer = initialShiftGuess.copy()\n",
    "\n",
    "    \n",
    "def OptimizeToRecoverFlowField(method, imageAB, hMatrix, shiftDescription, initialShiftGuess):\n",
    "    imageAB = imageAB.copy()    # This is just paranoia - I don't think it should get manipulated\n",
    "    print('True shift:', shiftDescription.T)\n",
    "\n",
    "    if False:\n",
    "        plt.imshow(imageAB[0,:,:])\n",
    "        plt.show()\n",
    "        plt.imshow(imageAB[1,:,:])\n",
    "        plt.show()\n",
    "\n",
    "    if False:\n",
    "        print('Score for correct shift:', ScoreShift2(shiftDescription.flatten(), method, imageAB, hMatrix))\n",
    "        print('Score for initial guess:', ScoreShift2(initialShiftGuess.flatten(), method, imageAB, hMatrix))\n",
    "\n",
    "    if True:\n",
    "        optimizationAlgorithm = 'Powell'\n",
    "        options = {'xtol': 1e-2}\n",
    "    elif True:\n",
    "        optimizationAlgorithm = 'L-BFGS-B'\n",
    "        options = {'eps': 5e-03, 'gtol': 1e-6}\n",
    "    else:\n",
    "        optimizationAlgorithm = 'Nelder-Mead'\n",
    "        options = {'eps': 5e-03, 'xatol': 1e-2, 'adaptive': True}\n",
    "\n",
    "    # Optimize to obtain the best-matching shift\n",
    "    shiftHistory = ShiftHistory()\n",
    "    try:\n",
    "        shift = scipy.optimize.minimize(ScoreShift2, initialShiftGuess, bounds=shiftSearchBounds, args=(method, imageAB, hMatrix, shiftHistory), method=optimizationAlgorithm, options=options)\n",
    "    except KeyboardInterrupt:\n",
    "        # Catch keyboard interrupts so that we still return whatever shiftHistory we have built up so far.\n",
    "        print('KEYBOARD INTERRUPT DURING OPTIMIZATION')\n",
    "        return shiftHistory\n",
    "    print('Optimizer finished:', str(shift.message), 'Final shift:', shift.x.T)\n",
    "    return shiftHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using direct shift-matching of the raw input images (for real experimental SPIM-PIV images)\n",
    "if True:\n",
    "    shiftHistoryRaw = OptimizeToRecoverFlowField('naive', dualObject[0], None, shiftDescription, startShiftForOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReportOnOptimizerConvergence(shiftHistoryRaw, dualObject[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using direct shift-matching of the light-field-deconvolved images\n",
    "if True:\n",
    "    shiftHistoryNaive = OptimizeToRecoverFlowField('naive', dualObjectRecovered[0], None, shiftDescription, startShiftForOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReportOnOptimizerConvergence(shiftHistoryNaive, dualObjectRecovered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the reconstruction using my new joint algorithm\n",
    "if True:\n",
    "    # Generate a camera image pair from the object.\n",
    "    # The B image is determined with the help of the chosen shift transform.\n",
    "    imageAB = forwardProjectACC_PIV(pivHMatrix, dualObject[:,0,:,:], shiftDescription)\n",
    "    # Run the joint optimizer optimizer to find the shift value for an input frame pair\n",
    "    shiftHistoryJoint = OptimizeToRecoverFlowField('joint', imageAB, pivHMatrix, shiftDescription, startShiftForOptimizer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    np.save('shiftHistory7c.npy', shiftHistoryJoint.shiftHistory)\n",
    "    np.save('scoreHistory7c.npy', shiftHistoryJoint.scoreHistory)\n",
    "    np.save('dualObject7c.npy', dualObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ReportOnOptimizerConvergence(shiftHistoryJoint, imageAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at how the scores are evolving during the powell iterations\n",
    "vals = np.array(shiftHistoryNaive.shiftHistory)\n",
    "scores = np.array(shiftHistoryNaive.scoreHistory)\n",
    "iwOfInterest = 5*7+3\n",
    "iwOfInterest = 5*7+6# Looking at border control point for shiftHistoryNaive\n",
    "x = []\n",
    "y = []\n",
    "y2 = []\n",
    "\n",
    "if False:\n",
    "    (_,_,_,_,comp) = ScoreShift3(vals[3020].flatten(), 'naive', objectToUse[0], log=False)    \n",
    "    for n in [3054]:#range(3030, 3055):\n",
    "#    for n in range(222, 224):\n",
    "        recalculatedVals = ScoreShift2(vals[n].flatten(), 'naive', objectToUse[0], log=False, comparator=comp)\n",
    "        recalculatedVals2 = ScoreShiftByDirectWarping(vals[n].flatten(), objectToUse[0], log=False)\n",
    "\n",
    "        print(vals[n].flatten()[iwOfInterest], scores[n])\n",
    "#        print(vals[n].flatten()[iwOfInterest], scores[n])\n",
    "     \n",
    "    plt.plot(np.array(vals[3043:3047])[:,iwOfInterest,0], scores[3043:3047], 'x')\n",
    "    plt.show()\n",
    "    plt.plot(np.array(vals[3040:3050])[:,iwOfInterest,0], 'x')\n",
    "    plt.show()\n",
    "\n",
    "if False:\n",
    "    for d in np.arange(5.011, 5.015, 0.0005):\n",
    "        sh = vals[3020].flatten()\n",
    "        sh[iwOfInterest] = d\n",
    "        sc = ScoreShift2(sh, 'naive', objectToUse[0], log=False, comparator=None)#comp)\n",
    "        plt.plot(d, sc, '.', color='red')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if False:\n",
    "    # Compare the results from different control points\n",
    "    sh = vals[3020].flatten()\n",
    "    sh[iwOfInterest] = 5.011\n",
    "    (_,_,_,_,comp) = ScoreShift3(sh, 'naive', objectToUse, log=False)    \n",
    "    for d in [5.012, 5.0135, 5.0145]:\n",
    "        sh[iwOfInterest] = d\n",
    "        sc = ScoreShift2(sh, 'naive', objectToUse[0], log=False, comparator=comp)\n",
    "        print('score', sc)\n",
    "\n",
    "\n",
    "if True:\n",
    "    #for iw in [iwOfInterest]:\n",
    "    for iw in range(49):\n",
    "    #for iw in [0]:\n",
    "        for n in range(0,vals.shape[0]-1):\n",
    "            if (vals[n,iw,0] != vals[n+1,iw,0]):\n",
    "                x.append(vals[n,iw,0])\n",
    "                y.append(scores[n])\n",
    "            else:\n",
    "                if (len(x) > 0):\n",
    "                    if (len(x) > 2):\n",
    "                        plt.plot(x, y, 'x')\n",
    "                        plt.title('%d,%d %d(%d)'%(iw/7,iw%7, n, len(x)))\n",
    "                        plt.show()\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    y2 = []\n",
    "                nStart = n\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand how the optimizer is behaving, scan the search space rather than optimizing\n",
    "\n",
    "# This gives a nice clear quadratic minimum, although biased to about 1.5 (true shift 1.0).\n",
    "# I should remember that I don't expect a perfect result in the native focal plane.\n",
    "# Very clear quadratic minimum at 1.0 when I use z plane index 7. This is good news!\n",
    "\n",
    "actualShift = (1,0)\n",
    "# Generate a camera image pair based on a chosen shift transform\n",
    "imageAB = forwardProjectACC_PIV(thisH, obj, actualShift)\n",
    "scores = []\n",
    "for dx in range(-2,4,1):\n",
    "    scores.append([dx, ScoreShift(np.array([dx,0]), imageAB)])\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores[:,0], scores[:,1], 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
