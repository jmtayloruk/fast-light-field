{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a .mat file representing the light field PSF\n",
    "This code is very closely modelled on Prevedel's original Matlab code (but with a bug fix for the z=0 plane)\n",
    "\n",
    "## Before running\n",
    "This code relies on the small `light_field_integrands` module. This can be installed by going to the `light-field-integrands` subfolder and running `python setup.py build install`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special, scipy.integrate, scipy.signal, scipy.misc\n",
    "import h5py, sys, time, os, h5py, warnings, cProfile, pstats\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import light_field_integrands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 40\n",
    "NA = 0.95\n",
    "MLPitch = 150e-6\n",
    "Nnum = 15\n",
    "# JT: Presumably this stands for 'oversampling ratio'? Although it doesn't appear in the PSF filename,\n",
    "# this is the value that is stored in the .mat files I have been using (and is the default value for their code)\n",
    "OSR = 3\n",
    "\n",
    "n = 1.0\n",
    "fml = 3000e-6\n",
    "lam = 520e-9;\n",
    "zmin = -26e-6\n",
    "zmax = 0\n",
    "zspacing = 2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtol = 1e-10;\n",
    "\n",
    "k = 2*np.pi*n/lam\n",
    "k0 = 2*np.pi*1/lam\n",
    "d = fml\n",
    "ftl = 200e-3          #focal length of tube lens\n",
    "fobj = ftl/M          # focal length of objective lens\n",
    "fnum_obj = M/(2*NA)   # f-number of objective lens (imaging-side)\n",
    "fnum_ml = fml/MLPitch # f-number of microlens\n",
    "\n",
    "assert((Nnum%2)==1), 'Nnum must be an odd number'\n",
    "assert((OSR%2)==1), 'OSR must be an odd number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JT: Load a .mat file generated by the actual Matlab code, for comparison with ours\n",
    "def MatrixFileString():\n",
    "    # Generates the long file string that the Matlab code generates based on the PSF parameters.\n",
    "    # Currently, I just treat the variables as globals, rather than accepting them all as parameters to this function.\n",
    "    return 'M%gNA%gMLPitch%gfml%gfrom%gto%gzspacing%gNnum%glambda%gn%g'%(M, NA, MLPitch*1e6, fml*1e6, zmin*1e6, zmax*1e6, zspacing*1e6, Nnum, lam*1e9, n)\n",
    "\n",
    "def LoadRawMatrixData(matPath):\n",
    "    # Load the matrices from the .mat file.\n",
    "    # This is slow since they must be decompressed and are rather large! (9.5GB each, in single-precision FP)\n",
    "    hReducedShape = []\n",
    "    htReducedShape = []\n",
    "    with h5py.File(matPath, 'r') as f:\n",
    "        print('Load CAindex')\n",
    "        sys.stdout.flush()\n",
    "        _CAindex = f['CAindex'].value.astype('int')\n",
    "        \n",
    "        print('Load H')\n",
    "        sys.stdout.flush()\n",
    "        _H = f['H'].value.astype('float32')\n",
    "        Nnum = _H.shape[2]\n",
    "        aabbRange = int((Nnum+1)/2)        \n",
    "        for cc in range(_H.shape[0]):\n",
    "            HCC =  _H[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            hReducedShape.append(HCC.shape)\n",
    "\n",
    "        print('Load Ht')\n",
    "        sys.stdout.flush()\n",
    "        _Ht = f['Ht'].value.astype('float32')\n",
    "\n",
    "        for cc in range(_Ht.shape[0]):\n",
    "            HtCC =  _Ht[cc, :aabbRange, :aabbRange, _CAindex[0,cc]-1:_CAindex[1,cc], _CAindex[0,cc]-1:_CAindex[1,cc]]\n",
    "            htReducedShape.append(HtCC.shape)\n",
    "        \n",
    "    return (_H, _Ht, hReducedShape, htReducedShape, _CAindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPSFFT(p3, fobj, NA, x1space, scale, lam, fml, M, n):     #√\n",
    "    k = 2*np.pi*n/lam\n",
    "    alpha = np.arcsin(NA/n)\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    psfLine = np.zeros((len(x1space)))\n",
    "    integrandCython_r = scipy.LowLevelCallable.from_cython(light_field_integrands, 'integrandPSF_r')\n",
    "    integrandCython_i = scipy.LowLevelCallable.from_cython(light_field_integrands, 'integrandPSF_i')\n",
    "\n",
    "    for a in tqdm(range(len(x1space))):\n",
    "        x1 = x1space[a]\n",
    "        x2 = 0\n",
    "        xL2normsq = (((x1+M*p1)**2+(x2+M*p2)**2)**0.5)/M\n",
    "        v = k*xL2normsq*np.sin(alpha)   \n",
    "        u = 4*k*p3*(np.sin(alpha/2)**2)\n",
    "\n",
    "        Koi = M/((fobj*lam)**2)*np.exp(-1j*u/(4*(np.sin(alpha/2)**2)))\n",
    "        if False:\n",
    "            # Old, slow pure python code, left here for reference\n",
    "    #        integrand = @(theta) (sqrt(cos(theta))) .* (1+cos(theta))  .*  (exp(-(i*u/2)* (sin(theta/2).^2) / (sin(alpha/2)^2)))  .*  (besselj(0, sin(theta)/sin(alpha)*v))  .*  (sin(theta));\n",
    "            integrand = lambda theta: (np.sqrt(np.cos(theta))) * (1+np.cos(theta))  \\\n",
    "                                        *  (np.exp(-(1j*u/2)* (np.sin(theta/2)**2) / (np.sin(alpha/2)**2))) \\\n",
    "                                        *  (scipy.special.jn(0, np.sin(theta)/np.sin(alpha)*v)) \\\n",
    "                                        *  (np.sin(theta))\n",
    "    #        I0 = integral(@(theta)integrand (theta),0,alpha);  \n",
    "            integrand_r = lambda theta: np.real(integrand(theta))\n",
    "            integrand_i = lambda theta: np.imag(integrand(theta))\n",
    "            # JT: I have bumped up the subdivision limit to 80 in order to silence warnings about problems\n",
    "            # in the integration. However, I suspect it probably doesn't need this level of detail...\n",
    "            I0_r2,err_r2 = scipy.integrate.quad(integrand_r, 0, alpha, limit=80)\n",
    "            I0_i2,err_i2 = scipy.integrate.quad(integrand_i, 0, alpha, limit=80)\n",
    "        if True:\n",
    "            # New fast code (using cython for speed)\n",
    "            alphaFactor = np.sin(alpha/2)**(-2)\n",
    "            uOver2 = u/2\n",
    "            vFactor = v/np.sin(alpha)\n",
    "            I0_r,err_r = scipy.integrate.quad(integrandCython_r, 0, alpha, limit=180, args=(alphaFactor, uOver2, vFactor))\n",
    "            I0_i,err_i = scipy.integrate.quad(integrandCython_i, 0, alpha, limit=180, args=(alphaFactor, uOver2, vFactor))\n",
    "        \n",
    "        I0 = (I0_r + 1j*I0_i)\n",
    "        err = (err_r + 1j*err_i)\n",
    "        psfLine[a] =  np.abs((Koi*I0)**2)\n",
    "    return psfLine / np.max(psfLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelPitch = MLPitch/Nnum # pitch of virtual pixels\n",
    "\n",
    "# JT: not sure why these first two are created as single-element arrays \n",
    "#     - maybe a feature that they never implemented?\n",
    "x1objspace = np.array([0])\n",
    "x2objspace = np.array([0])\n",
    "x3objspace = np.arange(zmin, zmax+0.1*zspacing, zspacing)\n",
    "objspace = np.ones((len(x1objspace),len(x2objspace),len(x3objspace)))\n",
    "# JT: I am not completely sure why, but the code has to work with at least two different z coordinates.\n",
    "# Having only one ultimately leads to division-by-zero in calculating IMGSIZE_REF_IL (because p3max==0),\n",
    "# but I don't follow what IMGSIZE has to do with the total of z planes we have.\n",
    "# I wonder if it might be something to do with having a generous estimate of how rapidly the PSF will spread\n",
    "# as a function of z coordinate...\n",
    "assert(len(x3objspace) > 1)\n",
    "\n",
    "p3max = np.max(np.abs(x3objspace))\n",
    "x1testspace = (pixelPitch/OSR) * np.arange(0, Nnum*OSR*20 +1) #√  [Matlab really does start at 0]\n",
    "x2testspace = [0]   \n",
    "psfLine = calcPSFFT(p3max, fobj, NA, x1testspace, pixelPitch/OSR, lam, d, M, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outArea = np.where(psfLine<0.04)[0]\n",
    "if len(outArea) == 0:  #√ [checked that this logic works]\n",
    "    raise('Estimated PSF size exceeds the limit');   \n",
    "IMGSIZE_REF = int(np.ceil(outArea[0]/(OSR*Nnum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcML(fml, k, x1MLspace, x2MLspace, x1space, x2space):  #√\n",
    "    x1length = len(x1space)\n",
    "    x2length = len(x2space)\n",
    "    x1MLdist = len(x1MLspace)\n",
    "    x2MLdist = len(x2MLspace)\n",
    "    # JT: the Matlab here is a very strange code construction, but its aim appears to be to identify\n",
    "    # one (any) index in x1space that is ==0, and take that as one 'center' in x1.\n",
    "    # It then constructs a list of indices that represents *all* the 'centers' in x1.\n",
    "    # The code relies on the fact that (x1center: -x1MLdist:1) is defined in matlab to use \n",
    "    # only the value of the first element of the array x1center when generating the range.\n",
    "    # original Matlab:\n",
    "    #   x1center = find(x1space==0);\n",
    "    #   x1centerALL = [  (x1center: -x1MLdist:1)  (x1center + x1MLdist: x1MLdist :x1length)];\n",
    "    #   x1centerALL = sort(x1centerALL);\n",
    "    x1center = np.where(x1space==0)[0][0]\n",
    "    x1centerALL_p = np.append(np.arange(x1center, -1, -x1MLdist), \\\n",
    "                              np.arange(x1center+x1MLdist, x1length, x1MLdist)) #√ for python array indexing\n",
    "    np.sort(x1centerALL_p)\n",
    "    x2center = np.where(x2space==0)[0][0]\n",
    "    x2centerALL_p = np.append(np.arange(x2center, -1, -x2MLdist), \\\n",
    "                              np.arange(x2center+x2MLdist, x2length, x2MLdist)) #√ for python array indexing\n",
    "    np.sort(x2centerALL_p)\n",
    "\n",
    "    patternML = np.zeros((len(x1MLspace), len(x2MLspace)), dtype='complex128')\n",
    "    patternMLcp = np.zeros((len(x1MLspace), len(x2MLspace)), dtype='complex128')\n",
    "    for a in range(len(x1MLspace)):\n",
    "        for b in range(len(x2MLspace)):\n",
    "            x1 = x1MLspace[a]\n",
    "            x2 = x2MLspace[b]\n",
    "            xL2norm = x1**2 + x2**2\n",
    "            patternML[a,b] = np.exp(-1j*k/(2*fml)*xL2norm)\n",
    "            patternMLcp[a,b] = np.exp(-0.05*1j*k/(2*fml)*xL2norm) \n",
    "    MLcenters = np.zeros((len(x1space), len(x2space)))\n",
    "    for a in range(len(x1centerALL_p)):\n",
    "        for b in range(len(x2centerALL_p)):\n",
    "            MLcenters[x1centerALL_p[a], x2centerALL_p[b]] = 1\n",
    "    MLARRAY = scipy.signal.fftconvolve(MLcenters.astype('complex128'), patternML, 'same')\n",
    "    return MLARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of PSF ~= {0} [microlens pitch]'.format(IMGSIZE_REF))\n",
    "IMG_HALFWIDTH = np.maximum(Nnum*(IMGSIZE_REF + 1), 2*Nnum)\n",
    "print('Size of IMAGE = {0}x{1}'.format(IMG_HALFWIDTH*2*OSR+1, IMG_HALFWIDTH*2*OSR+1))\n",
    "x1space = (pixelPitch/OSR)*np.arange(-IMG_HALFWIDTH*OSR, IMG_HALFWIDTH*OSR+0.1, 1);   #√? not sure if this is array indexing\n",
    "x2space = (pixelPitch/OSR)*np.arange(-IMG_HALFWIDTH*OSR, IMG_HALFWIDTH*OSR+0.1, 1); \n",
    "x1length = len(x1space)\n",
    "x2length = len(x2space)\n",
    "\n",
    "x1MLspace = (pixelPitch/OSR)* np.arange(-(Nnum*OSR-1)/2 , (Nnum*OSR-1)/2+0.1, 1)\n",
    "x2MLspace = (pixelPitch/OSR)* np.arange(-(Nnum*OSR-1)/2 , (Nnum*OSR-1)/2+0.1, 1)\n",
    "x1MLdist = len(x1MLspace)\n",
    "x2MLdist = len(x2MLspace)\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%% FIND NON-ZERO POINTS %%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "validpts = np.where(objspace>eqtol)\n",
    "numpts = len(validpts[0])\n",
    "# Matlab code:\n",
    "#  [p1indALL p2indALL p3indALL] = ind2sub( size(objspace), validpts);\n",
    "#  p1ALL = x1objspace(p1indALL)';\n",
    "(p1indALL, p2indALL, p3indALL) = validpts\n",
    "p1ALL = x1objspace[p1indALL]\n",
    "p2ALL = x2objspace[p2indALL]\n",
    "p3ALL = x3objspace[p3indALL]\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%% DEFINE ML ARRAY %%%%%%%%%%%%%%%%%%%%%%%%% \n",
    "MLARRAY = calcML(fml, k0, x1MLspace, x2MLspace, x1space, x2space)\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%% Alocate Memory for storing PSFs %%%%%%%%%%%   \n",
    "LFpsfWAVE_STACK = np.zeros((x1length, x2length, numpts), dtype='complex128')\n",
    "psfWAVE_STACK = np.zeros((x1length, x2length, numpts), dtype='complex128')\n",
    "\n",
    "# Note: if, when this cell is run, a warning appears about multidimensional indexing,\n",
    "# this is due to an internal issue in scipy (which I think can be fixed by upgrading to the latest scipy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: \"Projection from single point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fresnel2D(f0,dx0,z,lam):  #√\n",
    "    (Nx,Ny) = f0.shape\n",
    "    k = 2*np.pi/lam\n",
    "\n",
    "    du = 1/(Nx*dx0)\n",
    "    u = np.append(np.arange(0,np.ceil(Nx/2)), np.arange(np.ceil(-Nx/2),0))*du  #√\n",
    "    dv = 1/(Ny*dx0)\n",
    "    v = np.append(np.arange(0,np.ceil(Ny/2)), np.arange(np.ceil(-Ny/2),0))*dv  #√\n",
    "\n",
    "    #√ think I checked this.\n",
    "    #(although there is probably a much more legible way to do this in python with meshgrid or similar,\n",
    "    # and indeed with fftshift as well!)\n",
    "    H = np.exp(-1j*2*np.pi**2 * (np.tile(u[:,np.newaxis],(1,len(v)))**2+np.tile(v,(len(u),1))**2)*z/k)  \n",
    "    f1 = np.exp(1j*k*z)*np.fft.ifft2(np.fft.fft2(f0) * H )\n",
    "    dx1 = dx0\n",
    "    x1 = np.arange(-Nx/2,Nx/2)*dx1\n",
    "    return f1,dx1,x1                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPSF_p(p1, p2, p3, fobj, NA, x1space, x2space, scale, lam, MLARRAY, fml, M, n, centerArea_p):  #√\n",
    "    k = 2*np.pi*n/lam\n",
    "    alpha = np.arcsin(NA/n)\n",
    "    x1length = len(x1space)\n",
    "    x2length = len(x2space)\n",
    "    zeroline = np.zeros(len(x2space), dtype='complex128')\n",
    "\n",
    "    pattern = np.zeros((x1length, x2length), dtype='complex128')\n",
    "    centerPT_m = int(np.ceil(len(x1space)/2))     #√Matlab indexing\n",
    "    integrandCython_r = scipy.LowLevelCallable.from_cython(light_field_integrands, 'integrandPSF_r')\n",
    "    integrandCython_i = scipy.LowLevelCallable.from_cython(light_field_integrands, 'integrandPSF_i')\n",
    "    \n",
    "    for a in tqdm(range(centerArea_p[0],centerPT_m), leave=False):   #√\n",
    "        patternLine = zeroline.copy()\n",
    "        for b in range(a,centerPT_m):  #√\n",
    "            x1 = x1space[a]\n",
    "            x2 = x2space[b]\n",
    "            xL2normsq = (((x1+M*p1)**2+(x2+M*p2)**2)**0.5)/M\n",
    "\n",
    "            v = k*xL2normsq*np.sin(alpha)\n",
    "            u = 4*k*(p3*1)*(np.sin(alpha/2)**2)\n",
    "            Koi = M/((fobj*lam)**2)*np.exp(-1j*u/(4*(np.sin(alpha/2)**2)))\n",
    "            tol = 1e-15\n",
    "            if False:\n",
    "                # Old, slow pure python code for reference\n",
    "                #intgrand = @(theta) (sqrt(cos(theta))) .* (1+cos(theta))  .*  (exp(-(i*u/2)* (sin(theta/2).^2) / (sin(alpha/2)^2)))  .*  (besselj(0, sin(theta)/sin(alpha)*v))  .*  (sin(theta));\n",
    "                #I0 = integral(@(theta)intgrand (theta),0,alpha);  \n",
    "                def integrand(theta, alpha, u, v):\n",
    "                    return (np.sqrt(np.cos(theta))) * (1+np.cos(theta))  \\\n",
    "                                        *  (np.exp(-(1j*u/2)* (np.sin(theta/2)**2) / (np.sin(alpha/2)**2))) \\\n",
    "                                        *  (scipy.special.jn(0, np.sin(theta)/np.sin(alpha)*v)) \\\n",
    "                                        *  (np.sin(theta))\n",
    "                integrand_r = lambda theta: np.real(integrand(theta, alpha, u, v))\n",
    "                integrand_i = lambda theta: np.imag(integrand(theta, alpha, u, v))\n",
    "                I0_r2,err_r = scipy.integrate.quad(integrand_r, 0, alpha, limit=180,epsabs=tol,epsrel=tol)\n",
    "                I0_i2,err_i = scipy.integrate.quad(integrand_i, 0, alpha, limit=180,epsabs=tol,epsrel=tol)\n",
    "#                print(I0_r2, I0_i2, err_r)\n",
    "            if True:\n",
    "                # New fast code\n",
    "                # JT: note that I see strangely incorrect results with tol=1e-10 (see \"digression\" cell below).\n",
    "                alphaFactor = np.sin(alpha/2)**(-2)\n",
    "                uOver2 = u/2\n",
    "                vFactor = v/np.sin(alpha)\n",
    "                I0_r,err_r = scipy.integrate.quad(integrandCython_r, 0, alpha, args=(alphaFactor, uOver2, vFactor),limit=180,epsabs=tol,epsrel=tol)\n",
    "                I0_i,err_i = scipy.integrate.quad(integrandCython_i, 0, alpha, args=(alphaFactor, uOver2, vFactor),limit=180,epsabs=tol,epsrel=tol)\n",
    "#                print(I0_r, I0_i, err_r)\n",
    "\n",
    "            I0 = (I0_r + 1j*I0_i)\n",
    "            err = (err_r + 1j*err_i)\n",
    "            patternLine[b] = Koi*I0\n",
    "        pattern[a,:] = patternLine\n",
    "\n",
    "    patternA = pattern[0:centerPT_m, 0:centerPT_m];   #√\n",
    "    patternAt = np.fliplr(patternA)\n",
    "\n",
    "    pattern3D = np.zeros((pattern.shape[0], pattern.shape[1], 4), dtype='complex128');\n",
    "    pattern3D[:,:,0] = pattern;\n",
    "    pattern3D[:centerPT_m, centerPT_m-1:,0] = patternAt   #√\n",
    "    # JT: empirically, this does rotate in the same direction as matlab (when the indexing order\n",
    "    # is identical in both cases). However, it shouldn't matter because we consider all four rotations\n",
    "    # and take the maximum!\n",
    "    pattern3D[:,:,1] = np.rot90( pattern3D[:,:,0] , -1)\n",
    "    pattern3D[:,:,2] = np.rot90( pattern3D[:,:,0] , -2)\n",
    "    pattern3D[:,:,3] = np.rot90( pattern3D[:,:,0] , -3)\n",
    "    # JT: unfortunately it is a pain to do the simple 'max' in python.\n",
    "    # Matlab takes the maximum abs(z), whereas python silently takes the maximum real(z).\n",
    "    # I can't see an obvious and tidy way to code what I need in python.\n",
    "    # I think the following should work as a quick bodge, and this shouldn't be a bottleneck\n",
    "    pattern = pattern3D[:,:,0].copy()\n",
    "    pattern[pattern == 0] = pattern3D[:,:,1][pattern == 0]\n",
    "    pattern[pattern == 0] = pattern3D[:,:,2][pattern == 0]\n",
    "    pattern[pattern == 0] = pattern3D[:,:,3][pattern == 0]\n",
    "\n",
    "#    %%%%%%%%%%%%%%%%%%% CALCULATED LF PSF %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    f1,dx1,x1 = fresnel2D(pattern*MLARRAY, scale, 1*fml, lam)\n",
    "\n",
    "    return pattern, f1, pattern3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "centerPT_m = int(np.ceil(len(x1space)/2)) #√\n",
    "halfWidth =  Nnum*(IMGSIZE_REF + 0 )*OSR\n",
    "centerArea_p = np.arange(np.maximum((centerPT_m - halfWidth),1)-1,          #√\n",
    "                       np.minimum((centerPT_m + halfWidth),len(x1space)-1))\n",
    "\n",
    "warnings.resetwarnings()\n",
    "for eachpt in tqdm(range(numpts), desc='Computing PSFs'):\n",
    "    p1 = p1ALL[eachpt]\n",
    "    p2 = p2ALL[eachpt]\n",
    "    p3 = p3ALL[eachpt]\n",
    "    \n",
    "    IMGSIZE_REF_IL = np.ceil(IMGSIZE_REF*( np.abs(p3)/p3max))\n",
    "    halfWidth_IL =  np.maximum(Nnum*(IMGSIZE_REF_IL + 0 )*OSR, 2*Nnum*OSR)\n",
    "    centerArea_IL_p = np.arange(np.maximum((centerPT_m - halfWidth_IL),1)-1,\n",
    "                              np.minimum((centerPT_m + halfWidth_IL),len(x1space)), dtype=np.int)   #√\n",
    "    print('Plane {0}: size of center area = {1}x{2}'.format(eachpt, len(centerArea_IL_p), len(centerArea_IL_p)))\n",
    "    \n",
    "    # excute PSF computing function\n",
    "    if True:\n",
    "        t1 = time.time()\n",
    "        psfWAVE, LFpsfWAVE, pattern3D = calcPSF_p(p1, p2, p3, fobj, NA, x1space, x2space, pixelPitch/OSR, lam, MLARRAY, d, M, n,  centerArea_IL_p)\n",
    "        psfWAVE_STACK[:,:,eachpt]  = psfWAVE\n",
    "        LFpsfWAVE_STACK[:,:,eachpt]= LFpsfWAVE\n",
    "        print('Plane {0} took {1}'.format(eachpt, time.time()-t1))\n",
    "    else:\n",
    "        warnings.warn('Not actually computing PSF!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression: accuracy of integration\n",
    "Strangely, and rather worryingly, scipy.integrate.quad seems to misbehave with certain very specific inputs. As demonstrated below, if the tolerance is 1e-10 the returned result can be wrong by 2% (despite reporting that the error is ~1e-10). I don't understand enough about what it is doing to know why on earth this might be happening! I have increased the tolerance to 1e-15 and that seems to have made the problem go away, but it is still a little worrying not to understand why it is happening (and whether 1e-15 is definitely safe under all circumstances...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def DemonstrateProblem(tol, thetas, vals):\n",
    "        alpha = 1.253235897503375\n",
    "        u = -432.1261323834447\n",
    "        v = 686.3628350636566\n",
    "        def integrand(theta, alpha, u, v, thetas, vals):\n",
    "            result = ((np.sqrt(np.cos(theta))) * (1+np.cos(theta))  \\\n",
    "                                *  (np.exp(-(1j*u/2)* (np.sin(theta/2)**2) / (np.sin(alpha/2)**2))) \\\n",
    "                                *  (scipy.special.jn(0, np.sin(theta)/np.sin(alpha)*v)) \\\n",
    "                                *  (np.sin(theta))).real\n",
    "            thetas.append(theta)\n",
    "            vals.append(result)\n",
    "            return result\n",
    "        I0_r,err_r = scipy.integrate.quad(lambda theta:integrand(theta, alpha, u, v, thetas, vals), 0, alpha, limit=180,epsabs=tol,epsrel=tol)\n",
    "        print(tol, I0_r, err_r)\n",
    "\n",
    "    thetas = []\n",
    "    vals = []\n",
    "    for tol in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
    "        DemonstrateProblem(tol, thetas, vals)\n",
    "\n",
    "    thetas10 = []\n",
    "    vals10 = []\n",
    "    DemonstrateProblem(1e-10, thetas10, vals10)    \n",
    "    thetas11 = []\n",
    "    vals11 = []\n",
    "    DemonstrateProblem(1e-11, thetas11, vals11)    \n",
    "\n",
    "    def PlotForOrder(thetas, vals, line=True, dots=True, new=True):\n",
    "        order = np.argsort(thetas)\n",
    "        temp1 = np.array(thetas)[order]\n",
    "        temp2 = (np.array(vals).real)[order]\n",
    "        if new is True:\n",
    "            plt.figure(figsize=(20,10))\n",
    "        if line is True:\n",
    "            plt.plot(temp1, temp2)\n",
    "        if dots is True:\n",
    "            plt.plot(temp1, temp2, '.')\n",
    "\n",
    "    # There is a range from 0.6 to 0.8 where it really does not sample the function much.\n",
    "    # I don't know how the algorithm is meant to work, but it seems rather implausible to me that\n",
    "    # it could be possible to be that confident in the integral when there is so much going on in the function\n",
    "    # that has not been sampled by the integrator at all!\n",
    "    for lim in np.arange(0, 1.2, 0.1):\n",
    "        PlotForOrder(thetas11, vals11, True, False)\n",
    "        PlotForOrder(thetas10, vals10, False, True, False)\n",
    "        plt.xlim(lim, lim+0.1)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Compute light field PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_shift2(img, SHIFTX, SHIFTY):  #√\n",
    "    eqtol = 1e-10\n",
    "    assert (np.abs(SHIFTX%1)<eqtol and np.abs(SHIFTY%1)<eqtol), 'SHIFTX and SHIFTY should be integer numbers'\n",
    "\n",
    "    SHIFTX = int(round(SHIFTX))\n",
    "    SHIFTY = int(round(SHIFTY))\n",
    "    new_im = np.zeros_like(img);\n",
    "\n",
    "    # JT: logic for here: 0:end-SHIFTX in matlab would skip final element if SHIFTX=-1\n",
    "    # In python, :-1 would skip final element too, so :-SHIFTX will do the trick.\n",
    "    # However, care is needed to cope with SHIFTX=0, hence the use of endx\n",
    "    endx,endy = img.shape\n",
    "    if SHIFTX >=0 and SHIFTY >= 0:\n",
    "        new_im[SHIFTX:, SHIFTY:] = img[:endx-SHIFTX, :endy-SHIFTY]\n",
    "    elif SHIFTX >=0 and SHIFTY < 0:\n",
    "        new_im[SHIFTX:, :SHIFTY] = img[:endx-SHIFTX, -SHIFTY:]\n",
    "    elif SHIFTX <0 and SHIFTY >= 0:\n",
    "        new_im[:SHIFTX, SHIFTY:] = img[-SHIFTX:, :endy-SHIFTY]\n",
    "    else:\n",
    "        new_im[:SHIFTX, :SHIFTY] = img[-SHIFTX:, -SHIFTY:]\n",
    "\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelBinning(SIMG, OSR):  #√\n",
    "    assert((OSR % 2) == 1)   # Should already be caught at top of script, but repeat the check here to be sure.\n",
    "    x1length, x2length = SIMG.shape\n",
    "\n",
    "    x1center_m = int((x1length-1)/2 + 1)   #√ I think (though I am only assuming I need to cast to int here)\n",
    "    x2center_m = int((x2length-1)/2 + 1)\n",
    "    x1centerinit_m = x1center_m - int((OSR-1)/2)\n",
    "    x2centerinit_m = x2center_m - int((OSR-1)/2)\n",
    "    x1init_m = x1centerinit_m -  int(np.floor(x1centerinit_m/OSR)*OSR)\n",
    "    x2init_m = x2centerinit_m -  int(np.floor(x2centerinit_m/OSR)*OSR)\n",
    "\n",
    "    x1shift = 0\n",
    "    x2shift = 0\n",
    "    if x1init_m<1:\n",
    "        x1init_m += OSR\n",
    "        x1shift = 1\n",
    "    if x2init_m<1:\n",
    "        x2init_m += OSR\n",
    "        x2shift = 1\n",
    "\n",
    "    # JT: commented out in MATLAB code:  SIMG_crop = SIMG( (x1init:1:end-OSR+1), (x2init:1:end-OSR+1) );\n",
    "    # JT: commented out in MATLAB code:  SIMG_crop = SIMG_crop( (1:1: floor(size(SIMG_crop,1)/OSR)*OSR) ,  (1:1: floor(size(SIMG_crop,2)/OSR)*OSR) );\n",
    "    halfWidth = len(range(x1init_m,x1center_m-1+1))  #√\n",
    "    # JT: not sure why this is split into multiple separate ranges that are then concatenated:\n",
    "    # Matlab: SIMG_crop = SIMG( [ (x1init:x1center-1) x1center x1center+1:x1center+halfWidth ],  [ (x2init:x2center-1) x2center x2center+1:x2center+halfWidth ] );\n",
    "    SIMG_crop = SIMG[ x1init_m-1:x1center_m+halfWidth,  #√\n",
    "                      x2init_m-1:x2center_m+halfWidth]\n",
    "\n",
    "#    %%%%%%%%%%%%%%%%%% PIXEL BINNING  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # JT: I am not totally certain I am doing the same as the matlab,\n",
    "    # but this achieves what I think I would expect the matlab to do!\n",
    "    m,n = SIMG_crop.shape \n",
    "    SIMG_crop = np.reshape(SIMG_crop, (int(m/OSR), OSR, int(n/OSR), OSR))\n",
    "    OIMG = np.sum(SIMG_crop, axis=(1,3))\n",
    "    #SIMG_crop = sum( reshape(SIMG_crop,OSR,[]) ,1 );\n",
    "    #SIMG_crop=reshape(SIMG_crop,m/OSR,[]).'; %Note transpose\n",
    "    #SIMG_crop=sum( reshape(SIMG_crop,OSR,[]) ,1);\n",
    "    #OIMG =reshape(SIMG_crop,n/OSR,[]).'; %Note transpose\n",
    "\n",
    "    return OIMG, x1shift, x2shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1objspace = (pixelPitch/M)*np.arange(-np.floor(Nnum/2), np.floor(Nnum/2)+0.1, 1)\n",
    "x2objspace = x1objspace.copy()\n",
    "XREF = np.ceil(len(x1objspace)/2)\n",
    "YREF = np.ceil(len(x1objspace)/2)\n",
    "CP_p = np.arange((centerPT_m-1)/OSR - halfWidth/OSR, (centerPT_m-1)/OSR + halfWidth/OSR +0.1, 1, dtype=np.int) #√For Python indexing\n",
    "H = np.zeros((len(CP_p), len(CP_p), len(x1objspace), len(x2objspace), len(x3objspace) ))\n",
    "\n",
    "if True:\n",
    "    for i in tqdm(range(len(x1objspace)*len(x2objspace)*len(x3objspace)), desc='Computing LF PSFs'):\n",
    "        (a, b, c) = np.unravel_index(i, (len(x1objspace), len(x2objspace), len(x3objspace)))\n",
    "        psfREF = psfWAVE_STACK[:,:,c]\n",
    "        psfSHIFT = im_shift2(psfREF, OSR*(a+1-XREF), OSR*(b+1-YREF) )   #√ switched to allow for a,b in python\n",
    "        f1,dx1,x1 = fresnel2D(psfSHIFT*MLARRAY, pixelPitch/OSR, d,lam)\n",
    "        f1 = im_shift2(f1, -OSR*(a+1-XREF), -OSR*(b+1-YREF) )     #√ switched to allow for a,b in python\n",
    "\n",
    "        xmin_p =  np.maximum( centerPT_m-1  - halfWidth, 0) #√\n",
    "        xmax_p =  np.minimum( centerPT_m-1  + halfWidth, f1.shape[0]-1) #√\n",
    "        ymin_p =  np.maximum( centerPT_m-1  - halfWidth, 0) #√\n",
    "        ymax_p =  np.minimum( centerPT_m-1  + halfWidth, f1.shape[1]-1) #√\n",
    "\n",
    "        f1_AP = np.zeros_like(f1)\n",
    "        f1_AP[xmin_p:xmax_p+1,ymin_p:ymax_p+1] = f1[xmin_p:xmax_p+1,ymin_p:ymax_p+1]   #√\n",
    "        [f1_AP_resize, x1shift, x2shift] = pixelBinning(np.abs(f1_AP**2), OSR)      \n",
    "        # JT: I had to split this up into two separate commands to make it work in Python\n",
    "        temp = f1_AP_resize[ CP_p - x1shift, : ]   #√\n",
    "        f1_CP = temp[ :, CP_p-x2shift ]   #√\n",
    "        H[:,:,a,b,c] = f1_CP\n",
    "    # Take a copy of H before the maximum was calculated\n",
    "    H_premax = H.copy()\n",
    "    Hmax = np.max(H)\n",
    "    H = H/Hmax\n",
    "else:\n",
    "    warnings.warn('Skipping LF PSF calculation, and using H from .mat file')\n",
    "    H = _H.T.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1space = (pixelPitch/1)*np.arange(-IMG_HALFWIDTH*1, IMG_HALFWIDTH*1+0.1, 1);\n",
    "x2space = x1space.copy()\n",
    "x1space = x1space[CP_p]\n",
    "x2space = x2space[CP_p]\n",
    "\n",
    "if True:\n",
    "    # Force very small values (in each separate plane) to zero\n",
    "    tol = 0.005\n",
    "    # JT TODO: I think this may be slow due to the copying back at the end.\n",
    "    # I am almost certain that that is unnecessary in python, and could be removed.\n",
    "    # (or actually, is it really any sort of bottleneck? I think not...)\n",
    "    for i in tqdm(range(H.shape[4]), desc='clipping to zero'):\n",
    "        H4Dslice = H[:,:,:,:,i]\n",
    "        H4Dslice[H4Dslice < (tol*np.max(H4Dslice))] = 0\n",
    "        H[:,:,:,:,i] = H4Dslice\n",
    "else:\n",
    "    warnings.warn('Not clipping to zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = H.astype('float32')\n",
    "\n",
    "#%%%%%%%%%%%%%%%%% Estimate PSF size again  %%%%%%%%%%%%%%%%%%%%%%%\n",
    "# JT: I *DO* want to save CAindex in 1-based MATLAB indexing.\n",
    "#     My python deconvolution code expects that (since we are just loading .mat files...),\n",
    "#     and my deconvolution code will take that into account.\n",
    "centerCP_m = np.ceil(len(CP_p)/2)\n",
    "CAindex = np.zeros((2,len(x3objspace)), dtype='int')\n",
    "for i in range(len(x3objspace)):\n",
    "    IMGSIZE_REF_IL = np.ceil(IMGSIZE_REF*( np.abs(x3objspace[i])/p3max))\n",
    "    halfWidth_IL =  np.maximum(Nnum*(IMGSIZE_REF_IL + 0 ), 2*Nnum)\n",
    "    CAindex[0,i] = np.maximum( centerCP_m - halfWidth_IL , 1)\n",
    "    CAindex[1,i] = np.minimum( centerCP_m + halfWidth_IL , H.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory from variables we have now finished with\n",
    "if False:\n",
    "    del f1\n",
    "    del f1_AP\n",
    "    del f1_AP_resize\n",
    "    del f1_CP\n",
    "    del psfREF\n",
    "    del psfSHIFT\n",
    "    del LFpsfWAVE_STACK\n",
    "    del psfWAVE_STACK\n",
    "else:\n",
    "    warnings.warn('Not freeing up variables')\n",
    "    # For small |z| these array sizes are not that big.\n",
    "    # It's possible, though, that at larger |z| these really do take up a substantial amount of space\n",
    "    def PrintSizes(*args):\n",
    "        for a in args:\n",
    "            print(a.size*a.itemsize)\n",
    "    PrintSizes(f1, f1_AP, f1_AP_resize, f1_CP, psfREF, psfSHIFT, LFpsfWAVE_STACK, psfWAVE_STACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: calculate Ht\n",
    "This appears to be correct now. If I run this code here, starting with H loaded from a real Matlab .mat file, the result I get for Ht (or, at least, for certain PSFs selected from it) is basically identical to the Ht stored in the original .mat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains old code, now superseded by MUCH faster code I have written to do the same thing\n",
    "# (there is no need to do the convolution - or indeed the longhand rotation - to get the elements we need for Ht)\n",
    "def Rotate180(img):\n",
    "    h = img.shape[0]\n",
    "    rot_img = np.zeros_like(img)\n",
    "    for i in range(h):\n",
    "        rot_img[i] = img[h-i-1,::-1]\n",
    "    return rot_img\n",
    "\n",
    "def backwardProject(H, projection, Nnum, ccRange=None):\n",
    "    x3length = H.shape[4]\n",
    "    if (ccRange is None):\n",
    "        ccRange = range(x3length)\n",
    "    Backprojection = np.zeros((projection.shape[0], projection.shape[0], x3length))\n",
    "    for aa in tqdm(range(Nnum), leave=False):\n",
    "        for bb in range(Nnum):\n",
    "            for cc in ccRange:\n",
    "                Ht = Rotate180(H[:,:,aa,bb,cc])\n",
    "                tempSlice = scipy.signal.fftconvolve(projection, Ht, 'same')\n",
    "                Backprojection[aa::Nnum, bb::Nnum, cc] += tempSlice[aa::Nnum, bb::Nnum]\n",
    "    return Backprojection\n",
    "\n",
    "def calcHt(H):\n",
    "    Hsize1,_,Nnum,_,x3length = H.shape\n",
    "    tmpsize = int(np.ceil(H.shape[0]/Nnum))\n",
    "    if ((tmpsize%2) == 1):\n",
    "        imgsize = (tmpsize+2)*Nnum;\n",
    "    else:\n",
    "        imgsize = (tmpsize+3)*Nnum,\n",
    "\n",
    "    zeroprojection = np.zeros((imgsize, imgsize))\n",
    "    imcenter_m = int(np.ceil(imgsize/2))\n",
    "    imcenterinit_m = imcenter_m - int(np.ceil(Nnum/2))\n",
    "\n",
    "    Ht = np.zeros_like(H)\n",
    "    for aa in tqdm(range(Nnum)):\n",
    "        for bb in tqdm(range(Nnum), leave=False):\n",
    "            temp = zeroprojection.copy()\n",
    "            temp[imcenterinit_m+aa, imcenterinit_m+bb] = 1  #√\n",
    "            tempback = backwardProject(H, temp, Nnum)\n",
    "            tempback_cut = tempback[imcenter_m - int((Hsize1-1)/2) - 0*Nnum - 1 : imcenter_m + int((Hsize1-1)/2) + 0*Nnum, \n",
    "                                    imcenter_m - int((Hsize1-1)/2) - 0*Nnum - 1 : imcenter_m + int((Hsize1-1)/2) + 0*Nnum]#√\n",
    "            tempback_shift = np.zeros_like(tempback_cut)\n",
    "            for cc in range(x3length):\n",
    "                Ht[:,:,aa,bb,cc] = im_shift2(tempback_cut[:,:,cc], int(np.ceil(Nnum/2)-aa-1), int(np.ceil(Nnum/2)-bb-1) ) #√\n",
    "    return Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains my new code (way faster)\n",
    "def backwardProject_new(H, projection, Nnum, imcenterinit_mp, _aa, _bb):\n",
    "    # Note that with imcenterinit_mp the _mp suffix is a reminder that the same number can\n",
    "    # work for both python and matlab. Since we add aa to it to get a pixel index, that works\n",
    "    # in either language, since aa will start from 0 and 1 in the respective languages.\n",
    "    x3length = H.shape[4]\n",
    "    Backprojection2 = np.zeros((projection.shape[0], projection.shape[0], x3length))\n",
    "    imcenter = imcenterinit_mp + int(Nnum/2)\n",
    "    # Original code convolves a point at _aa,_bb with the rotated H\n",
    "    for aa in range(Nnum):\n",
    "        for bb in range(Nnum):\n",
    "            # No need to call Rotate180 - we can just mirror the axes and that has the same effect\n",
    "            _Ht = H[::-1,::-1,aa,bb]\n",
    "            # Identify the indices in _Ht that we will be keeping\n",
    "            # i.e. the ones that, in the original code, would actually be \n",
    "            # sampled by the aa::Nnum indexing of tempSlice.\n",
    "            # In this calculation, note that the central pixel of _Ht \n",
    "            # will be indexed at a multiple of Nnum\n",
    "            HtCentA = int(_Ht.shape[0]/2)\n",
    "            HtCentB = int(_Ht.shape[1]/2)\n",
    "            assert((HtCentA % Nnum) == 0)\n",
    "            aStart = (-_aa + aa) % Nnum\n",
    "            bStart = (-_bb + bb) % Nnum\n",
    "            # The next question is where these should go in Backprojection2. \n",
    "            # We know that the *middle pixel* of _Ht goes at imcenterinit+_aa,_bb in Backprojection2.\n",
    "            # It therefore follows that pixel 'aStart' should go\n",
    "            # at the following coordinate in Backprojection2:\n",
    "            aStartDest = imcenterinit_mp+_aa - HtCentA + aStart\n",
    "            bStartDest = imcenterinit_mp+_bb - HtCentB + bStart\n",
    "            strided = _Ht[aStart::Nnum, bStart::Nnum]\n",
    "            aEndDest = aStartDest + strided.shape[0]*Nnum\n",
    "            bEndDest = bStartDest + strided.shape[1]*Nnum\n",
    "            Backprojection2[aStartDest:aEndDest:Nnum, bStartDest:bEndDest:Nnum] = strided\n",
    "    return Backprojection2\n",
    "\n",
    "def calcHt_new(_H):\n",
    "    # Not currently working - I just naively tried using BackwardProject\n",
    "    # (having previously set up Ht for the matrix to be a rotated version of H),\n",
    "    # but this does not give anything remotely resembling the correct result for Ht!\n",
    "    Hsize1,_,Nnum,_,x3length = _H.shape\n",
    "    tmpsize = int(np.ceil(_H.shape[0]/Nnum))\n",
    "    if ((tmpsize%2) == 1):\n",
    "        imgsize = (tmpsize+2)*Nnum;\n",
    "    else:\n",
    "        imgsize = (tmpsize+3)*Nnum,\n",
    "\n",
    "    zeroprojection = np.zeros((imgsize, imgsize))\n",
    "    imcenter_m = int(np.ceil(imgsize/2))\n",
    "    imcenterinit_m = imcenter_m - int(np.ceil(Nnum/2))\n",
    "\n",
    "    Ht = np.zeros_like(_H)\n",
    "    for aa in tqdm(range(Nnum)):\n",
    "        for bb in tqdm(range(Nnum), leave=False):\n",
    "            temp = zeroprojection.copy().astype('float32')\n",
    "            temp[imcenterinit_m+aa, imcenterinit_m+bb] = 1  #√ same arithmetic works for me, because aa starts at 0 instead of 1\n",
    "            tempback = backwardProject_new(H, temp, Nnum, imcenterinit_m, aa, bb)\n",
    "            tempback_cut = tempback[imcenter_m - int((Hsize1-1)/2) - 0*Nnum - 1 : imcenter_m + int((Hsize1-1)/2) + 0*Nnum, \n",
    "                                    imcenter_m - int((Hsize1-1)/2) - 0*Nnum - 1 : imcenter_m + int((Hsize1-1)/2) + 0*Nnum]#√\n",
    "            tempback_shift = np.zeros_like(tempback_cut)\n",
    "            for cc in range(x3length):\n",
    "                Ht[:,:,aa,bb,cc] = im_shift2(tempback_cut[:,:,cc], int(np.ceil(Nnum/2)-aa-1), int(np.ceil(Nnum/2)-bb-1) ) #√\n",
    "    return Ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%% Calculate Ht (transpose for backprojection) %%%%%%%%%\n",
    "print('Computing Transpose (3/3)')\n",
    "if False:\n",
    "    Ht = calcHt(H)\n",
    "elif True:\n",
    "    # JT: my new code, massively faster\n",
    "    Ht = calcHt_new(H)\n",
    "else:\n",
    "    warnings.warn('Not computing transpose!')\n",
    "    Ht = H.copy()\n",
    "Ht = Ht.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the matrices we have generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveMatrices(_H, _Ht, _CAindex, Nnum, matPathStem):\n",
    "    # Save a .mat file just like the Matlab code does.\n",
    "    # In fact, my deconvolution code will take that and convert it to my own format,\n",
    "    # but to avoid confusion(?) I just generate the .mat file here.\n",
    "    # My deconvolution code will auto-generate the files it actually needs, when it sees they don't exist yet.\n",
    "    matPath = '%s_%s.mat'%(matPathStem, MatrixFileString())\n",
    "    print('Saving to', matPath)\n",
    "    with h5py.File(matPath, 'w') as f:\n",
    "        print('Write parameters')\n",
    "        f['M'] = M\n",
    "        f['NA'] = NA\n",
    "        f['MLPitch'] = MLPitch\n",
    "        f['Nnum'] = 15\n",
    "        f['OSR'] = OSR\n",
    "        f['n'] = n\n",
    "        f['fml'] = fml\n",
    "        f['lambda'] = lam\n",
    "        f['zmax'] = zmax\n",
    "        f['zmin'] = zmin\n",
    "        f['zspacing'] = zspacing\n",
    "        \n",
    "        f['fobj'] = fobj\n",
    "        f['d'] = d\n",
    "        f['x3objspace'] = x3objspace\n",
    "        f['pixelPitch'] = pixelPitch\n",
    "        f['CAindex'] = CAindex\n",
    "\n",
    "        f['Hmax'] = Hmax   # JT: maximum value of H prior to normalization. Useful for fusing multiple z ranges.\n",
    "        \n",
    "        # Matlab works with Fortran-contiguous arrays, and writes them to disk as such.\n",
    "        # Consequently, if I want my arrays (same indexing order but different contiguity)\n",
    "        # to look exactly the same when saved to disk, I need to save their transpose.\n",
    "        print('Write H'); sys.stdout.flush()\n",
    "        print('H shape', H.shape)\n",
    "        f['H'] = H.T\n",
    "        print('Write Ht'); sys.stdout.flush()\n",
    "        f['Ht'] = Ht.T\n",
    "        print('Ht shape', Ht.shape)\n",
    "        print('Done'); sys.stdout.flush()\n",
    "\n",
    "SaveMatrices(H, Ht, CAindex, Nnum, 'PSFMatrix/expt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check my results against the Matlab ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theirs:\n",
    "(_H1, _Ht1, hReducedShape1, htReducedShape1, _CAindex1) = LoadRawMatrixData('/Volumes/Development/SIsoftware/PSFmatrix/PSFmatrix_%s.mat'%MatrixFileString())\n",
    "# Mine:\n",
    "(_H2, _Ht2, hReducedShape2, htReducedShape2, _CAindex2) = LoadRawMatrixData('/Volumes/Development/light-field-flow/PSFmatrix/expt_%s.mat'%MatrixFileString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(np.abs(_H1 - _H2)))\n",
    "print(np.max(np.abs(_Ht1 - _Ht2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
