{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf840
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww21260\viewh16500\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 A general note to myself about work-in-progress C code
\b0 \
My c code can't cope with an array that has been transposed (Probably because it assumes adjacent strides in x?). I should probably fix that, though I doubt it's a performance issue to just .copy() the transposed array, which is what I do at the moment. I should really be swapping the transpose to be the final operation (in the case of square inputs) anyway. However, it looks as if a decent chunk of the fft time is actually being spent in the other ffts (for the reduced arrays) anyway!
\b \
\
Single-pixel imaging
\b0 \
This seems as good as anywhere to add a note about single-pixel imaging (which is another application where I think my approach is plausible). I need to remember this as a reference:\
https://www.osapublishing.org/oe/abstract.cfm?uri=oe-28-6-7889\
They are just using a moving target over a static illumination pattern (don\'92t know if they referenced the japanese Science flow cytometry paper\'85!), but I should still bear it in mind as a citation.
\b \
\
Flow recovery - what I\'92ve done\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\b0 \cf0 - I am using a local optimizer, of course, so I need to choose a plausible starting point or things go crazy. That\'92s ok: I should have a decent estimate from PIV analysis of artefact-corrupted images\
- It turns out that the naive method works surprisingly well with large blurry features - I suppose that\'92s not surprising, since effectively the resolution of the flow analysis is greater than the lenslet pitch. It struggles more when I run it with small blobs (thank goodness!).\
- BFGS actually doesn\'92t seem to converge to the solution (it fails for some reason). Powell seems more reliable.\
- I discovered that edge effects with warp() were distorting the solution in random ways. That may well explain why BFGS was failing to find a solution! I battled with warp() issues a lot. These included:\
	- warp() leads to anomalies at the edge of the image. Specifically, pixels are either \'91in\'92 or \'91out\'92, and the switch between the two states causes jumps in the score. It\'92s not clear what the best thing to do about this is. mode=\'92edge\'92 might work, but I would worry it might introduce odd biasing behaviour. I tried extending the object size and then cropping it down (i.e. filling with real data).\
	- It turned out it wasn\'92t enough to ignore the edge pixels, because the edge pixels affect a large area when I forward project. A combination of forcing zero edge shifts and specifying edge padding seems to have suppressed edge artefacts enough to stop instability in the scores I get for two virtually-identical shift values.\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\b \cf0 Flow recovery - next steps\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\b0 \cf0 \
- See how the naive algorithm fares with a larger peak velocity (12 instead of 7). Does it still consistently underestimate? By more\'85? Actually no, it does ok. I should maybe investigate somewhat systematically how it fares with different shift values. And also go back to uniform shifts, because I thought I\'92d observed that it really didn\'92t perform properly in that case - but maybe I\'92ve since fixed a bug in that code.\
\
- I should maybe revisit BFGS now I have excluded edge effects from warp()\'85\
\
- Save the input image (maybe with a timestamp in the filename to avoid overwriting?), so that I can reproduce previous runs\
\
- Can I estimate the 
\i gradients
\i0  of the problem by just warping the 
\i same
\i0  recovered object and scoring it? I am pretty sure that will be imperfect, but I have a feeling it might be close enough to the truth to send the optimizer in the right direction. Worth a try! Should be pretty quick to implement, I think. I can also compare it to reality by running some full recoveries with W+dW and determining the true gradient that way.\
\
- Look a bit at the internals of Powell. Does it really need as many trial values to reach an optimum, given that I think my cost function is pretty smooth and quadratic?
\b \

\b0 \
- Think about convergence criterion, and ensuring behaviour is similar for different input intensities. How much does it help to choose a more relaxed xtol for Powell? Actually, choosing 1e-1 instead of 1e-2 seems to take 
\i longer
\i0  to converge. Also, it seems to be evaluating shifts to a smaller granularity than e.g. 1e-2. Is that definitely correct, or have I got the settings wrong somehow? See comment above about tiny changes.\
\
- Consider expanding the PIV code to more than one z plane\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\b \cf0 \
Things to investigate
\b0 \
- deconvRL and _PIV actually give slightly different results (deconvRL seems better). Is there an actual bug in deconvRL_PIV, or is Prevedel\'92s implementation of RL actually slightly different (and more efficient)?\
\

\b \
Performance
\b0 \
- Look at how well my code is using multithreading.\
\
- Revisit what\'92s happening on mac pro - multithreading performance seems much worse. Is it a linux benefit, or something else?\
\
- The optimizer calculates the full gradients even if some variables are bounded to a constant. I should be able to do better if I write my own gradient function. That would also have the benefit that I should be able to parallelize the computations much better. Similarly, with a bit of faffing around rewriting the code myself, I should be able to run a Powell optimizer that tweaks all individual flow components in parallel.\
}